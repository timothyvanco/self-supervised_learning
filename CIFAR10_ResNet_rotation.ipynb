{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CIFAR10_ResNet_rotation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOKP2vWrU3cU6Zv6nbq5QfN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/timothyvanco/self-supervised_learning/blob/main/CIFAR10_ResNet_rotation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6zA2mL0vLcvA"
      },
      "source": [
        "from __future__ import print_function\n",
        "import keras\n",
        "from keras.layers import Dense, Conv2D, BatchNormalization, Activation\n",
        "from keras.layers import AveragePooling2D, Input, Flatten\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.regularizers import l2\n",
        "from keras import backend as K\n",
        "from keras.models import Model\n",
        "from keras.datasets import cifar10\n",
        "import numpy as np\n",
        "import os\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import random\n",
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0sgvT5IRw4bv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c642e95-1655-41c8-e194-e582ab50406c"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L7qxptaf-jfv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8b5af51-6608-47ba-d945-9d6aa8ef6d6d"
      },
      "source": [
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "    for gpu in gpus:\n",
        "        try:\n",
        "            tf.config.experimental.set_memory_growth(gpu, True)\n",
        "            logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
        "            print(len(gpus), 'Physical GPUs,', len(logical_gpus), 'Logical GPUs')\n",
        "        except RuntimeError as e:\n",
        "            print(e)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 Physical GPUs, 1 Logical GPUs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rkXMSw3T-l9j"
      },
      "source": [
        "def preprocess_data(x_train, y_train, x_test, y_test, subtract_pixel_mean=True):\n",
        "    \n",
        "    # Normalize data from 0-255 into 0-1\n",
        "    x_train = x_train.astype('float32') / 255\n",
        "    x_test = x_test.astype('float32') / 255\n",
        "    \n",
        "    # If subtract pixel mean is enabled - subtract mean\n",
        "    if subtract_pixel_mean:\n",
        "        x_train_mean = np.mean(x_train, axis=0)\n",
        "        x_train -= x_train_mean\n",
        "        x_test -= x_train_mean\n",
        "    \n",
        "    return x_train, y_train, x_test, y_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LGz8d0MdXugA"
      },
      "source": [
        "def preprocess_data2(x_train, y_train, x_test, y_test, subtract_pixel_mean=True):\n",
        "    \n",
        "    # Normalize data from 0-255 into 0-1\n",
        "    x_train = x_train.astype('float32') / 255\n",
        "    x_test = x_test.astype('float32') / 255\n",
        "    \n",
        "    # If subtract pixel mean is enabled - subtract mean\n",
        "    if subtract_pixel_mean:\n",
        "        x_train_mean = np.mean(x_train, axis=(0,1,2))\n",
        "        x_train_std = np.std(x_train, axis=(0,1,2))\n",
        "        x_train = (x_train - x_train_mean) / x_train_std\n",
        "        x_test = (x_test - x_train_mean) / x_train_std\n",
        "    \n",
        "    return x_train, y_train, x_test, y_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qw_6rEQr-wY1"
      },
      "source": [
        "def rotate_image(image, iterations=None):\n",
        "  # choose how many times it should rotate with 90\n",
        "  # if not specified -> choose random from 0 do 3 (0° - 270°)\n",
        "  if not iterations:\n",
        "    iterations = random.randint(0, 3) \n",
        "\n",
        "  y = [0, 0, 0, 0]\n",
        "  y[iterations] = 1\n",
        "\n",
        "  for i in range(iterations):\n",
        "    image = np.rot90(image)\n",
        "    \n",
        "  return image, y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ziXqZaiu-yKt"
      },
      "source": [
        "### Resnet Implementation taken from David Yang\n",
        "\n",
        "def lr_schedule(epoch):\n",
        "    \"\"\" Learning Rate Schedule\n",
        "    \n",
        "    Learning rate is scheduled to be reduced after 80, 120, 160, 180 epochs.\n",
        "    Called automatically every epoch as part of callbacks during training.\n",
        "    # Arguments\n",
        "        epoch (int): The number of epochs\n",
        "    # Returns\n",
        "        lr (float32): learning rate\n",
        "    \"\"\"\n",
        "\n",
        "    lr = 1e-3\n",
        "    if epoch > 40:\n",
        "        lr *= 0.5e-3\n",
        "    elif epoch > 30:\n",
        "        lr *= 1e-3\n",
        "    elif epoch > 20:\n",
        "        lr *= 1e-2\n",
        "    elif epoch > 10:\n",
        "        lr *= 1e-1\n",
        "    print('Learning rate: ', lr)\n",
        "\n",
        "    return lr\n",
        "    \n",
        "def resnet_layer(inputs,\n",
        "                 num_filters= 16,\n",
        "                 kernel_size= 3,\n",
        "                 strides= 1,\n",
        "                 activation= 'relu',\n",
        "                 batch_normalization= True,\n",
        "                 conv_first= True):\n",
        "    \n",
        "    \"\"\"2D Convolution-Batch Normalization-Activation stack builder\n",
        "    # Arguments\n",
        "        inputs (tensor): input tensor from input image or previous layer\n",
        "        num_filters (int): Conv2D number of filters\n",
        "        kernel_size (int): Conv2D square kernel dimensions\n",
        "        strides (int): Conv2D square stride dimensions\n",
        "        activation (string): activation name\n",
        "        batch_normalization (bool): whether to include batch normalization\n",
        "        conv_first (bool): conv-bn-activation (True) or\n",
        "            bn-activation-conv (False)\n",
        "    # Returns\n",
        "        x (tensor): tensor as input to the next layer\n",
        "    \"\"\"\n",
        "    conv = Conv2D(num_filters,\n",
        "                  kernel_size=kernel_size,\n",
        "                  strides=strides,\n",
        "                  padding='same',\n",
        "                  kernel_initializer='he_normal',\n",
        "                  kernel_regularizer=l2(1e-4))\n",
        "    x = inputs\n",
        "    if conv_first:\n",
        "        x = conv(x)\n",
        "        if batch_normalization:\n",
        "            x = BatchNormalization()(x)\n",
        "        if activation is not None:\n",
        "            x = Activation(activation)(x)\n",
        "    else:\n",
        "        if batch_normalization:\n",
        "            x = BatchNormalization()(x)\n",
        "        if activation is not None:\n",
        "            x = Activation(activation)(x)\n",
        "        x = conv(x)\n",
        "    return x\n",
        "\n",
        "def resnet_v1(input_shape, depth, num_classes=10):\n",
        "    \"\"\"ResNet Version 1 Model builder [a]\n",
        "    \n",
        "    Stacks of 2 x (3 x 3) Conv2D-BN-ReLU\n",
        "    Last ReLU is after the shortcut connection.\n",
        "    At the beginning of each stage, the feature map size is halved (downsampled)\n",
        "    by a convolutional layer with strides=2, while the number of filters is\n",
        "    doubled. Within each stage, the layers have the same number filters and the\n",
        "    same number of filters.\n",
        "    \n",
        "    Features maps sizes:\n",
        "    stage 0: 32x32, 16\n",
        "    stage 1: 16x16, 32\n",
        "    stage 2:  8x8,  64\n",
        "    \n",
        "    The Number of parameters is approx the same as Table 6 of [a]:\n",
        "    ResNet20 0.27M\n",
        "    ResNet32 0.46M\n",
        "    ResNet44 0.66M\n",
        "    ResNet56 0.85M\n",
        "    ResNet110 1.7M\n",
        "    \n",
        "    # Arguments\n",
        "        input_shape (tensor): shape of input image tensor\n",
        "        depth (int): number of core convolutional layers\n",
        "        num_classes (int): number of classes (CIFAR10 has 10)\n",
        "    # Returns\n",
        "        model (Model): Keras model instance\n",
        "    \"\"\"\n",
        "\n",
        "    if (depth - 2) % 6 != 0:\n",
        "        raise ValueError('depth should be 6n+2 (eg 20, 32, 44 in [a])')\n",
        "    \n",
        "    # Start model definition.\n",
        "    num_filters = 16\n",
        "    num_res_blocks = int((depth - 2) / 6)\n",
        "    inputs = Input(shape=input_shape)\n",
        "    x = resnet_layer(inputs=inputs)\n",
        "    \n",
        "    # Instantiate the stack of residual units\n",
        "    for stack in range(3):\n",
        "        for res_block in range(num_res_blocks):\n",
        "            strides = 1\n",
        "\n",
        "            if stack > 0 and res_block == 0:  # first layer but not first stack\n",
        "                strides = 2  # downsample\n",
        "\n",
        "            y = resnet_layer(inputs=x,\n",
        "                             num_filters=num_filters,\n",
        "                             strides=strides)\n",
        "            y = resnet_layer(inputs=y,\n",
        "                             num_filters=num_filters,\n",
        "                             activation=None)\n",
        "            \n",
        "            if stack > 0 and res_block == 0:  # first layer but not first stack\n",
        "                # linear projection residual shortcut connection to match changed dims\n",
        "                x = resnet_layer(inputs=x,\n",
        "                                 num_filters=num_filters,\n",
        "                                 kernel_size=1,\n",
        "                                 strides=strides,\n",
        "                                 activation=None,\n",
        "                                 batch_normalization=False)\n",
        "                \n",
        "            x = keras.layers.add([x, y])\n",
        "            x = Activation('relu')(x)\n",
        "        num_filters *= 2\n",
        "        \n",
        "    # Add classifier on top.\n",
        "    # v1 does not use BN after last shortcut connection-ReLU\n",
        "    x = AveragePooling2D(pool_size=8)(x)\n",
        "    y = Flatten()(x)\n",
        "    outputs = Dense(num_classes,\n",
        "                    activation='softmax',\n",
        "                    kernel_initializer='he_normal')(y)\n",
        "    # Instantiate model.\n",
        "    model = Model(inputs=inputs, outputs=outputs)\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "po0XgDWA-12V"
      },
      "source": [
        "def make_rotated_data(Train, Test, subtract_pixel_mean=True):\n",
        "    model_name='cifar100SLL'\n",
        "\n",
        "    xy_rot_train = list(zip(*[rotate_image(im) for im in Train[0]]))\n",
        "    xy_rot_test = list(zip(*[rotate_image(im) for im in Test[0]]))\n",
        "    \n",
        "    x_rot_train = np.array(xy_rot_train[0][:]).astype('float32')/255\n",
        "    y_rot_train = np.array(xy_rot_train[1][:])\n",
        "\n",
        "    x_rot_test = np.array(xy_rot_test[0][:]).astype('float32')/255\n",
        "    y_rot_test = np.array(xy_rot_test[1][:])\n",
        "    \n",
        "    if subtract_pixel_mean:\n",
        "        #x_rot_train_mean = np.mean(x_rot_train, axis=0)\n",
        "        #x_rot_train -= x_rot_train_mean\n",
        "        #x_rot_test -= x_rot_train_mean\n",
        "        x_rot_train_mean = np.mean(x_rot_train, axis=(0,1,2))\n",
        "        x_rot_train_std = np.std(x_rot_train_mean, axis=(0,1,2))\n",
        "        x_rot_train = (x_rot_train - x_rot_train_mean) / x_rot_train_std\n",
        "        x_rot_test = (x_rot_test - x_rot_train_mean) / x_rot_train_std\n",
        "    \n",
        "    return x_rot_train, y_rot_train, x_rot_test, y_rot_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CewH-Lpb-4yB"
      },
      "source": [
        "def make_ssl_backbone(Train, Test, save_dir, input_shape=(32,32,3), n=3, model_name='Restnetv1_SSL_Rotation.h5'):\n",
        "    # rotate images with PRETEXT task (rotate images (x) and add number into array (y) on place of number of rotations made)\n",
        "    x_rot_train, y_rot_train, x_rot_test, y_rot_test = make_rotated_data(Train, Test)\n",
        "    \n",
        "    # Computed depth from supplied model parameter n\n",
        "    depth = n * 6 + 2\n",
        "    \n",
        "    resnet_model = resnet_v1(input_shape=input_shape, depth=depth)\n",
        "    x = Dense(4, activation='softmax')(resnet_model.layers[-2].output)\n",
        "    model = keras.Model(resnet_model.inputs,x)\n",
        "\n",
        "    filepath = os.path.join(save_dir, model_name)\n",
        "    \n",
        "    # Prepare callbacks for model saving and for learning rate adjustment.\n",
        "    checkpoint = ModelCheckpoint(filepath=filepath,\n",
        "                                 monitor='val_accuracy',\n",
        "                                 verbose=1,\n",
        "                                 save_best_only=True)\n",
        "    \n",
        "    lr_scheduler = LearningRateScheduler(lr_schedule)\n",
        "\n",
        "    # Reduce learning rate when a metric has stopped improving\n",
        "    lr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1), # factor by which the learning rate will be reduced\n",
        "                                   cooldown=0,          # number of epochs to wait before resuming normal operation after lr has been reduced\n",
        "                                   patience=10,         # number of epochs with no improvement after which learning rate will be reduced\n",
        "                                   min_lr=0.5e-6)       # lower bound on the learning rate\n",
        "    callbacks = [checkpoint, lr_reducer, lr_scheduler]\n",
        "\n",
        "    optimizer = keras.optimizers.Adam()\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    \n",
        "    datagen = ImageDataGenerator(\n",
        "                featurewise_center=False,             # set input mean to 0 over the dataset\n",
        "                samplewise_center=False,              # set each sample mean to 0\n",
        "                featurewise_std_normalization=False,  # divide inputs by std of dataset\n",
        "                samplewise_std_normalization=False,   # divide each input by its std\n",
        "                zca_whitening=False,                  # apply ZCA whitening\n",
        "                zca_epsilon=1e-06,                    # epsilon for ZCA whitening\n",
        "                rotation_range=0,                     # randomly rotate images in the range (deg 0 to 180)\n",
        "                width_shift_range=0.1,                # randomly shift images horizontally\n",
        "                height_shift_range=0.1,               # randomly shift images vertically\n",
        "                shear_range=0.,                       # set range for random shear\n",
        "                zoom_range=0.,                        # set range for random zoom\n",
        "                channel_shift_range=0.,               # set range for random channel shifts\n",
        "                fill_mode='nearest',                  # set mode for filling points outside the input boundaries\n",
        "                cval=0.,                              # value used for fill_mode = \"constant\"\n",
        "                horizontal_flip=True,                 # randomly flip images\n",
        "                vertical_flip=False,                  # randomly flip images\n",
        "                rescale=None,                         # set rescaling factor (applied before any other transformation)\n",
        "                preprocessing_function=None,          # set function that will be applied on each input\n",
        "                data_format=None,                     # image data format, either \"channels_first\" or \"channels_last\"\n",
        "                validation_split=0)                   # fraction of images reserved for validation (strictly between 0 and 1)\n",
        "            # Compute quantities required for featurewise normalization\n",
        "            # (std, mean, and principal components if ZCA whitening is applied).\n",
        "\n",
        "    datagen.fit(x_rot_train)\n",
        "\n",
        "    history_SSL = model.fit_generator(datagen.flow(x_rot_train,y_rot_train), validation_data=(x_rot_test,y_rot_test), epochs=50, callbacks=callbacks)\n",
        "    \n",
        "    history_filepath = os.path.join(save_dir, model_name+\"_history\")\n",
        "    \n",
        "    with open(history_filepath,'wb') as fp:\n",
        "        print(\"open pickle: {}\".format(history_filepath))\n",
        "        pickle.dump(history_SSL.history,fp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8do2Jh7C-7SK"
      },
      "source": [
        "Train, Test = cifar10.load_data()\n",
        "make_ssl_backbone(Train, Test, save_dir='/content/drive/My Drive/Colab Notebooks/Self-Supervised-Learning/Pre-text_Rotation')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I0KvmK-q-9Lz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 700
        },
        "outputId": "7af4ea2c-236e-4141-ea0d-082927deac63"
      },
      "source": [
        "with open(\"/content/drive/My Drive/Colab Notebooks/Self-Supervised-Learning/Pre-text_Rotation/Restnetv1_SSL_Rotation.h5_history\",'rb') as fp:\n",
        "        history = pickle.load(fp)\n",
        "\n",
        "ssl_df = pd.DataFrame({'loss':history['loss'] + history['val_loss'], 'accuracy':history['accuracy'] + history['val_accuracy'], 'Dataset':'train'})\n",
        "ssl_df.loc[len(ssl_df)//2:,'Dataset'] = 'validation'\n",
        "ssl_df['epoch'] = np.concatenate((np.arange(len(history['loss'])),np.arange(len(history['loss']))))\n",
        "\n",
        "figure = plt.figure(figsize=(10,5))\n",
        "g = sns.lineplot(y='accuracy',x='epoch',hue='Dataset',data=ssl_df)\n",
        "g.set_title('Accuracy - Self-Supervised Image Rotation Pretext Task')\n",
        "\n",
        "figure = plt.figure(figsize=(10,5))\n",
        "g = sns.lineplot(y='loss',x='epoch',hue='Dataset',data=ssl_df)\n",
        "g.set_title('Loss - Self-Supervised Image Rotation Pretext Task')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Loss - Self-Supervised Image Rotation Pretext Task')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4tkrjz___AHB"
      },
      "source": [
        "def train_models_datasplit(x_train, y_train, x_test, y_test,\n",
        "                           batch_size = 128, epochs=50, data_augmentation=True,\n",
        "                           num_classes=10,\n",
        "                           n = 3, ssl_path=None, dataset='cifar10', input_shape=(32,32,3),\n",
        "                           data_fraction_increment=0.1, num_increments=10, random_state=689):\n",
        "     \n",
        "    ### Calcualte number of many kfolds splits - 10\n",
        "    n_splits = int(1/data_fraction_increment)\n",
        "        \n",
        "    # Convert class vectors to binary class matrices.\n",
        "    y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "    # Computed depth from supplied model parameter n\n",
        "    depth = n * 6 + 2\n",
        "\n",
        "    # Model name, depth and version\n",
        "    model_type = 'ResNet%d' % depth\n",
        "    \n",
        "    ## Ensure that data increments consist of class balanced data\n",
        "    skf = StratifiedKFold(n_splits = n_splits, random_state = random_state)\n",
        "    \n",
        "    histories = []\n",
        "    for i,index  in enumerate(skf.split(x_train, y=y_train)):\n",
        "        print(\"Training number: {}\".format(i))\n",
        "        if i > num_increments-1:\n",
        "            break\n",
        "        if i > 0:\n",
        "            test_index = np.concatenate((test_index, index[1]))\n",
        "        else:\n",
        "            test_index = index[1]\n",
        "\n",
        "        y_train_t = keras.utils.to_categorical(y_train, num_classes)[test_index]\n",
        "        \n",
        "        # if doing SSL method or not\n",
        "        if ssl_path:\n",
        "            # take already pretrained model\n",
        "            ssl_model = keras.models.load_model(ssl_path)\n",
        "            x = model = ssl_model.layers[-2].output # take model but without last layer\n",
        "            x = Dense(10, activation='softmax')(x)  # replace that last layer with new for 10 neurons - 10 classes for dataset\n",
        "            model = keras.Model(ssl_model.inputs,x)\n",
        "        else:\n",
        "            # take resnet_v1\n",
        "            model = resnet_v1(input_shape=input_shape, depth=depth)\n",
        "        \n",
        "        # compile model - does not matter if it is SSL or not\n",
        "        model.compile(loss ='categorical_crossentropy',\n",
        "                      optimizer = Adam(learning_rate=lr_schedule(0)),\n",
        "                      metrics = ['accuracy'])\n",
        "        \n",
        "        #model.summary()\n",
        "        print(model_type)\n",
        "        \n",
        "        # Prepare model model saving directory.\n",
        "        save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
        "        model_name = dataset + '_%s_model.h5' % model_type +\"_\"+ str((i/n_splits)*100)\n",
        "        \n",
        "        if not os.path.isdir(save_dir):\n",
        "            os.makedirs(save_dir)\n",
        "        filepath = os.path.join(save_dir, model_name)\n",
        "        \n",
        "        # Prepare callbacks for model saving and for learning rate adjustment.\n",
        "#         checkpoint = ModelCheckpoint(filepath=filepath,\n",
        "#                                      monitor='val_loss',\n",
        "#                                      verbose=1,\n",
        "#                                      save_best_only=True)\n",
        "        lr_scheduler = LearningRateScheduler(lr_schedule)\n",
        "        lr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1),\n",
        "                                       cooldown=0,\n",
        "                                       patience=5,\n",
        "                                       min_lr=0.5e-6)\n",
        "        callbacks = [ lr_reducer, lr_scheduler]\n",
        "        \n",
        "        # Run training, with or without data augmentation.\n",
        "        if not data_augmentation:\n",
        "            print('Not using data augmentation.')\n",
        "            model.fit(x_train, y_train,\n",
        "                      batch_size=batch_size,\n",
        "                      epochs=epochs,\n",
        "                      validation_data=(x_test, y_test),\n",
        "                      shuffle=True,\n",
        "                      callbacks=callbacks)\n",
        "        else:\n",
        "            print('Using real-time data augmentation.')\n",
        "            datagen = ImageDataGenerator(               # This will do preprocessing and realtime data augmentation:\n",
        "                featurewise_center=False,               # set input mean to 0 over the dataset\n",
        "                samplewise_center=False,                # set each sample mean to 0\n",
        "                featurewise_std_normalization=False,    # divide inputs by std of dataset\n",
        "                samplewise_std_normalization=False,     # divide each input by its std\n",
        "                zca_whitening=False,                    # apply ZCA whitening\n",
        "                zca_epsilon=1e-06,                      # epsilon for ZCA whitening\n",
        "                rotation_range=0,                       # randomly rotate images in the range (deg 0 to 180)\n",
        "                width_shift_range=0.1,                  # randomly shift images horizontally\n",
        "                height_shift_range=0.1,                 # randomly shift images vertically\n",
        "                shear_range=0.,                         # set range for random shear\n",
        "                zoom_range=0.,                          # set range for random zoom\n",
        "                channel_shift_range=0.,                 # set range for random channel shifts\n",
        "                fill_mode='nearest',                    # set mode for filling points outside the input boundaries\n",
        "                cval=0.,                                # value used for fill_mode = \"constant\"\n",
        "                horizontal_flip=True,                   # randomly flip images\n",
        "                vertical_flip=False,                    # randomly flip images\n",
        "                rescale=None,                           # set rescaling factor (applied before any other transformation)\n",
        "                preprocessing_function=None,            # set function that will be applied on each input\n",
        "                data_format=None,                       # image data format, either \"channels_first\" or \"channels_last\"\n",
        "                validation_split=0)                     # fraction of images reserved for validation (strictly between 0 and 1)\n",
        "            \n",
        "            # Compute quantities required for featurewise normalization\n",
        "            # (std, mean, and principal components if ZCA whitening is applied).\n",
        "            datagen.fit(x_train)\n",
        "           \n",
        "            # Fit the model on the batches generated by datagen.flow().\n",
        "            histories.append(model.fit_generator(datagen.flow(x_train[test_index], y_train_t, batch_size=batch_size),\n",
        "                             epochs=epochs, verbose=1, workers=4, validation_data=(x_test,y_test),\n",
        "                             callbacks=callbacks))\n",
        "            \n",
        "        # Record performance of trained model into csv files for later plotting\n",
        "        train_maxes = []\n",
        "        val_maxes = []\n",
        "        val_loss = []\n",
        "        train_loss = []\n",
        "        path_csv = '/content/drive/My Drive/Colab Notebooks/Self-Supervised-Learning/Pre-text_Rotation/'\n",
        "        \n",
        "        if ssl_path:\n",
        "            print(\" -- PATH: self_supervised\")\n",
        "            record_path = path_csv +'_self_supervised.csv'\n",
        "        else:\n",
        "            print(\" -- PATH: supervised\")\n",
        "            record_path = path_csv +'_supervised.csv'\n",
        "\n",
        "        for i in range(len(histories)):\n",
        "            val_maxes.append(max(histories[i].history['val_accuracy']))\n",
        "            train_maxes.append(max(histories[i].history['accuracy']))\n",
        "            val_loss.append(min(histories[i].history['val_loss']))\n",
        "            train_loss.append(min(histories[i].history['loss']))\n",
        "\n",
        "        print(\" -- write into csv file\")\n",
        "        pd.DataFrame({'Val_Accuracy':val_maxes,\n",
        "                      'Train_Accuracy':train_maxes,\n",
        "                      'Val_Loss':val_loss,\n",
        "                      'Train_Loss':train_loss}).to_csv(record_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x-QPTeEA_xXi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c691c44d-d340-4b88-f5de-6e9dff00cf9d"
      },
      "source": [
        "### Run experiment WITHOUT self-supervision\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "x_train, y_train, x_test, y_test = preprocess_data2(x_train, y_train, x_test, y_test)\n",
        "train_models_datasplit(x_train, y_train, x_test, y_test, data_fraction_increment=0.02, batch_size=32, num_increments=10, dataset='CIFAR10_large')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
            "  FutureWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Num of trainings: 0\n",
            "Learning rate:  0.001\n",
            "ResNet20\n",
            "Using real-time data augmentation.\n",
            "Learning rate:  0.001\n",
            "Epoch 1/50\n",
            "32/32 [==============================] - 3s 84ms/step - loss: 3.0254 - accuracy: 0.1980 - val_loss: 18.2566 - val_accuracy: 0.0902\n",
            "Learning rate:  0.001\n",
            "Epoch 2/50\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 2.0876 - accuracy: 0.2980 - val_loss: 4.7409 - val_accuracy: 0.1230\n",
            "Learning rate:  0.001\n",
            "Epoch 3/50\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 1.8999 - accuracy: 0.3470 - val_loss: 2.6003 - val_accuracy: 0.2149\n",
            "Learning rate:  0.001\n",
            "Epoch 4/50\n",
            "32/32 [==============================] - 2s 61ms/step - loss: 1.8574 - accuracy: 0.3530 - val_loss: 2.4829 - val_accuracy: 0.2513\n",
            "Learning rate:  0.001\n",
            "Epoch 5/50\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 1.7708 - accuracy: 0.4000 - val_loss: 2.5462 - val_accuracy: 0.2588\n",
            "Learning rate:  0.001\n",
            "Epoch 6/50\n",
            "32/32 [==============================] - 2s 61ms/step - loss: 1.7156 - accuracy: 0.4080 - val_loss: 3.3710 - val_accuracy: 0.1953\n",
            "Learning rate:  0.001\n",
            "Epoch 7/50\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 1.6325 - accuracy: 0.4500 - val_loss: 2.3281 - val_accuracy: 0.3241\n",
            "Learning rate:  0.001\n",
            "Epoch 8/50\n",
            "32/32 [==============================] - 2s 60ms/step - loss: 1.6473 - accuracy: 0.4390 - val_loss: 1.7931 - val_accuracy: 0.3975\n",
            "Learning rate:  0.001\n",
            "Epoch 9/50\n",
            "32/32 [==============================] - 2s 61ms/step - loss: 1.5418 - accuracy: 0.4740 - val_loss: 2.2689 - val_accuracy: 0.3418\n",
            "Learning rate:  0.001\n",
            "Epoch 10/50\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 1.5228 - accuracy: 0.4790 - val_loss: 1.7839 - val_accuracy: 0.4125\n",
            "Learning rate:  0.001\n",
            "Epoch 11/50\n",
            "32/32 [==============================] - 2s 61ms/step - loss: 1.4573 - accuracy: 0.5090 - val_loss: 2.1746 - val_accuracy: 0.3413\n",
            "Learning rate:  0.0001\n",
            "Epoch 12/50\n",
            "32/32 [==============================] - 2s 61ms/step - loss: 1.3493 - accuracy: 0.5600 - val_loss: 1.7918 - val_accuracy: 0.4097\n",
            "Learning rate:  0.0001\n",
            "Epoch 13/50\n",
            "32/32 [==============================] - 2s 60ms/step - loss: 1.3017 - accuracy: 0.5910 - val_loss: 1.6961 - val_accuracy: 0.4350\n",
            "Learning rate:  0.0001\n",
            "Epoch 14/50\n",
            "32/32 [==============================] - 2s 61ms/step - loss: 1.3010 - accuracy: 0.5930 - val_loss: 1.6417 - val_accuracy: 0.4540\n",
            "Learning rate:  0.0001\n",
            "Epoch 15/50\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 1.2803 - accuracy: 0.5990 - val_loss: 1.6439 - val_accuracy: 0.4572\n",
            "Learning rate:  0.0001\n",
            "Epoch 16/50\n",
            "32/32 [==============================] - 2s 61ms/step - loss: 1.2639 - accuracy: 0.5980 - val_loss: 1.6308 - val_accuracy: 0.4597\n",
            "Learning rate:  0.0001\n",
            "Epoch 17/50\n",
            "32/32 [==============================] - 2s 61ms/step - loss: 1.2474 - accuracy: 0.6000 - val_loss: 1.6364 - val_accuracy: 0.4615\n",
            "Learning rate:  0.0001\n",
            "Epoch 18/50\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 1.2330 - accuracy: 0.6160 - val_loss: 1.6514 - val_accuracy: 0.4569\n",
            "Learning rate:  0.0001\n",
            "Epoch 19/50\n",
            "32/32 [==============================] - 2s 61ms/step - loss: 1.2091 - accuracy: 0.6330 - val_loss: 1.6443 - val_accuracy: 0.4591\n",
            "Learning rate:  0.0001\n",
            "Epoch 20/50\n",
            "32/32 [==============================] - 2s 61ms/step - loss: 1.1933 - accuracy: 0.6310 - val_loss: 1.6339 - val_accuracy: 0.4639\n",
            "Learning rate:  0.0001\n",
            "Epoch 21/50\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 1.1971 - accuracy: 0.6350 - val_loss: 1.6365 - val_accuracy: 0.4613\n",
            "Learning rate:  1e-05\n",
            "Epoch 22/50\n",
            "32/32 [==============================] - 2s 61ms/step - loss: 1.1802 - accuracy: 0.6240 - val_loss: 1.6380 - val_accuracy: 0.4626\n",
            "Learning rate:  1e-05\n",
            "Epoch 23/50\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 1.1782 - accuracy: 0.6510 - val_loss: 1.6412 - val_accuracy: 0.4627\n",
            "Learning rate:  1e-05\n",
            "Epoch 24/50\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 1.1778 - accuracy: 0.6310 - val_loss: 1.6445 - val_accuracy: 0.4632\n",
            "Learning rate:  1e-05\n",
            "Epoch 25/50\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 1.1753 - accuracy: 0.6410 - val_loss: 1.6452 - val_accuracy: 0.4629\n",
            "Learning rate:  1e-05\n",
            "Epoch 26/50\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 1.1857 - accuracy: 0.6360 - val_loss: 1.6493 - val_accuracy: 0.4637\n",
            "Learning rate:  1e-05\n",
            "Epoch 27/50\n",
            "32/32 [==============================] - 2s 61ms/step - loss: 1.1937 - accuracy: 0.6290 - val_loss: 1.6472 - val_accuracy: 0.4625\n",
            "Learning rate:  1e-05\n",
            "Epoch 28/50\n",
            "32/32 [==============================] - 2s 61ms/step - loss: 1.1602 - accuracy: 0.6460 - val_loss: 1.6481 - val_accuracy: 0.4625\n",
            "Learning rate:  1e-05\n",
            "Epoch 29/50\n",
            "32/32 [==============================] - 2s 61ms/step - loss: 1.1711 - accuracy: 0.6590 - val_loss: 1.6493 - val_accuracy: 0.4611\n",
            "Learning rate:  1e-05\n",
            "Epoch 30/50\n",
            "32/32 [==============================] - 2s 61ms/step - loss: 1.1800 - accuracy: 0.6210 - val_loss: 1.6461 - val_accuracy: 0.4621\n",
            "Learning rate:  1e-05\n",
            "Epoch 31/50\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 1.1665 - accuracy: 0.6360 - val_loss: 1.6502 - val_accuracy: 0.4615\n",
            "Learning rate:  1e-06\n",
            "Epoch 32/50\n",
            "32/32 [==============================] - 2s 60ms/step - loss: 1.1585 - accuracy: 0.6360 - val_loss: 1.6513 - val_accuracy: 0.4619\n",
            "Learning rate:  1e-06\n",
            "Epoch 33/50\n",
            "32/32 [==============================] - 2s 61ms/step - loss: 1.1553 - accuracy: 0.6380 - val_loss: 1.6519 - val_accuracy: 0.4615\n",
            "Learning rate:  1e-06\n",
            "Epoch 34/50\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 1.1495 - accuracy: 0.6510 - val_loss: 1.6532 - val_accuracy: 0.4616\n",
            "Learning rate:  1e-06\n",
            "Epoch 35/50\n",
            "32/32 [==============================] - 2s 61ms/step - loss: 1.1783 - accuracy: 0.6380 - val_loss: 1.6552 - val_accuracy: 0.4622\n",
            "Learning rate:  1e-06\n",
            "Epoch 36/50\n",
            "32/32 [==============================] - 2s 60ms/step - loss: 1.1491 - accuracy: 0.6430 - val_loss: 1.6543 - val_accuracy: 0.4621\n",
            "Learning rate:  1e-06\n",
            "Epoch 37/50\n",
            "32/32 [==============================] - 2s 61ms/step - loss: 1.1500 - accuracy: 0.6470 - val_loss: 1.6536 - val_accuracy: 0.4622\n",
            "Learning rate:  1e-06\n",
            "Epoch 38/50\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 1.1715 - accuracy: 0.6410 - val_loss: 1.6537 - val_accuracy: 0.4614\n",
            "Learning rate:  1e-06\n",
            "Epoch 39/50\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 1.1518 - accuracy: 0.6340 - val_loss: 1.6545 - val_accuracy: 0.4617\n",
            "Learning rate:  1e-06\n",
            "Epoch 40/50\n",
            "32/32 [==============================] - 2s 60ms/step - loss: 1.1554 - accuracy: 0.6340 - val_loss: 1.6556 - val_accuracy: 0.4623\n",
            "Learning rate:  1e-06\n",
            "Epoch 41/50\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 1.1368 - accuracy: 0.6520 - val_loss: 1.6549 - val_accuracy: 0.4624\n",
            "Learning rate:  5e-07\n",
            "Epoch 42/50\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 1.1609 - accuracy: 0.6420 - val_loss: 1.6540 - val_accuracy: 0.4621\n",
            "Learning rate:  5e-07\n",
            "Epoch 43/50\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 1.1719 - accuracy: 0.6480 - val_loss: 1.6526 - val_accuracy: 0.4621\n",
            "Learning rate:  5e-07\n",
            "Epoch 44/50\n",
            "32/32 [==============================] - 2s 60ms/step - loss: 1.1582 - accuracy: 0.6580 - val_loss: 1.6539 - val_accuracy: 0.4621\n",
            "Learning rate:  5e-07\n",
            "Epoch 45/50\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 1.1489 - accuracy: 0.6340 - val_loss: 1.6544 - val_accuracy: 0.4619\n",
            "Learning rate:  5e-07\n",
            "Epoch 46/50\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 1.1705 - accuracy: 0.6540 - val_loss: 1.6548 - val_accuracy: 0.4621\n",
            "Learning rate:  5e-07\n",
            "Epoch 47/50\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 1.1650 - accuracy: 0.6480 - val_loss: 1.6553 - val_accuracy: 0.4620\n",
            "Learning rate:  5e-07\n",
            "Epoch 48/50\n",
            "32/32 [==============================] - 2s 61ms/step - loss: 1.1792 - accuracy: 0.6350 - val_loss: 1.6556 - val_accuracy: 0.4619\n",
            "Learning rate:  5e-07\n",
            "Epoch 49/50\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 1.1547 - accuracy: 0.6410 - val_loss: 1.6563 - val_accuracy: 0.4618\n",
            "Learning rate:  5e-07\n",
            "Epoch 50/50\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 1.1068 - accuracy: 0.6720 - val_loss: 1.6554 - val_accuracy: 0.4623\n",
            " -- PATH: supervised\n",
            " -- write into csv file\n",
            "Num of trainings: 1\n",
            "Learning rate:  0.001\n",
            "ResNet20\n",
            "Using real-time data augmentation.\n",
            "Learning rate:  0.001\n",
            "Epoch 1/50\n",
            "63/63 [==============================] - 3s 54ms/step - loss: 2.2698 - accuracy: 0.2590 - val_loss: 3.5722 - val_accuracy: 0.1660\n",
            "Learning rate:  0.001\n",
            "Epoch 2/50\n",
            "63/63 [==============================] - 3s 44ms/step - loss: 1.8883 - accuracy: 0.3560 - val_loss: 3.1132 - val_accuracy: 0.1687\n",
            "Learning rate:  0.001\n",
            "Epoch 3/50\n",
            "63/63 [==============================] - 3s 44ms/step - loss: 1.7728 - accuracy: 0.3915 - val_loss: 2.2817 - val_accuracy: 0.2837\n",
            "Learning rate:  0.001\n",
            "Epoch 4/50\n",
            "63/63 [==============================] - 3s 44ms/step - loss: 1.7079 - accuracy: 0.4385 - val_loss: 2.1952 - val_accuracy: 0.3055\n",
            "Learning rate:  0.001\n",
            "Epoch 5/50\n",
            "63/63 [==============================] - 3s 44ms/step - loss: 1.6261 - accuracy: 0.4700 - val_loss: 2.7808 - val_accuracy: 0.2867\n",
            "Learning rate:  0.001\n",
            "Epoch 6/50\n",
            "63/63 [==============================] - 3s 43ms/step - loss: 1.5949 - accuracy: 0.4835 - val_loss: 3.8624 - val_accuracy: 0.2623\n",
            "Learning rate:  0.001\n",
            "Epoch 7/50\n",
            "63/63 [==============================] - 3s 45ms/step - loss: 1.5471 - accuracy: 0.4905 - val_loss: 2.3699 - val_accuracy: 0.3211\n",
            "Learning rate:  0.001\n",
            "Epoch 8/50\n",
            "63/63 [==============================] - 3s 44ms/step - loss: 1.4938 - accuracy: 0.5115 - val_loss: 1.9266 - val_accuracy: 0.4071\n",
            "Learning rate:  0.001\n",
            "Epoch 9/50\n",
            "63/63 [==============================] - 3s 45ms/step - loss: 1.4574 - accuracy: 0.5375 - val_loss: 2.0145 - val_accuracy: 0.4043\n",
            "Learning rate:  0.001\n",
            "Epoch 10/50\n",
            "63/63 [==============================] - 3s 44ms/step - loss: 1.4125 - accuracy: 0.5450 - val_loss: 1.6836 - val_accuracy: 0.4699\n",
            "Learning rate:  0.001\n",
            "Epoch 11/50\n",
            "63/63 [==============================] - 3s 44ms/step - loss: 1.3928 - accuracy: 0.5485 - val_loss: 2.7520 - val_accuracy: 0.3062\n",
            "Learning rate:  0.0001\n",
            "Epoch 12/50\n",
            "63/63 [==============================] - 3s 45ms/step - loss: 1.2750 - accuracy: 0.6015 - val_loss: 1.5123 - val_accuracy: 0.5089\n",
            "Learning rate:  0.0001\n",
            "Epoch 13/50\n",
            "63/63 [==============================] - 3s 45ms/step - loss: 1.1987 - accuracy: 0.6285 - val_loss: 1.4570 - val_accuracy: 0.5282\n",
            "Learning rate:  0.0001\n",
            "Epoch 14/50\n",
            "63/63 [==============================] - 3s 44ms/step - loss: 1.1807 - accuracy: 0.6415 - val_loss: 1.4524 - val_accuracy: 0.5291\n",
            "Learning rate:  0.0001\n",
            "Epoch 15/50\n",
            "63/63 [==============================] - 3s 44ms/step - loss: 1.1862 - accuracy: 0.6390 - val_loss: 1.4741 - val_accuracy: 0.5321\n",
            "Learning rate:  0.0001\n",
            "Epoch 16/50\n",
            "63/63 [==============================] - 3s 44ms/step - loss: 1.1507 - accuracy: 0.6450 - val_loss: 1.4443 - val_accuracy: 0.5395\n",
            "Learning rate:  0.0001\n",
            "Epoch 17/50\n",
            "63/63 [==============================] - 3s 45ms/step - loss: 1.1511 - accuracy: 0.6455 - val_loss: 1.4379 - val_accuracy: 0.5405\n",
            "Learning rate:  0.0001\n",
            "Epoch 18/50\n",
            "63/63 [==============================] - 3s 44ms/step - loss: 1.1384 - accuracy: 0.6385 - val_loss: 1.4397 - val_accuracy: 0.5440\n",
            "Learning rate:  0.0001\n",
            "Epoch 19/50\n",
            "63/63 [==============================] - 3s 44ms/step - loss: 1.1162 - accuracy: 0.6655 - val_loss: 1.4469 - val_accuracy: 0.5404\n",
            "Learning rate:  0.0001\n",
            "Epoch 20/50\n",
            "63/63 [==============================] - 3s 44ms/step - loss: 1.1132 - accuracy: 0.6615 - val_loss: 1.4528 - val_accuracy: 0.5420\n",
            "Learning rate:  0.0001\n",
            "Epoch 21/50\n",
            "63/63 [==============================] - 3s 43ms/step - loss: 1.1250 - accuracy: 0.6570 - val_loss: 1.4343 - val_accuracy: 0.5437\n",
            "Learning rate:  1e-05\n",
            "Epoch 22/50\n",
            "63/63 [==============================] - 3s 44ms/step - loss: 1.0806 - accuracy: 0.6730 - val_loss: 1.4212 - val_accuracy: 0.5470\n",
            "Learning rate:  1e-05\n",
            "Epoch 23/50\n",
            "63/63 [==============================] - 3s 43ms/step - loss: 1.0781 - accuracy: 0.6775 - val_loss: 1.4184 - val_accuracy: 0.5464\n",
            "Learning rate:  1e-05\n",
            "Epoch 24/50\n",
            "63/63 [==============================] - 3s 44ms/step - loss: 1.0622 - accuracy: 0.6755 - val_loss: 1.4245 - val_accuracy: 0.5456\n",
            "Learning rate:  1e-05\n",
            "Epoch 25/50\n",
            "63/63 [==============================] - 3s 44ms/step - loss: 1.0694 - accuracy: 0.6700 - val_loss: 1.4244 - val_accuracy: 0.5470\n",
            "Learning rate:  1e-05\n",
            "Epoch 26/50\n",
            "63/63 [==============================] - 3s 44ms/step - loss: 1.0522 - accuracy: 0.6875 - val_loss: 1.4195 - val_accuracy: 0.5464\n",
            "Learning rate:  1e-05\n",
            "Epoch 27/50\n",
            "63/63 [==============================] - 3s 44ms/step - loss: 1.0770 - accuracy: 0.6735 - val_loss: 1.4187 - val_accuracy: 0.5473\n",
            "Learning rate:  1e-05\n",
            "Epoch 28/50\n",
            "63/63 [==============================] - 3s 44ms/step - loss: 1.0712 - accuracy: 0.6790 - val_loss: 1.4213 - val_accuracy: 0.5475\n",
            "Learning rate:  1e-05\n",
            "Epoch 29/50\n",
            "63/63 [==============================] - 3s 44ms/step - loss: 1.0822 - accuracy: 0.6790 - val_loss: 1.4227 - val_accuracy: 0.5469\n",
            "Learning rate:  1e-05\n",
            "Epoch 30/50\n",
            "63/63 [==============================] - 3s 44ms/step - loss: 1.0723 - accuracy: 0.6790 - val_loss: 1.4206 - val_accuracy: 0.5479\n",
            "Learning rate:  1e-05\n",
            "Epoch 31/50\n",
            "63/63 [==============================] - 3s 44ms/step - loss: 1.0726 - accuracy: 0.6785 - val_loss: 1.4229 - val_accuracy: 0.5482\n",
            "Learning rate:  1e-06\n",
            "Epoch 32/50\n",
            "63/63 [==============================] - 3s 44ms/step - loss: 1.0344 - accuracy: 0.6920 - val_loss: 1.4232 - val_accuracy: 0.5479\n",
            "Learning rate:  1e-06\n",
            "Epoch 33/50\n",
            "63/63 [==============================] - 3s 45ms/step - loss: 1.0848 - accuracy: 0.6760 - val_loss: 1.4237 - val_accuracy: 0.5484\n",
            "Learning rate:  1e-06\n",
            "Epoch 34/50\n",
            "63/63 [==============================] - 3s 44ms/step - loss: 1.0703 - accuracy: 0.6810 - val_loss: 1.4234 - val_accuracy: 0.5478\n",
            "Learning rate:  1e-06\n",
            "Epoch 35/50\n",
            "63/63 [==============================] - 3s 44ms/step - loss: 1.0764 - accuracy: 0.6770 - val_loss: 1.4225 - val_accuracy: 0.5477\n",
            "Learning rate:  1e-06\n",
            "Epoch 36/50\n",
            "63/63 [==============================] - 3s 44ms/step - loss: 1.0645 - accuracy: 0.6790 - val_loss: 1.4224 - val_accuracy: 0.5476\n",
            "Learning rate:  1e-06\n",
            "Epoch 37/50\n",
            "63/63 [==============================] - 3s 45ms/step - loss: 1.0285 - accuracy: 0.6935 - val_loss: 1.4230 - val_accuracy: 0.5473\n",
            "Learning rate:  1e-06\n",
            "Epoch 38/50\n",
            "63/63 [==============================] - 3s 44ms/step - loss: 1.0678 - accuracy: 0.6730 - val_loss: 1.4220 - val_accuracy: 0.5478\n",
            "Learning rate:  1e-06\n",
            "Epoch 39/50\n",
            "63/63 [==============================] - 3s 44ms/step - loss: 1.0733 - accuracy: 0.6770 - val_loss: 1.4227 - val_accuracy: 0.5477\n",
            "Learning rate:  1e-06\n",
            "Epoch 40/50\n",
            "63/63 [==============================] - 3s 44ms/step - loss: 1.0641 - accuracy: 0.6760 - val_loss: 1.4229 - val_accuracy: 0.5480\n",
            "Learning rate:  1e-06\n",
            "Epoch 41/50\n",
            "63/63 [==============================] - 3s 43ms/step - loss: 1.0637 - accuracy: 0.6785 - val_loss: 1.4236 - val_accuracy: 0.5481\n",
            "Learning rate:  5e-07\n",
            "Epoch 42/50\n",
            "63/63 [==============================] - 3s 44ms/step - loss: 1.0734 - accuracy: 0.6805 - val_loss: 1.4230 - val_accuracy: 0.5473\n",
            "Learning rate:  5e-07\n",
            "Epoch 43/50\n",
            "63/63 [==============================] - 3s 44ms/step - loss: 1.0542 - accuracy: 0.6865 - val_loss: 1.4225 - val_accuracy: 0.5467\n",
            "Learning rate:  5e-07\n",
            "Epoch 44/50\n",
            "63/63 [==============================] - 3s 44ms/step - loss: 1.0494 - accuracy: 0.6875 - val_loss: 1.4224 - val_accuracy: 0.5470\n",
            "Learning rate:  5e-07\n",
            "Epoch 45/50\n",
            "63/63 [==============================] - 3s 44ms/step - loss: 1.0562 - accuracy: 0.6885 - val_loss: 1.4234 - val_accuracy: 0.5476\n",
            "Learning rate:  5e-07\n",
            "Epoch 46/50\n",
            "63/63 [==============================] - 3s 44ms/step - loss: 1.0496 - accuracy: 0.6905 - val_loss: 1.4228 - val_accuracy: 0.5485\n",
            "Learning rate:  5e-07\n",
            "Epoch 47/50\n",
            "63/63 [==============================] - 3s 44ms/step - loss: 1.0546 - accuracy: 0.6840 - val_loss: 1.4223 - val_accuracy: 0.5476\n",
            "Learning rate:  5e-07\n",
            "Epoch 48/50\n",
            "63/63 [==============================] - 3s 43ms/step - loss: 1.0369 - accuracy: 0.6755 - val_loss: 1.4221 - val_accuracy: 0.5478\n",
            "Learning rate:  5e-07\n",
            "Epoch 49/50\n",
            "63/63 [==============================] - 3s 43ms/step - loss: 1.0695 - accuracy: 0.6790 - val_loss: 1.4217 - val_accuracy: 0.5472\n",
            "Learning rate:  5e-07\n",
            "Epoch 50/50\n",
            "63/63 [==============================] - 3s 43ms/step - loss: 1.0756 - accuracy: 0.6770 - val_loss: 1.4226 - val_accuracy: 0.5469\n",
            " -- PATH: supervised\n",
            " -- write into csv file\n",
            "Num of trainings: 2\n",
            "Learning rate:  0.001\n",
            "ResNet20\n",
            "Using real-time data augmentation.\n",
            "Learning rate:  0.001\n",
            "Epoch 1/50\n",
            "94/94 [==============================] - 4s 44ms/step - loss: 2.4372 - accuracy: 0.2547 - val_loss: 3.4295 - val_accuracy: 0.1594\n",
            "Learning rate:  0.001\n",
            "Epoch 2/50\n",
            "94/94 [==============================] - 3s 36ms/step - loss: 1.8380 - accuracy: 0.3710 - val_loss: 3.0735 - val_accuracy: 0.2203\n",
            "Learning rate:  0.001\n",
            "Epoch 3/50\n",
            "94/94 [==============================] - 3s 37ms/step - loss: 1.7519 - accuracy: 0.4173 - val_loss: 1.8601 - val_accuracy: 0.3882\n",
            "Learning rate:  0.001\n",
            "Epoch 4/50\n",
            "94/94 [==============================] - 3s 37ms/step - loss: 1.6410 - accuracy: 0.4623 - val_loss: 2.3188 - val_accuracy: 0.3338\n",
            "Learning rate:  0.001\n",
            "Epoch 5/50\n",
            "94/94 [==============================] - 3s 37ms/step - loss: 1.5655 - accuracy: 0.4950 - val_loss: 1.8768 - val_accuracy: 0.3889\n",
            "Learning rate:  0.001\n",
            "Epoch 6/50\n",
            "94/94 [==============================] - 3s 37ms/step - loss: 1.5276 - accuracy: 0.4993 - val_loss: 1.9057 - val_accuracy: 0.4089\n",
            "Learning rate:  0.001\n",
            "Epoch 7/50\n",
            "94/94 [==============================] - 3s 37ms/step - loss: 1.4662 - accuracy: 0.5227 - val_loss: 1.7508 - val_accuracy: 0.4656\n",
            "Learning rate:  0.001\n",
            "Epoch 8/50\n",
            "94/94 [==============================] - 3s 37ms/step - loss: 1.4439 - accuracy: 0.5407 - val_loss: 1.6086 - val_accuracy: 0.4822\n",
            "Learning rate:  0.001\n",
            "Epoch 9/50\n",
            "94/94 [==============================] - 4s 39ms/step - loss: 1.3793 - accuracy: 0.5520 - val_loss: 1.9164 - val_accuracy: 0.4347\n",
            "Learning rate:  0.001\n",
            "Epoch 10/50\n",
            "94/94 [==============================] - 4s 39ms/step - loss: 1.3552 - accuracy: 0.5720 - val_loss: 1.6695 - val_accuracy: 0.4743\n",
            "Learning rate:  0.001\n",
            "Epoch 11/50\n",
            "94/94 [==============================] - 4s 38ms/step - loss: 1.2878 - accuracy: 0.5943 - val_loss: 1.9346 - val_accuracy: 0.4319\n",
            "Learning rate:  0.0001\n",
            "Epoch 12/50\n",
            "94/94 [==============================] - 3s 37ms/step - loss: 1.1389 - accuracy: 0.6523 - val_loss: 1.3646 - val_accuracy: 0.5734\n",
            "Learning rate:  0.0001\n",
            "Epoch 13/50\n",
            "94/94 [==============================] - 3s 36ms/step - loss: 1.1040 - accuracy: 0.6573 - val_loss: 1.3183 - val_accuracy: 0.5855\n",
            "Learning rate:  0.0001\n",
            "Epoch 14/50\n",
            "94/94 [==============================] - 4s 37ms/step - loss: 1.0821 - accuracy: 0.6730 - val_loss: 1.3322 - val_accuracy: 0.5867\n",
            "Learning rate:  0.0001\n",
            "Epoch 15/50\n",
            "94/94 [==============================] - 3s 37ms/step - loss: 1.0768 - accuracy: 0.6790 - val_loss: 1.3359 - val_accuracy: 0.5879\n",
            "Learning rate:  0.0001\n",
            "Epoch 16/50\n",
            "94/94 [==============================] - 3s 37ms/step - loss: 1.0602 - accuracy: 0.6803 - val_loss: 1.3489 - val_accuracy: 0.5854\n",
            "Learning rate:  0.0001\n",
            "Epoch 17/50\n",
            "94/94 [==============================] - 3s 36ms/step - loss: 1.0450 - accuracy: 0.6907 - val_loss: 1.3498 - val_accuracy: 0.5865\n",
            "Learning rate:  0.0001\n",
            "Epoch 18/50\n",
            "94/94 [==============================] - 3s 36ms/step - loss: 1.0206 - accuracy: 0.6873 - val_loss: 1.3474 - val_accuracy: 0.5879\n",
            "Learning rate:  0.0001\n",
            "Epoch 19/50\n",
            "94/94 [==============================] - 3s 36ms/step - loss: 1.0226 - accuracy: 0.6983 - val_loss: 1.3300 - val_accuracy: 0.5876\n",
            "Learning rate:  0.0001\n",
            "Epoch 20/50\n",
            "94/94 [==============================] - 3s 36ms/step - loss: 1.0138 - accuracy: 0.6947 - val_loss: 1.3212 - val_accuracy: 0.5928\n",
            "Learning rate:  0.0001\n",
            "Epoch 21/50\n",
            "94/94 [==============================] - 3s 36ms/step - loss: 1.0117 - accuracy: 0.6970 - val_loss: 1.2893 - val_accuracy: 0.6040\n",
            "Learning rate:  1e-05\n",
            "Epoch 22/50\n",
            "94/94 [==============================] - 3s 36ms/step - loss: 0.9801 - accuracy: 0.7070 - val_loss: 1.3061 - val_accuracy: 0.5996\n",
            "Learning rate:  1e-05\n",
            "Epoch 23/50\n",
            "94/94 [==============================] - 3s 36ms/step - loss: 0.9716 - accuracy: 0.7170 - val_loss: 1.3152 - val_accuracy: 0.5985\n",
            "Learning rate:  1e-05\n",
            "Epoch 24/50\n",
            "94/94 [==============================] - 3s 37ms/step - loss: 0.9578 - accuracy: 0.7163 - val_loss: 1.3190 - val_accuracy: 0.5966\n",
            "Learning rate:  1e-05\n",
            "Epoch 25/50\n",
            "94/94 [==============================] - 3s 36ms/step - loss: 0.9666 - accuracy: 0.7187 - val_loss: 1.3175 - val_accuracy: 0.5997\n",
            "Learning rate:  1e-05\n",
            "Epoch 26/50\n",
            "94/94 [==============================] - 3s 37ms/step - loss: 0.9766 - accuracy: 0.7120 - val_loss: 1.3178 - val_accuracy: 0.6006\n",
            "Learning rate:  1e-05\n",
            "Epoch 27/50\n",
            "94/94 [==============================] - 3s 37ms/step - loss: 0.9726 - accuracy: 0.7177 - val_loss: 1.3103 - val_accuracy: 0.5988\n",
            "Learning rate:  1e-05\n",
            "Epoch 28/50\n",
            "94/94 [==============================] - 3s 36ms/step - loss: 0.9777 - accuracy: 0.7170 - val_loss: 1.3110 - val_accuracy: 0.5985\n",
            "Learning rate:  1e-05\n",
            "Epoch 29/50\n",
            "94/94 [==============================] - 3s 37ms/step - loss: 0.9633 - accuracy: 0.7137 - val_loss: 1.3119 - val_accuracy: 0.6009\n",
            "Learning rate:  1e-05\n",
            "Epoch 30/50\n",
            "94/94 [==============================] - 3s 36ms/step - loss: 0.9559 - accuracy: 0.7147 - val_loss: 1.3175 - val_accuracy: 0.5986\n",
            "Learning rate:  1e-05\n",
            "Epoch 31/50\n",
            "94/94 [==============================] - 3s 36ms/step - loss: 0.9596 - accuracy: 0.7227 - val_loss: 1.3181 - val_accuracy: 0.6000\n",
            "Learning rate:  1e-06\n",
            "Epoch 32/50\n",
            "94/94 [==============================] - 3s 37ms/step - loss: 0.9723 - accuracy: 0.7153 - val_loss: 1.3186 - val_accuracy: 0.5999\n",
            "Learning rate:  1e-06\n",
            "Epoch 33/50\n",
            "94/94 [==============================] - 3s 36ms/step - loss: 0.9608 - accuracy: 0.7157 - val_loss: 1.3181 - val_accuracy: 0.6008\n",
            "Learning rate:  1e-06\n",
            "Epoch 34/50\n",
            "94/94 [==============================] - 3s 36ms/step - loss: 0.9735 - accuracy: 0.7093 - val_loss: 1.3176 - val_accuracy: 0.6005\n",
            "Learning rate:  1e-06\n",
            "Epoch 35/50\n",
            "94/94 [==============================] - 3s 37ms/step - loss: 0.9601 - accuracy: 0.7167 - val_loss: 1.3179 - val_accuracy: 0.6008\n",
            "Learning rate:  1e-06\n",
            "Epoch 36/50\n",
            "94/94 [==============================] - 3s 36ms/step - loss: 0.9513 - accuracy: 0.7217 - val_loss: 1.3202 - val_accuracy: 0.6001\n",
            "Learning rate:  1e-06\n",
            "Epoch 37/50\n",
            "94/94 [==============================] - 3s 37ms/step - loss: 0.9379 - accuracy: 0.7220 - val_loss: 1.3197 - val_accuracy: 0.6009\n",
            "Learning rate:  1e-06\n",
            "Epoch 38/50\n",
            "94/94 [==============================] - 3s 36ms/step - loss: 0.9599 - accuracy: 0.7207 - val_loss: 1.3188 - val_accuracy: 0.6005\n",
            "Learning rate:  1e-06\n",
            "Epoch 39/50\n",
            "94/94 [==============================] - 3s 36ms/step - loss: 0.9548 - accuracy: 0.7153 - val_loss: 1.3203 - val_accuracy: 0.6010\n",
            "Learning rate:  1e-06\n",
            "Epoch 40/50\n",
            "94/94 [==============================] - 3s 37ms/step - loss: 0.9552 - accuracy: 0.7160 - val_loss: 1.3179 - val_accuracy: 0.6007\n",
            "Learning rate:  1e-06\n",
            "Epoch 41/50\n",
            "94/94 [==============================] - 3s 36ms/step - loss: 0.9661 - accuracy: 0.7113 - val_loss: 1.3172 - val_accuracy: 0.6005\n",
            "Learning rate:  5e-07\n",
            "Epoch 42/50\n",
            "94/94 [==============================] - 3s 36ms/step - loss: 0.9678 - accuracy: 0.7123 - val_loss: 1.3171 - val_accuracy: 0.6006\n",
            "Learning rate:  5e-07\n",
            "Epoch 43/50\n",
            "94/94 [==============================] - 3s 36ms/step - loss: 0.9553 - accuracy: 0.7167 - val_loss: 1.3166 - val_accuracy: 0.6010\n",
            "Learning rate:  5e-07\n",
            "Epoch 44/50\n",
            "94/94 [==============================] - 3s 37ms/step - loss: 0.9568 - accuracy: 0.7203 - val_loss: 1.3192 - val_accuracy: 0.6006\n",
            "Learning rate:  5e-07\n",
            "Epoch 45/50\n",
            "94/94 [==============================] - 3s 35ms/step - loss: 0.9544 - accuracy: 0.7233 - val_loss: 1.3194 - val_accuracy: 0.5998\n",
            "Learning rate:  5e-07\n",
            "Epoch 46/50\n",
            "94/94 [==============================] - 3s 36ms/step - loss: 0.9591 - accuracy: 0.7117 - val_loss: 1.3197 - val_accuracy: 0.5998\n",
            "Learning rate:  5e-07\n",
            "Epoch 47/50\n",
            "94/94 [==============================] - 3s 36ms/step - loss: 0.9518 - accuracy: 0.7243 - val_loss: 1.3179 - val_accuracy: 0.6004\n",
            "Learning rate:  5e-07\n",
            "Epoch 48/50\n",
            "94/94 [==============================] - 3s 36ms/step - loss: 0.9486 - accuracy: 0.7123 - val_loss: 1.3176 - val_accuracy: 0.6007\n",
            "Learning rate:  5e-07\n",
            "Epoch 49/50\n",
            "94/94 [==============================] - 3s 36ms/step - loss: 0.9545 - accuracy: 0.7153 - val_loss: 1.3197 - val_accuracy: 0.6007\n",
            "Learning rate:  5e-07\n",
            "Epoch 50/50\n",
            "94/94 [==============================] - 3s 37ms/step - loss: 0.9425 - accuracy: 0.7207 - val_loss: 1.3185 - val_accuracy: 0.6005\n",
            " -- PATH: supervised\n",
            " -- write into csv file\n",
            "Num of trainings: 3\n",
            "Learning rate:  0.001\n",
            "ResNet20\n",
            "Using real-time data augmentation.\n",
            "Learning rate:  0.001\n",
            "Epoch 1/50\n",
            "125/125 [==============================] - 5s 39ms/step - loss: 2.2280 - accuracy: 0.2767 - val_loss: 2.0736 - val_accuracy: 0.2882\n",
            "Learning rate:  0.001\n",
            "Epoch 2/50\n",
            "125/125 [==============================] - 4s 33ms/step - loss: 1.8212 - accuracy: 0.3733 - val_loss: 2.9661 - val_accuracy: 0.2013\n",
            "Learning rate:  0.001\n",
            "Epoch 3/50\n",
            "125/125 [==============================] - 4s 33ms/step - loss: 1.6888 - accuracy: 0.4342 - val_loss: 2.0998 - val_accuracy: 0.3489\n",
            "Learning rate:  0.001\n",
            "Epoch 4/50\n",
            "125/125 [==============================] - 4s 33ms/step - loss: 1.6121 - accuracy: 0.4745 - val_loss: 2.6587 - val_accuracy: 0.3371\n",
            "Learning rate:  0.001\n",
            "Epoch 5/50\n",
            "125/125 [==============================] - 4s 33ms/step - loss: 1.5428 - accuracy: 0.5008 - val_loss: 2.3343 - val_accuracy: 0.3182\n",
            "Learning rate:  0.001\n",
            "Epoch 6/50\n",
            "125/125 [==============================] - 4s 33ms/step - loss: 1.4692 - accuracy: 0.5165 - val_loss: 1.9603 - val_accuracy: 0.4119\n",
            "Learning rate:  0.001\n",
            "Epoch 7/50\n",
            "125/125 [==============================] - 4s 33ms/step - loss: 1.4268 - accuracy: 0.5450 - val_loss: 1.6244 - val_accuracy: 0.4968\n",
            "Learning rate:  0.001\n",
            "Epoch 8/50\n",
            "125/125 [==============================] - 4s 33ms/step - loss: 1.3658 - accuracy: 0.5675 - val_loss: 2.3048 - val_accuracy: 0.3941\n",
            "Learning rate:  0.001\n",
            "Epoch 9/50\n",
            "125/125 [==============================] - 4s 32ms/step - loss: 1.3327 - accuracy: 0.5732 - val_loss: 1.6918 - val_accuracy: 0.4960\n",
            "Learning rate:  0.001\n",
            "Epoch 10/50\n",
            "125/125 [==============================] - 4s 33ms/step - loss: 1.2812 - accuracy: 0.5900 - val_loss: 1.8137 - val_accuracy: 0.4736\n",
            "Learning rate:  0.001\n",
            "Epoch 11/50\n",
            "125/125 [==============================] - 4s 33ms/step - loss: 1.2824 - accuracy: 0.5993 - val_loss: 1.6564 - val_accuracy: 0.4974\n",
            "Learning rate:  0.0001\n",
            "Epoch 12/50\n",
            "125/125 [==============================] - 4s 33ms/step - loss: 1.1218 - accuracy: 0.6600 - val_loss: 1.2237 - val_accuracy: 0.6232\n",
            "Learning rate:  0.0001\n",
            "Epoch 13/50\n",
            "125/125 [==============================] - 4s 33ms/step - loss: 1.0736 - accuracy: 0.6768 - val_loss: 1.2183 - val_accuracy: 0.6221\n",
            "Learning rate:  0.0001\n",
            "Epoch 14/50\n",
            "125/125 [==============================] - 4s 32ms/step - loss: 1.0484 - accuracy: 0.6812 - val_loss: 1.2158 - val_accuracy: 0.6263\n",
            "Learning rate:  0.0001\n",
            "Epoch 15/50\n",
            "125/125 [==============================] - 4s 33ms/step - loss: 1.0400 - accuracy: 0.6852 - val_loss: 1.2435 - val_accuracy: 0.6179\n",
            "Learning rate:  0.0001\n",
            "Epoch 16/50\n",
            "125/125 [==============================] - 4s 32ms/step - loss: 1.0149 - accuracy: 0.7060 - val_loss: 1.2035 - val_accuracy: 0.6290\n",
            "Learning rate:  0.0001\n",
            "Epoch 17/50\n",
            "125/125 [==============================] - 4s 32ms/step - loss: 1.0105 - accuracy: 0.6923 - val_loss: 1.2268 - val_accuracy: 0.6244\n",
            "Learning rate:  0.0001\n",
            "Epoch 18/50\n",
            "125/125 [==============================] - 4s 32ms/step - loss: 0.9986 - accuracy: 0.7010 - val_loss: 1.2167 - val_accuracy: 0.6284\n",
            "Learning rate:  0.0001\n",
            "Epoch 19/50\n",
            "125/125 [==============================] - 4s 32ms/step - loss: 0.9843 - accuracy: 0.7175 - val_loss: 1.2477 - val_accuracy: 0.6281\n",
            "Learning rate:  0.0001\n",
            "Epoch 20/50\n",
            "125/125 [==============================] - 4s 32ms/step - loss: 0.9829 - accuracy: 0.7015 - val_loss: 1.1983 - val_accuracy: 0.6343\n",
            "Learning rate:  0.0001\n",
            "Epoch 21/50\n",
            "125/125 [==============================] - 4s 32ms/step - loss: 0.9544 - accuracy: 0.7243 - val_loss: 1.2137 - val_accuracy: 0.6329\n",
            "Learning rate:  1e-05\n",
            "Epoch 22/50\n",
            "125/125 [==============================] - 4s 32ms/step - loss: 0.9396 - accuracy: 0.7280 - val_loss: 1.1958 - val_accuracy: 0.6416\n",
            "Learning rate:  1e-05\n",
            "Epoch 23/50\n",
            "125/125 [==============================] - 4s 33ms/step - loss: 0.9432 - accuracy: 0.7240 - val_loss: 1.1961 - val_accuracy: 0.6394\n",
            "Learning rate:  1e-05\n",
            "Epoch 24/50\n",
            "125/125 [==============================] - 4s 33ms/step - loss: 0.9402 - accuracy: 0.7222 - val_loss: 1.2004 - val_accuracy: 0.6410\n",
            "Learning rate:  1e-05\n",
            "Epoch 25/50\n",
            "125/125 [==============================] - 4s 33ms/step - loss: 0.9271 - accuracy: 0.7237 - val_loss: 1.2041 - val_accuracy: 0.6389\n",
            "Learning rate:  1e-05\n",
            "Epoch 26/50\n",
            "125/125 [==============================] - 4s 32ms/step - loss: 0.9517 - accuracy: 0.7203 - val_loss: 1.1995 - val_accuracy: 0.6415\n",
            "Learning rate:  1e-05\n",
            "Epoch 27/50\n",
            "125/125 [==============================] - 4s 32ms/step - loss: 0.9400 - accuracy: 0.7260 - val_loss: 1.1957 - val_accuracy: 0.6424\n",
            "Learning rate:  1e-05\n",
            "Epoch 28/50\n",
            "125/125 [==============================] - 4s 32ms/step - loss: 0.9297 - accuracy: 0.7370 - val_loss: 1.1989 - val_accuracy: 0.6426\n",
            "Learning rate:  1e-05\n",
            "Epoch 29/50\n",
            "125/125 [==============================] - 4s 32ms/step - loss: 0.9364 - accuracy: 0.7255 - val_loss: 1.2021 - val_accuracy: 0.6421\n",
            "Learning rate:  1e-05\n",
            "Epoch 30/50\n",
            "125/125 [==============================] - 4s 33ms/step - loss: 0.9397 - accuracy: 0.7325 - val_loss: 1.2005 - val_accuracy: 0.6408\n",
            "Learning rate:  1e-05\n",
            "Epoch 31/50\n",
            "125/125 [==============================] - 4s 32ms/step - loss: 0.9220 - accuracy: 0.7330 - val_loss: 1.1995 - val_accuracy: 0.6433\n",
            "Learning rate:  1e-06\n",
            "Epoch 32/50\n",
            "125/125 [==============================] - 4s 32ms/step - loss: 0.9199 - accuracy: 0.7315 - val_loss: 1.2016 - val_accuracy: 0.6427\n",
            "Learning rate:  1e-06\n",
            "Epoch 33/50\n",
            "125/125 [==============================] - 4s 33ms/step - loss: 0.9315 - accuracy: 0.7260 - val_loss: 1.2023 - val_accuracy: 0.6421\n",
            "Learning rate:  1e-06\n",
            "Epoch 34/50\n",
            "125/125 [==============================] - 4s 32ms/step - loss: 0.9312 - accuracy: 0.7320 - val_loss: 1.1996 - val_accuracy: 0.6436\n",
            "Learning rate:  1e-06\n",
            "Epoch 35/50\n",
            "125/125 [==============================] - 4s 32ms/step - loss: 0.9137 - accuracy: 0.7310 - val_loss: 1.2001 - val_accuracy: 0.6438\n",
            "Learning rate:  1e-06\n",
            "Epoch 36/50\n",
            "125/125 [==============================] - 4s 32ms/step - loss: 0.9397 - accuracy: 0.7222 - val_loss: 1.2028 - val_accuracy: 0.6425\n",
            "Learning rate:  1e-06\n",
            "Epoch 37/50\n",
            "125/125 [==============================] - 4s 32ms/step - loss: 0.9412 - accuracy: 0.7283 - val_loss: 1.2025 - val_accuracy: 0.6429\n",
            "Learning rate:  1e-06\n",
            "Epoch 38/50\n",
            "125/125 [==============================] - 4s 32ms/step - loss: 0.9291 - accuracy: 0.7350 - val_loss: 1.1997 - val_accuracy: 0.6439\n",
            "Learning rate:  1e-06\n",
            "Epoch 39/50\n",
            "125/125 [==============================] - 4s 34ms/step - loss: 0.9103 - accuracy: 0.7390 - val_loss: 1.2010 - val_accuracy: 0.6430\n",
            "Learning rate:  1e-06\n",
            "Epoch 40/50\n",
            "125/125 [==============================] - 4s 34ms/step - loss: 0.9192 - accuracy: 0.7377 - val_loss: 1.2022 - val_accuracy: 0.6434\n",
            "Learning rate:  1e-06\n",
            "Epoch 41/50\n",
            "125/125 [==============================] - 4s 33ms/step - loss: 0.9397 - accuracy: 0.7215 - val_loss: 1.2001 - val_accuracy: 0.6432\n",
            "Learning rate:  5e-07\n",
            "Epoch 42/50\n",
            "125/125 [==============================] - 4s 32ms/step - loss: 0.9245 - accuracy: 0.7300 - val_loss: 1.2002 - val_accuracy: 0.6426\n",
            "Learning rate:  5e-07\n",
            "Epoch 43/50\n",
            "125/125 [==============================] - 4s 33ms/step - loss: 0.9397 - accuracy: 0.7347 - val_loss: 1.2017 - val_accuracy: 0.6426\n",
            "Learning rate:  5e-07\n",
            "Epoch 44/50\n",
            "125/125 [==============================] - 4s 33ms/step - loss: 0.9211 - accuracy: 0.7283 - val_loss: 1.2014 - val_accuracy: 0.6435\n",
            "Learning rate:  5e-07\n",
            "Epoch 45/50\n",
            "125/125 [==============================] - 4s 32ms/step - loss: 0.9333 - accuracy: 0.7247 - val_loss: 1.1998 - val_accuracy: 0.6432\n",
            "Learning rate:  5e-07\n",
            "Epoch 46/50\n",
            "125/125 [==============================] - 4s 32ms/step - loss: 0.9238 - accuracy: 0.7322 - val_loss: 1.2021 - val_accuracy: 0.6421\n",
            "Learning rate:  5e-07\n",
            "Epoch 47/50\n",
            "125/125 [==============================] - 4s 32ms/step - loss: 0.9249 - accuracy: 0.7287 - val_loss: 1.2022 - val_accuracy: 0.6426\n",
            "Learning rate:  5e-07\n",
            "Epoch 48/50\n",
            "125/125 [==============================] - 4s 32ms/step - loss: 0.9177 - accuracy: 0.7312 - val_loss: 1.1997 - val_accuracy: 0.6433\n",
            "Learning rate:  5e-07\n",
            "Epoch 49/50\n",
            "125/125 [==============================] - 4s 32ms/step - loss: 0.9180 - accuracy: 0.7370 - val_loss: 1.2019 - val_accuracy: 0.6428\n",
            "Learning rate:  5e-07\n",
            "Epoch 50/50\n",
            "125/125 [==============================] - 4s 32ms/step - loss: 0.9381 - accuracy: 0.7240 - val_loss: 1.2008 - val_accuracy: 0.6422\n",
            " -- PATH: supervised\n",
            " -- write into csv file\n",
            "Num of trainings: 4\n",
            "Learning rate:  0.001\n",
            "ResNet20\n",
            "Using real-time data augmentation.\n",
            "Learning rate:  0.001\n",
            "Epoch 1/50\n",
            "157/157 [==============================] - 5s 34ms/step - loss: 2.1358 - accuracy: 0.2990 - val_loss: 2.1999 - val_accuracy: 0.2365\n",
            "Learning rate:  0.001\n",
            "Epoch 2/50\n",
            "157/157 [==============================] - 5s 31ms/step - loss: 1.7484 - accuracy: 0.4162 - val_loss: 1.8408 - val_accuracy: 0.4012\n",
            "Learning rate:  0.001\n",
            "Epoch 3/50\n",
            "157/157 [==============================] - 5s 30ms/step - loss: 1.6199 - accuracy: 0.4668 - val_loss: 1.6848 - val_accuracy: 0.4648\n",
            "Learning rate:  0.001\n",
            "Epoch 4/50\n",
            "157/157 [==============================] - 5s 30ms/step - loss: 1.5421 - accuracy: 0.4944 - val_loss: 2.6634 - val_accuracy: 0.3450\n",
            "Learning rate:  0.001\n",
            "Epoch 5/50\n",
            "157/157 [==============================] - 5s 30ms/step - loss: 1.4654 - accuracy: 0.5290 - val_loss: 1.6082 - val_accuracy: 0.4863\n",
            "Learning rate:  0.001\n",
            "Epoch 6/50\n",
            "157/157 [==============================] - 5s 30ms/step - loss: 1.3729 - accuracy: 0.5582 - val_loss: 1.7937 - val_accuracy: 0.4713\n",
            "Learning rate:  0.001\n",
            "Epoch 7/50\n",
            "157/157 [==============================] - 5s 31ms/step - loss: 1.3414 - accuracy: 0.5714 - val_loss: 1.6505 - val_accuracy: 0.4764\n",
            "Learning rate:  0.001\n",
            "Epoch 8/50\n",
            "157/157 [==============================] - 5s 30ms/step - loss: 1.2663 - accuracy: 0.6034 - val_loss: 2.5491 - val_accuracy: 0.3609\n",
            "Learning rate:  0.001\n",
            "Epoch 9/50\n",
            "157/157 [==============================] - 5s 30ms/step - loss: 1.2348 - accuracy: 0.6082 - val_loss: 1.6801 - val_accuracy: 0.5226\n",
            "Learning rate:  0.001\n",
            "Epoch 10/50\n",
            "157/157 [==============================] - 5s 31ms/step - loss: 1.2105 - accuracy: 0.6356 - val_loss: 1.7429 - val_accuracy: 0.4940\n",
            "Learning rate:  0.001\n",
            "Epoch 11/50\n",
            "157/157 [==============================] - 5s 31ms/step - loss: 1.1604 - accuracy: 0.6470 - val_loss: 1.3766 - val_accuracy: 0.5749\n",
            "Learning rate:  0.0001\n",
            "Epoch 12/50\n",
            "157/157 [==============================] - 5s 30ms/step - loss: 1.0365 - accuracy: 0.6912 - val_loss: 1.1466 - val_accuracy: 0.6521\n",
            "Learning rate:  0.0001\n",
            "Epoch 13/50\n",
            "157/157 [==============================] - 5s 30ms/step - loss: 0.9787 - accuracy: 0.7138 - val_loss: 1.1495 - val_accuracy: 0.6514\n",
            "Learning rate:  0.0001\n",
            "Epoch 14/50\n",
            "157/157 [==============================] - 5s 30ms/step - loss: 0.9503 - accuracy: 0.7230 - val_loss: 1.1639 - val_accuracy: 0.6449\n",
            "Learning rate:  0.0001\n",
            "Epoch 15/50\n",
            "157/157 [==============================] - 5s 31ms/step - loss: 0.9525 - accuracy: 0.7306 - val_loss: 1.1255 - val_accuracy: 0.6580\n",
            "Learning rate:  0.0001\n",
            "Epoch 16/50\n",
            "157/157 [==============================] - 5s 30ms/step - loss: 0.9383 - accuracy: 0.7264 - val_loss: 1.1234 - val_accuracy: 0.6640\n",
            "Learning rate:  0.0001\n",
            "Epoch 17/50\n",
            "157/157 [==============================] - 5s 30ms/step - loss: 0.9220 - accuracy: 0.7364 - val_loss: 1.1192 - val_accuracy: 0.6649\n",
            "Learning rate:  0.0001\n",
            "Epoch 18/50\n",
            "157/157 [==============================] - 5s 30ms/step - loss: 0.9211 - accuracy: 0.7318 - val_loss: 1.0908 - val_accuracy: 0.6699\n",
            "Learning rate:  0.0001\n",
            "Epoch 19/50\n",
            "157/157 [==============================] - 5s 30ms/step - loss: 0.8911 - accuracy: 0.7446 - val_loss: 1.1150 - val_accuracy: 0.6640\n",
            "Learning rate:  0.0001\n",
            "Epoch 20/50\n",
            "157/157 [==============================] - 5s 30ms/step - loss: 0.8890 - accuracy: 0.7464 - val_loss: 1.1138 - val_accuracy: 0.6687\n",
            "Learning rate:  0.0001\n",
            "Epoch 21/50\n",
            "157/157 [==============================] - 5s 30ms/step - loss: 0.8784 - accuracy: 0.7472 - val_loss: 1.1768 - val_accuracy: 0.6537\n",
            "Learning rate:  1e-05\n",
            "Epoch 22/50\n",
            "157/157 [==============================] - 5s 30ms/step - loss: 0.8540 - accuracy: 0.7576 - val_loss: 1.1137 - val_accuracy: 0.6673\n",
            "Learning rate:  1e-05\n",
            "Epoch 23/50\n",
            "157/157 [==============================] - 5s 30ms/step - loss: 0.8523 - accuracy: 0.7610 - val_loss: 1.0985 - val_accuracy: 0.6742\n",
            "Learning rate:  1e-05\n",
            "Epoch 24/50\n",
            "157/157 [==============================] - 5s 30ms/step - loss: 0.8484 - accuracy: 0.7574 - val_loss: 1.1067 - val_accuracy: 0.6719\n",
            "Learning rate:  1e-05\n",
            "Epoch 25/50\n",
            "157/157 [==============================] - 5s 31ms/step - loss: 0.8606 - accuracy: 0.7522 - val_loss: 1.1030 - val_accuracy: 0.6729\n",
            "Learning rate:  1e-05\n",
            "Epoch 26/50\n",
            "157/157 [==============================] - 5s 31ms/step - loss: 0.8394 - accuracy: 0.7666 - val_loss: 1.1031 - val_accuracy: 0.6706\n",
            "Learning rate:  1e-05\n",
            "Epoch 27/50\n",
            "157/157 [==============================] - 5s 31ms/step - loss: 0.8271 - accuracy: 0.7700 - val_loss: 1.1029 - val_accuracy: 0.6724\n",
            "Learning rate:  1e-05\n",
            "Epoch 28/50\n",
            "157/157 [==============================] - 5s 31ms/step - loss: 0.8438 - accuracy: 0.7652 - val_loss: 1.0997 - val_accuracy: 0.6745\n",
            "Learning rate:  1e-05\n",
            "Epoch 29/50\n",
            "157/157 [==============================] - 5s 30ms/step - loss: 0.8452 - accuracy: 0.7596 - val_loss: 1.0995 - val_accuracy: 0.6737\n",
            "Learning rate:  1e-05\n",
            "Epoch 30/50\n",
            "157/157 [==============================] - 5s 30ms/step - loss: 0.8446 - accuracy: 0.7586 - val_loss: 1.1025 - val_accuracy: 0.6727\n",
            "Learning rate:  1e-05\n",
            "Epoch 31/50\n",
            "157/157 [==============================] - 5s 30ms/step - loss: 0.8423 - accuracy: 0.7658 - val_loss: 1.0984 - val_accuracy: 0.6734\n",
            "Learning rate:  1e-06\n",
            "Epoch 32/50\n",
            "157/157 [==============================] - 5s 30ms/step - loss: 0.8420 - accuracy: 0.7622 - val_loss: 1.1024 - val_accuracy: 0.6724\n",
            "Learning rate:  1e-06\n",
            "Epoch 33/50\n",
            "157/157 [==============================] - 5s 30ms/step - loss: 0.8399 - accuracy: 0.7642 - val_loss: 1.1023 - val_accuracy: 0.6723\n",
            "Learning rate:  1e-06\n",
            "Epoch 34/50\n",
            "157/157 [==============================] - 5s 31ms/step - loss: 0.8335 - accuracy: 0.7632 - val_loss: 1.1005 - val_accuracy: 0.6730\n",
            "Learning rate:  1e-06\n",
            "Epoch 35/50\n",
            "157/157 [==============================] - 5s 30ms/step - loss: 0.8466 - accuracy: 0.7596 - val_loss: 1.1043 - val_accuracy: 0.6722\n",
            "Learning rate:  1e-06\n",
            "Epoch 36/50\n",
            "157/157 [==============================] - 5s 31ms/step - loss: 0.8488 - accuracy: 0.7628 - val_loss: 1.1022 - val_accuracy: 0.6725\n",
            "Learning rate:  1e-06\n",
            "Epoch 37/50\n",
            "157/157 [==============================] - 5s 30ms/step - loss: 0.8325 - accuracy: 0.7656 - val_loss: 1.1027 - val_accuracy: 0.6723\n",
            "Learning rate:  1e-06\n",
            "Epoch 38/50\n",
            "157/157 [==============================] - 5s 30ms/step - loss: 0.8383 - accuracy: 0.7614 - val_loss: 1.1005 - val_accuracy: 0.6732\n",
            "Learning rate:  1e-06\n",
            "Epoch 39/50\n",
            "157/157 [==============================] - 5s 31ms/step - loss: 0.8357 - accuracy: 0.7728 - val_loss: 1.1016 - val_accuracy: 0.6729\n",
            "Learning rate:  1e-06\n",
            "Epoch 40/50\n",
            "157/157 [==============================] - 5s 31ms/step - loss: 0.8417 - accuracy: 0.7660 - val_loss: 1.1013 - val_accuracy: 0.6729\n",
            "Learning rate:  1e-06\n",
            "Epoch 41/50\n",
            "157/157 [==============================] - 5s 31ms/step - loss: 0.8514 - accuracy: 0.7600 - val_loss: 1.1016 - val_accuracy: 0.6729\n",
            "Learning rate:  5e-07\n",
            "Epoch 42/50\n",
            "157/157 [==============================] - 5s 30ms/step - loss: 0.8368 - accuracy: 0.7718 - val_loss: 1.1005 - val_accuracy: 0.6733\n",
            "Learning rate:  5e-07\n",
            "Epoch 43/50\n",
            "157/157 [==============================] - 5s 31ms/step - loss: 0.8291 - accuracy: 0.7716 - val_loss: 1.0995 - val_accuracy: 0.6733\n",
            "Learning rate:  5e-07\n",
            "Epoch 44/50\n",
            "157/157 [==============================] - 5s 31ms/step - loss: 0.8492 - accuracy: 0.7538 - val_loss: 1.1023 - val_accuracy: 0.6728\n",
            "Learning rate:  5e-07\n",
            "Epoch 45/50\n",
            "157/157 [==============================] - 5s 31ms/step - loss: 0.8485 - accuracy: 0.7648 - val_loss: 1.1040 - val_accuracy: 0.6722\n",
            "Learning rate:  5e-07\n",
            "Epoch 46/50\n",
            "157/157 [==============================] - 5s 31ms/step - loss: 0.8325 - accuracy: 0.7648 - val_loss: 1.1037 - val_accuracy: 0.6722\n",
            "Learning rate:  5e-07\n",
            "Epoch 47/50\n",
            "157/157 [==============================] - 5s 31ms/step - loss: 0.8398 - accuracy: 0.7620 - val_loss: 1.1029 - val_accuracy: 0.6726\n",
            "Learning rate:  5e-07\n",
            "Epoch 48/50\n",
            "157/157 [==============================] - 5s 32ms/step - loss: 0.8393 - accuracy: 0.7620 - val_loss: 1.0985 - val_accuracy: 0.6747\n",
            "Learning rate:  5e-07\n",
            "Epoch 49/50\n",
            "157/157 [==============================] - 5s 31ms/step - loss: 0.8363 - accuracy: 0.7648 - val_loss: 1.1012 - val_accuracy: 0.6730\n",
            "Learning rate:  5e-07\n",
            "Epoch 50/50\n",
            "157/157 [==============================] - 5s 31ms/step - loss: 0.8459 - accuracy: 0.7590 - val_loss: 1.1006 - val_accuracy: 0.6742\n",
            " -- PATH: supervised\n",
            " -- write into csv file\n",
            "Num of trainings: 5\n",
            "Learning rate:  0.001\n",
            "ResNet20\n",
            "Using real-time data augmentation.\n",
            "Learning rate:  0.001\n",
            "Epoch 1/50\n",
            "188/188 [==============================] - 6s 33ms/step - loss: 2.0547 - accuracy: 0.3225 - val_loss: 2.2771 - val_accuracy: 0.2655\n",
            "Learning rate:  0.001\n",
            "Epoch 2/50\n",
            "188/188 [==============================] - 6s 30ms/step - loss: 1.7373 - accuracy: 0.4243 - val_loss: 2.1839 - val_accuracy: 0.3470\n",
            "Learning rate:  0.001\n",
            "Epoch 3/50\n",
            "188/188 [==============================] - 6s 31ms/step - loss: 1.5859 - accuracy: 0.4772 - val_loss: 2.3327 - val_accuracy: 0.3764\n",
            "Learning rate:  0.001\n",
            "Epoch 4/50\n",
            "188/188 [==============================] - 6s 30ms/step - loss: 1.5181 - accuracy: 0.5055 - val_loss: 1.6699 - val_accuracy: 0.4764\n",
            "Learning rate:  0.001\n",
            "Epoch 5/50\n",
            "188/188 [==============================] - 6s 30ms/step - loss: 1.4295 - accuracy: 0.5433 - val_loss: 1.6736 - val_accuracy: 0.4671\n",
            "Learning rate:  0.001\n",
            "Epoch 6/50\n",
            "188/188 [==============================] - 6s 29ms/step - loss: 1.3719 - accuracy: 0.5603 - val_loss: 1.7386 - val_accuracy: 0.4654\n",
            "Learning rate:  0.001\n",
            "Epoch 7/50\n",
            "188/188 [==============================] - 6s 30ms/step - loss: 1.3007 - accuracy: 0.5917 - val_loss: 1.6529 - val_accuracy: 0.4754\n",
            "Learning rate:  0.001\n",
            "Epoch 8/50\n",
            "188/188 [==============================] - 6s 29ms/step - loss: 1.2665 - accuracy: 0.6008 - val_loss: 1.3833 - val_accuracy: 0.5673\n",
            "Learning rate:  0.001\n",
            "Epoch 9/50\n",
            "188/188 [==============================] - 5s 29ms/step - loss: 1.2150 - accuracy: 0.6212 - val_loss: 1.5707 - val_accuracy: 0.5288\n",
            "Learning rate:  0.001\n",
            "Epoch 10/50\n",
            "188/188 [==============================] - 5s 29ms/step - loss: 1.1639 - accuracy: 0.6423 - val_loss: 1.7366 - val_accuracy: 0.5197\n",
            "Learning rate:  0.001\n",
            "Epoch 11/50\n",
            "188/188 [==============================] - 5s 29ms/step - loss: 1.1415 - accuracy: 0.6550 - val_loss: 1.7902 - val_accuracy: 0.5110\n",
            "Learning rate:  0.0001\n",
            "Epoch 12/50\n",
            "188/188 [==============================] - 5s 29ms/step - loss: 1.0146 - accuracy: 0.6997 - val_loss: 1.1499 - val_accuracy: 0.6549\n",
            "Learning rate:  0.0001\n",
            "Epoch 13/50\n",
            "188/188 [==============================] - 5s 29ms/step - loss: 0.9728 - accuracy: 0.7213 - val_loss: 1.0711 - val_accuracy: 0.6808\n",
            "Learning rate:  0.0001\n",
            "Epoch 14/50\n",
            "188/188 [==============================] - 5s 29ms/step - loss: 0.9400 - accuracy: 0.7268 - val_loss: 1.1118 - val_accuracy: 0.6681\n",
            "Learning rate:  0.0001\n",
            "Epoch 15/50\n",
            "188/188 [==============================] - 5s 29ms/step - loss: 0.9409 - accuracy: 0.7258 - val_loss: 1.0692 - val_accuracy: 0.6816\n",
            "Learning rate:  0.0001\n",
            "Epoch 16/50\n",
            "188/188 [==============================] - 6s 29ms/step - loss: 0.9159 - accuracy: 0.7367 - val_loss: 1.0899 - val_accuracy: 0.6758\n",
            "Learning rate:  0.0001\n",
            "Epoch 17/50\n",
            "188/188 [==============================] - 6s 29ms/step - loss: 0.9091 - accuracy: 0.7388 - val_loss: 1.0846 - val_accuracy: 0.6778\n",
            "Learning rate:  0.0001\n",
            "Epoch 18/50\n",
            "188/188 [==============================] - 5s 29ms/step - loss: 0.9084 - accuracy: 0.7353 - val_loss: 1.0801 - val_accuracy: 0.6806\n",
            "Learning rate:  0.0001\n",
            "Epoch 19/50\n",
            "188/188 [==============================] - 6s 29ms/step - loss: 0.8987 - accuracy: 0.7430 - val_loss: 1.1039 - val_accuracy: 0.6722\n",
            "Learning rate:  0.0001\n",
            "Epoch 20/50\n",
            "188/188 [==============================] - 5s 29ms/step - loss: 0.8747 - accuracy: 0.7457 - val_loss: 1.0840 - val_accuracy: 0.6829\n",
            "Learning rate:  0.0001\n",
            "Epoch 21/50\n",
            "188/188 [==============================] - 6s 29ms/step - loss: 0.8673 - accuracy: 0.7563 - val_loss: 1.0597 - val_accuracy: 0.6903\n",
            "Learning rate:  1e-05\n",
            "Epoch 22/50\n",
            "188/188 [==============================] - 6s 30ms/step - loss: 0.8344 - accuracy: 0.7680 - val_loss: 1.0559 - val_accuracy: 0.6919\n",
            "Learning rate:  1e-05\n",
            "Epoch 23/50\n",
            "188/188 [==============================] - 6s 30ms/step - loss: 0.8421 - accuracy: 0.7558 - val_loss: 1.0582 - val_accuracy: 0.6918\n",
            "Learning rate:  1e-05\n",
            "Epoch 24/50\n",
            "188/188 [==============================] - 5s 29ms/step - loss: 0.8426 - accuracy: 0.7577 - val_loss: 1.0590 - val_accuracy: 0.6931\n",
            "Learning rate:  1e-05\n",
            "Epoch 25/50\n",
            "188/188 [==============================] - 5s 29ms/step - loss: 0.8409 - accuracy: 0.7580 - val_loss: 1.0590 - val_accuracy: 0.6932\n",
            "Learning rate:  1e-05\n",
            "Epoch 26/50\n",
            "188/188 [==============================] - 5s 29ms/step - loss: 0.8352 - accuracy: 0.7667 - val_loss: 1.0593 - val_accuracy: 0.6932\n",
            "Learning rate:  1e-05\n",
            "Epoch 27/50\n",
            "188/188 [==============================] - 6s 29ms/step - loss: 0.8390 - accuracy: 0.7667 - val_loss: 1.0542 - val_accuracy: 0.6946\n",
            "Learning rate:  1e-05\n",
            "Epoch 28/50\n",
            "188/188 [==============================] - 5s 29ms/step - loss: 0.8195 - accuracy: 0.7700 - val_loss: 1.0613 - val_accuracy: 0.6944\n",
            "Learning rate:  1e-05\n",
            "Epoch 29/50\n",
            "188/188 [==============================] - 5s 29ms/step - loss: 0.8287 - accuracy: 0.7712 - val_loss: 1.0553 - val_accuracy: 0.6934\n",
            "Learning rate:  1e-05\n",
            "Epoch 30/50\n",
            "188/188 [==============================] - 5s 29ms/step - loss: 0.8288 - accuracy: 0.7668 - val_loss: 1.0546 - val_accuracy: 0.6945\n",
            "Learning rate:  1e-05\n",
            "Epoch 31/50\n",
            "188/188 [==============================] - 5s 29ms/step - loss: 0.8238 - accuracy: 0.7692 - val_loss: 1.0544 - val_accuracy: 0.6956\n",
            "Learning rate:  1e-06\n",
            "Epoch 32/50\n",
            "188/188 [==============================] - 6s 29ms/step - loss: 0.8268 - accuracy: 0.7718 - val_loss: 1.0528 - val_accuracy: 0.6966\n",
            "Learning rate:  1e-06\n",
            "Epoch 33/50\n",
            "188/188 [==============================] - 5s 29ms/step - loss: 0.8176 - accuracy: 0.7703 - val_loss: 1.0529 - val_accuracy: 0.6966\n",
            "Learning rate:  1e-06\n",
            "Epoch 34/50\n",
            "188/188 [==============================] - 5s 29ms/step - loss: 0.8211 - accuracy: 0.7718 - val_loss: 1.0535 - val_accuracy: 0.6960\n",
            "Learning rate:  1e-06\n",
            "Epoch 35/50\n",
            "188/188 [==============================] - 5s 29ms/step - loss: 0.8204 - accuracy: 0.7667 - val_loss: 1.0529 - val_accuracy: 0.6963\n",
            "Learning rate:  1e-06\n",
            "Epoch 36/50\n",
            "188/188 [==============================] - 5s 29ms/step - loss: 0.8227 - accuracy: 0.7708 - val_loss: 1.0514 - val_accuracy: 0.6966\n",
            "Learning rate:  1e-06\n",
            "Epoch 37/50\n",
            "188/188 [==============================] - 6s 29ms/step - loss: 0.8218 - accuracy: 0.7700 - val_loss: 1.0522 - val_accuracy: 0.6963\n",
            "Learning rate:  1e-06\n",
            "Epoch 38/50\n",
            "188/188 [==============================] - 6s 29ms/step - loss: 0.8280 - accuracy: 0.7623 - val_loss: 1.0527 - val_accuracy: 0.6958\n",
            "Learning rate:  1e-06\n",
            "Epoch 39/50\n",
            "188/188 [==============================] - 6s 29ms/step - loss: 0.8228 - accuracy: 0.7707 - val_loss: 1.0541 - val_accuracy: 0.6956\n",
            "Learning rate:  1e-06\n",
            "Epoch 40/50\n",
            "188/188 [==============================] - 5s 29ms/step - loss: 0.8158 - accuracy: 0.7713 - val_loss: 1.0525 - val_accuracy: 0.6960\n",
            "Learning rate:  1e-06\n",
            "Epoch 41/50\n",
            "188/188 [==============================] - 5s 29ms/step - loss: 0.8134 - accuracy: 0.7673 - val_loss: 1.0521 - val_accuracy: 0.6958\n",
            "Learning rate:  5e-07\n",
            "Epoch 42/50\n",
            "188/188 [==============================] - 6s 29ms/step - loss: 0.8203 - accuracy: 0.7722 - val_loss: 1.0521 - val_accuracy: 0.6955\n",
            "Learning rate:  5e-07\n",
            "Epoch 43/50\n",
            "188/188 [==============================] - 6s 29ms/step - loss: 0.8205 - accuracy: 0.7723 - val_loss: 1.0541 - val_accuracy: 0.6954\n",
            "Learning rate:  5e-07\n",
            "Epoch 44/50\n",
            "188/188 [==============================] - 5s 29ms/step - loss: 0.8211 - accuracy: 0.7752 - val_loss: 1.0531 - val_accuracy: 0.6956\n",
            "Learning rate:  5e-07\n",
            "Epoch 45/50\n",
            "188/188 [==============================] - 5s 29ms/step - loss: 0.8144 - accuracy: 0.7712 - val_loss: 1.0534 - val_accuracy: 0.6958\n",
            "Learning rate:  5e-07\n",
            "Epoch 46/50\n",
            "188/188 [==============================] - 6s 29ms/step - loss: 0.8210 - accuracy: 0.7663 - val_loss: 1.0525 - val_accuracy: 0.6951\n",
            "Learning rate:  5e-07\n",
            "Epoch 47/50\n",
            "188/188 [==============================] - 6s 30ms/step - loss: 0.8277 - accuracy: 0.7655 - val_loss: 1.0525 - val_accuracy: 0.6963\n",
            "Learning rate:  5e-07\n",
            "Epoch 48/50\n",
            "188/188 [==============================] - 6s 29ms/step - loss: 0.8187 - accuracy: 0.7672 - val_loss: 1.0512 - val_accuracy: 0.6967\n",
            "Learning rate:  5e-07\n",
            "Epoch 49/50\n",
            "188/188 [==============================] - 6s 30ms/step - loss: 0.8227 - accuracy: 0.7667 - val_loss: 1.0544 - val_accuracy: 0.6955\n",
            "Learning rate:  5e-07\n",
            "Epoch 50/50\n",
            "188/188 [==============================] - 6s 29ms/step - loss: 0.8193 - accuracy: 0.7715 - val_loss: 1.0552 - val_accuracy: 0.6963\n",
            " -- PATH: supervised\n",
            " -- write into csv file\n",
            "Num of trainings: 6\n",
            "Learning rate:  0.001\n",
            "ResNet20\n",
            "Using real-time data augmentation.\n",
            "Learning rate:  0.001\n",
            "Epoch 1/50\n",
            "219/219 [==============================] - 7s 32ms/step - loss: 2.0210 - accuracy: 0.3317 - val_loss: 1.9197 - val_accuracy: 0.3609\n",
            "Learning rate:  0.001\n",
            "Epoch 2/50\n",
            "219/219 [==============================] - 6s 28ms/step - loss: 1.7088 - accuracy: 0.4366 - val_loss: 1.9107 - val_accuracy: 0.3839\n",
            "Learning rate:  0.001\n",
            "Epoch 3/50\n",
            "219/219 [==============================] - 6s 29ms/step - loss: 1.5927 - accuracy: 0.4706 - val_loss: 1.6314 - val_accuracy: 0.4773\n",
            "Learning rate:  0.001\n",
            "Epoch 4/50\n",
            "219/219 [==============================] - 6s 28ms/step - loss: 1.5077 - accuracy: 0.5133 - val_loss: 1.7795 - val_accuracy: 0.4350\n",
            "Learning rate:  0.001\n",
            "Epoch 5/50\n",
            "219/219 [==============================] - 6s 29ms/step - loss: 1.4327 - accuracy: 0.5393 - val_loss: 2.8222 - val_accuracy: 0.3385\n",
            "Learning rate:  0.001\n",
            "Epoch 6/50\n",
            "219/219 [==============================] - 6s 29ms/step - loss: 1.3585 - accuracy: 0.5676 - val_loss: 1.5781 - val_accuracy: 0.5005\n",
            "Learning rate:  0.001\n",
            "Epoch 7/50\n",
            "219/219 [==============================] - 7s 30ms/step - loss: 1.2920 - accuracy: 0.5940 - val_loss: 1.8488 - val_accuracy: 0.4658\n",
            "Learning rate:  0.001\n",
            "Epoch 8/50\n",
            "219/219 [==============================] - 6s 29ms/step - loss: 1.2488 - accuracy: 0.6141 - val_loss: 1.5886 - val_accuracy: 0.5125\n",
            "Learning rate:  0.001\n",
            "Epoch 9/50\n",
            "219/219 [==============================] - 6s 28ms/step - loss: 1.1881 - accuracy: 0.6317 - val_loss: 1.4092 - val_accuracy: 0.5812\n",
            "Learning rate:  0.001\n",
            "Epoch 10/50\n",
            "219/219 [==============================] - 6s 28ms/step - loss: 1.1724 - accuracy: 0.6349 - val_loss: 1.4028 - val_accuracy: 0.5789\n",
            "Learning rate:  0.001\n",
            "Epoch 11/50\n",
            "219/219 [==============================] - 6s 29ms/step - loss: 1.1346 - accuracy: 0.6544 - val_loss: 1.3173 - val_accuracy: 0.6047\n",
            "Learning rate:  0.0001\n",
            "Epoch 12/50\n",
            "219/219 [==============================] - 6s 29ms/step - loss: 0.9959 - accuracy: 0.7073 - val_loss: 1.1233 - val_accuracy: 0.6632\n",
            "Learning rate:  0.0001\n",
            "Epoch 13/50\n",
            "219/219 [==============================] - 6s 29ms/step - loss: 0.9416 - accuracy: 0.7280 - val_loss: 1.0878 - val_accuracy: 0.6777\n",
            "Learning rate:  0.0001\n",
            "Epoch 14/50\n",
            "219/219 [==============================] - 6s 29ms/step - loss: 0.9333 - accuracy: 0.7247 - val_loss: 1.1410 - val_accuracy: 0.6595\n",
            "Learning rate:  0.0001\n",
            "Epoch 15/50\n",
            "219/219 [==============================] - 6s 28ms/step - loss: 0.9080 - accuracy: 0.7424 - val_loss: 1.0680 - val_accuracy: 0.6862\n",
            "Learning rate:  0.0001\n",
            "Epoch 16/50\n",
            "219/219 [==============================] - 6s 29ms/step - loss: 0.9022 - accuracy: 0.7381 - val_loss: 1.0960 - val_accuracy: 0.6785\n",
            "Learning rate:  0.0001\n",
            "Epoch 17/50\n",
            "219/219 [==============================] - 6s 29ms/step - loss: 0.8841 - accuracy: 0.7490 - val_loss: 1.1088 - val_accuracy: 0.6741\n",
            "Learning rate:  0.0001\n",
            "Epoch 18/50\n",
            "219/219 [==============================] - 6s 28ms/step - loss: 0.8692 - accuracy: 0.7481 - val_loss: 1.0593 - val_accuracy: 0.6891\n",
            "Learning rate:  0.0001\n",
            "Epoch 19/50\n",
            "219/219 [==============================] - 6s 28ms/step - loss: 0.8709 - accuracy: 0.7500 - val_loss: 1.0350 - val_accuracy: 0.6991\n",
            "Learning rate:  0.0001\n",
            "Epoch 20/50\n",
            "219/219 [==============================] - 6s 28ms/step - loss: 0.8668 - accuracy: 0.7523 - val_loss: 1.0821 - val_accuracy: 0.6789\n",
            "Learning rate:  0.0001\n",
            "Epoch 21/50\n",
            "219/219 [==============================] - 6s 28ms/step - loss: 0.8470 - accuracy: 0.7633 - val_loss: 1.0638 - val_accuracy: 0.6885\n",
            "Learning rate:  1e-05\n",
            "Epoch 22/50\n",
            "219/219 [==============================] - 6s 29ms/step - loss: 0.8141 - accuracy: 0.7729 - val_loss: 1.0430 - val_accuracy: 0.6947\n",
            "Learning rate:  1e-05\n",
            "Epoch 23/50\n",
            "219/219 [==============================] - 6s 28ms/step - loss: 0.8125 - accuracy: 0.7676 - val_loss: 1.0421 - val_accuracy: 0.6938\n",
            "Learning rate:  1e-05\n",
            "Epoch 24/50\n",
            "219/219 [==============================] - 6s 28ms/step - loss: 0.8194 - accuracy: 0.7739 - val_loss: 1.0490 - val_accuracy: 0.6927\n",
            "Learning rate:  1e-05\n",
            "Epoch 25/50\n",
            "219/219 [==============================] - 6s 28ms/step - loss: 0.8157 - accuracy: 0.7714 - val_loss: 1.0417 - val_accuracy: 0.6938\n",
            "Learning rate:  1e-05\n",
            "Epoch 26/50\n",
            "219/219 [==============================] - 6s 29ms/step - loss: 0.8142 - accuracy: 0.7707 - val_loss: 1.0440 - val_accuracy: 0.6933\n",
            "Learning rate:  1e-05\n",
            "Epoch 27/50\n",
            "219/219 [==============================] - 6s 28ms/step - loss: 0.8199 - accuracy: 0.7669 - val_loss: 1.0400 - val_accuracy: 0.6954\n",
            "Learning rate:  1e-05\n",
            "Epoch 28/50\n",
            "219/219 [==============================] - 6s 28ms/step - loss: 0.8044 - accuracy: 0.7761 - val_loss: 1.0402 - val_accuracy: 0.6949\n",
            "Learning rate:  1e-05\n",
            "Epoch 29/50\n",
            "219/219 [==============================] - 6s 28ms/step - loss: 0.8075 - accuracy: 0.7727 - val_loss: 1.0394 - val_accuracy: 0.6966\n",
            "Learning rate:  1e-05\n",
            "Epoch 30/50\n",
            "219/219 [==============================] - 6s 28ms/step - loss: 0.8074 - accuracy: 0.7737 - val_loss: 1.0370 - val_accuracy: 0.6960\n",
            "Learning rate:  1e-05\n",
            "Epoch 31/50\n",
            "219/219 [==============================] - 6s 28ms/step - loss: 0.8081 - accuracy: 0.7760 - val_loss: 1.0385 - val_accuracy: 0.6952\n",
            "Learning rate:  1e-06\n",
            "Epoch 32/50\n",
            "219/219 [==============================] - 6s 28ms/step - loss: 0.8098 - accuracy: 0.7704 - val_loss: 1.0387 - val_accuracy: 0.6954\n",
            "Learning rate:  1e-06\n",
            "Epoch 33/50\n",
            "219/219 [==============================] - 6s 28ms/step - loss: 0.7984 - accuracy: 0.7727 - val_loss: 1.0377 - val_accuracy: 0.6953\n",
            "Learning rate:  1e-06\n",
            "Epoch 34/50\n",
            "219/219 [==============================] - 6s 28ms/step - loss: 0.8093 - accuracy: 0.7770 - val_loss: 1.0352 - val_accuracy: 0.6962\n",
            "Learning rate:  1e-06\n",
            "Epoch 35/50\n",
            "219/219 [==============================] - 6s 28ms/step - loss: 0.7916 - accuracy: 0.7800 - val_loss: 1.0355 - val_accuracy: 0.6962\n",
            "Learning rate:  1e-06\n",
            "Epoch 36/50\n",
            "219/219 [==============================] - 6s 28ms/step - loss: 0.8029 - accuracy: 0.7783 - val_loss: 1.0357 - val_accuracy: 0.6962\n",
            "Learning rate:  1e-06\n",
            "Epoch 37/50\n",
            "219/219 [==============================] - 6s 28ms/step - loss: 0.8128 - accuracy: 0.7704 - val_loss: 1.0386 - val_accuracy: 0.6950\n",
            "Learning rate:  1e-06\n",
            "Epoch 38/50\n",
            "219/219 [==============================] - 6s 29ms/step - loss: 0.7981 - accuracy: 0.7751 - val_loss: 1.0372 - val_accuracy: 0.6953\n",
            "Learning rate:  1e-06\n",
            "Epoch 39/50\n",
            "219/219 [==============================] - 6s 30ms/step - loss: 0.8024 - accuracy: 0.7760 - val_loss: 1.0381 - val_accuracy: 0.6953\n",
            "Learning rate:  1e-06\n",
            "Epoch 40/50\n",
            "219/219 [==============================] - 7s 30ms/step - loss: 0.8109 - accuracy: 0.7691 - val_loss: 1.0359 - val_accuracy: 0.6962\n",
            "Learning rate:  1e-06\n",
            "Epoch 41/50\n",
            "219/219 [==============================] - 7s 31ms/step - loss: 0.8077 - accuracy: 0.7764 - val_loss: 1.0342 - val_accuracy: 0.6969\n",
            "Learning rate:  5e-07\n",
            "Epoch 42/50\n",
            "219/219 [==============================] - 7s 30ms/step - loss: 0.8059 - accuracy: 0.7759 - val_loss: 1.0343 - val_accuracy: 0.6966\n",
            "Learning rate:  5e-07\n",
            "Epoch 43/50\n",
            "219/219 [==============================] - 7s 30ms/step - loss: 0.7988 - accuracy: 0.7770 - val_loss: 1.0351 - val_accuracy: 0.6962\n",
            "Learning rate:  5e-07\n",
            "Epoch 44/50\n",
            "219/219 [==============================] - 7s 30ms/step - loss: 0.8036 - accuracy: 0.7743 - val_loss: 1.0346 - val_accuracy: 0.6967\n",
            "Learning rate:  5e-07\n",
            "Epoch 45/50\n",
            "219/219 [==============================] - 7s 31ms/step - loss: 0.7914 - accuracy: 0.7759 - val_loss: 1.0384 - val_accuracy: 0.6953\n",
            "Learning rate:  5e-07\n",
            "Epoch 46/50\n",
            "219/219 [==============================] - 7s 30ms/step - loss: 0.7986 - accuracy: 0.7757 - val_loss: 1.0359 - val_accuracy: 0.6960\n",
            "Learning rate:  5e-07\n",
            "Epoch 47/50\n",
            "219/219 [==============================] - 6s 30ms/step - loss: 0.7968 - accuracy: 0.7760 - val_loss: 1.0344 - val_accuracy: 0.6970\n",
            "Learning rate:  5e-07\n",
            "Epoch 48/50\n",
            "219/219 [==============================] - 6s 29ms/step - loss: 0.8091 - accuracy: 0.7796 - val_loss: 1.0338 - val_accuracy: 0.6964\n",
            "Learning rate:  5e-07\n",
            "Epoch 49/50\n",
            "219/219 [==============================] - 6s 29ms/step - loss: 0.7914 - accuracy: 0.7750 - val_loss: 1.0344 - val_accuracy: 0.6968\n",
            "Learning rate:  5e-07\n",
            "Epoch 50/50\n",
            "219/219 [==============================] - 6s 30ms/step - loss: 0.7925 - accuracy: 0.7787 - val_loss: 1.0336 - val_accuracy: 0.6968\n",
            " -- PATH: supervised\n",
            " -- write into csv file\n",
            "Num of trainings: 7\n",
            "Learning rate:  0.001\n",
            "ResNet20\n",
            "Using real-time data augmentation.\n",
            "Learning rate:  0.001\n",
            "Epoch 1/50\n",
            "250/250 [==============================] - 8s 32ms/step - loss: 2.0782 - accuracy: 0.3109 - val_loss: 2.2806 - val_accuracy: 0.2728\n",
            "Learning rate:  0.001\n",
            "Epoch 2/50\n",
            "250/250 [==============================] - 7s 29ms/step - loss: 1.7045 - accuracy: 0.4191 - val_loss: 1.9038 - val_accuracy: 0.3792\n",
            "Learning rate:  0.001\n",
            "Epoch 3/50\n",
            "250/250 [==============================] - 7s 28ms/step - loss: 1.5751 - accuracy: 0.4726 - val_loss: 1.8738 - val_accuracy: 0.3854\n",
            "Learning rate:  0.001\n",
            "Epoch 4/50\n",
            "250/250 [==============================] - 7s 30ms/step - loss: 1.4922 - accuracy: 0.5117 - val_loss: 1.7431 - val_accuracy: 0.4360\n",
            "Learning rate:  0.001\n",
            "Epoch 5/50\n",
            "250/250 [==============================] - 7s 29ms/step - loss: 1.4050 - accuracy: 0.5444 - val_loss: 2.0225 - val_accuracy: 0.4044\n",
            "Learning rate:  0.001\n",
            "Epoch 6/50\n",
            "250/250 [==============================] - 7s 29ms/step - loss: 1.3237 - accuracy: 0.5773 - val_loss: 1.6340 - val_accuracy: 0.5071\n",
            "Learning rate:  0.001\n",
            "Epoch 7/50\n",
            "250/250 [==============================] - 7s 29ms/step - loss: 1.2693 - accuracy: 0.5997 - val_loss: 1.7370 - val_accuracy: 0.4855\n",
            "Learning rate:  0.001\n",
            "Epoch 8/50\n",
            "250/250 [==============================] - 7s 28ms/step - loss: 1.2114 - accuracy: 0.6275 - val_loss: 1.5021 - val_accuracy: 0.5439\n",
            "Learning rate:  0.001\n",
            "Epoch 9/50\n",
            "250/250 [==============================] - 7s 28ms/step - loss: 1.1508 - accuracy: 0.6430 - val_loss: 1.3085 - val_accuracy: 0.5961\n",
            "Learning rate:  0.001\n",
            "Epoch 10/50\n",
            "250/250 [==============================] - 7s 29ms/step - loss: 1.1300 - accuracy: 0.6521 - val_loss: 1.1634 - val_accuracy: 0.6427\n",
            "Learning rate:  0.001\n",
            "Epoch 11/50\n",
            "250/250 [==============================] - 7s 29ms/step - loss: 1.0749 - accuracy: 0.6754 - val_loss: 1.4398 - val_accuracy: 0.5619\n",
            "Learning rate:  0.0001\n",
            "Epoch 12/50\n",
            "250/250 [==============================] - 7s 29ms/step - loss: 0.9525 - accuracy: 0.7216 - val_loss: 1.0253 - val_accuracy: 0.6971\n",
            "Learning rate:  0.0001\n",
            "Epoch 13/50\n",
            "250/250 [==============================] - 7s 29ms/step - loss: 0.9038 - accuracy: 0.7426 - val_loss: 1.0170 - val_accuracy: 0.7011\n",
            "Learning rate:  0.0001\n",
            "Epoch 14/50\n",
            "250/250 [==============================] - 7s 28ms/step - loss: 0.8705 - accuracy: 0.7517 - val_loss: 1.0029 - val_accuracy: 0.7091\n",
            "Learning rate:  0.0001\n",
            "Epoch 15/50\n",
            "250/250 [==============================] - 7s 28ms/step - loss: 0.8524 - accuracy: 0.7598 - val_loss: 1.0124 - val_accuracy: 0.7011\n",
            "Learning rate:  0.0001\n",
            "Epoch 16/50\n",
            "250/250 [==============================] - 7s 28ms/step - loss: 0.8557 - accuracy: 0.7561 - val_loss: 1.0114 - val_accuracy: 0.7023\n",
            "Learning rate:  0.0001\n",
            "Epoch 17/50\n",
            "250/250 [==============================] - 7s 28ms/step - loss: 0.8420 - accuracy: 0.7628 - val_loss: 1.0075 - val_accuracy: 0.7081\n",
            "Learning rate:  0.0001\n",
            "Epoch 18/50\n",
            "250/250 [==============================] - 7s 28ms/step - loss: 0.8279 - accuracy: 0.7665 - val_loss: 0.9873 - val_accuracy: 0.7135\n",
            "Learning rate:  0.0001\n",
            "Epoch 19/50\n",
            "250/250 [==============================] - 7s 29ms/step - loss: 0.8155 - accuracy: 0.7696 - val_loss: 1.0642 - val_accuracy: 0.6881\n",
            "Learning rate:  0.0001\n",
            "Epoch 20/50\n",
            "250/250 [==============================] - 7s 29ms/step - loss: 0.8098 - accuracy: 0.7736 - val_loss: 1.0160 - val_accuracy: 0.7037\n",
            "Learning rate:  0.0001\n",
            "Epoch 21/50\n",
            "250/250 [==============================] - 7s 29ms/step - loss: 0.7966 - accuracy: 0.7753 - val_loss: 0.9905 - val_accuracy: 0.7151\n",
            "Learning rate:  1e-05\n",
            "Epoch 22/50\n",
            "250/250 [==============================] - 7s 29ms/step - loss: 0.7859 - accuracy: 0.7830 - val_loss: 0.9854 - val_accuracy: 0.7165\n",
            "Learning rate:  1e-05\n",
            "Epoch 23/50\n",
            "250/250 [==============================] - 7s 29ms/step - loss: 0.7760 - accuracy: 0.7853 - val_loss: 0.9784 - val_accuracy: 0.7191\n",
            "Learning rate:  1e-05\n",
            "Epoch 24/50\n",
            "250/250 [==============================] - 7s 28ms/step - loss: 0.7759 - accuracy: 0.7836 - val_loss: 0.9781 - val_accuracy: 0.7191\n",
            "Learning rate:  1e-05\n",
            "Epoch 25/50\n",
            "250/250 [==============================] - 7s 28ms/step - loss: 0.7788 - accuracy: 0.7849 - val_loss: 0.9753 - val_accuracy: 0.7183\n",
            "Learning rate:  1e-05\n",
            "Epoch 26/50\n",
            "250/250 [==============================] - 7s 28ms/step - loss: 0.7713 - accuracy: 0.7856 - val_loss: 0.9782 - val_accuracy: 0.7200\n",
            "Learning rate:  1e-05\n",
            "Epoch 27/50\n",
            "250/250 [==============================] - 7s 28ms/step - loss: 0.7732 - accuracy: 0.7868 - val_loss: 0.9716 - val_accuracy: 0.7212\n",
            "Learning rate:  1e-05\n",
            "Epoch 28/50\n",
            "250/250 [==============================] - 7s 28ms/step - loss: 0.7628 - accuracy: 0.7906 - val_loss: 0.9725 - val_accuracy: 0.7206\n",
            "Learning rate:  1e-05\n",
            "Epoch 29/50\n",
            "250/250 [==============================] - 7s 28ms/step - loss: 0.7712 - accuracy: 0.7841 - val_loss: 0.9718 - val_accuracy: 0.7204\n",
            "Learning rate:  1e-05\n",
            "Epoch 30/50\n",
            "250/250 [==============================] - 7s 28ms/step - loss: 0.7678 - accuracy: 0.7871 - val_loss: 0.9709 - val_accuracy: 0.7223\n",
            "Learning rate:  1e-05\n",
            "Epoch 31/50\n",
            "250/250 [==============================] - 7s 29ms/step - loss: 0.7622 - accuracy: 0.7916 - val_loss: 0.9736 - val_accuracy: 0.7217\n",
            "Learning rate:  1e-06\n",
            "Epoch 32/50\n",
            "250/250 [==============================] - 7s 29ms/step - loss: 0.7605 - accuracy: 0.7845 - val_loss: 0.9693 - val_accuracy: 0.7222\n",
            "Learning rate:  1e-06\n",
            "Epoch 33/50\n",
            "250/250 [==============================] - 7s 29ms/step - loss: 0.7548 - accuracy: 0.7971 - val_loss: 0.9693 - val_accuracy: 0.7227\n",
            "Learning rate:  1e-06\n",
            "Epoch 34/50\n",
            "250/250 [==============================] - 7s 29ms/step - loss: 0.7601 - accuracy: 0.7875 - val_loss: 0.9718 - val_accuracy: 0.7220\n",
            "Learning rate:  1e-06\n",
            "Epoch 35/50\n",
            "250/250 [==============================] - 7s 29ms/step - loss: 0.7666 - accuracy: 0.7887 - val_loss: 0.9703 - val_accuracy: 0.7225\n",
            "Learning rate:  1e-06\n",
            "Epoch 36/50\n",
            "250/250 [==============================] - 7s 28ms/step - loss: 0.7665 - accuracy: 0.7862 - val_loss: 0.9706 - val_accuracy: 0.7222\n",
            "Learning rate:  1e-06\n",
            "Epoch 37/50\n",
            "250/250 [==============================] - 7s 29ms/step - loss: 0.7540 - accuracy: 0.7924 - val_loss: 0.9713 - val_accuracy: 0.7224\n",
            "Learning rate:  1e-06\n",
            "Epoch 38/50\n",
            "250/250 [==============================] - 7s 29ms/step - loss: 0.7666 - accuracy: 0.7890 - val_loss: 0.9723 - val_accuracy: 0.7219\n",
            "Learning rate:  1e-06\n",
            "Epoch 39/50\n",
            "250/250 [==============================] - 8s 30ms/step - loss: 0.7662 - accuracy: 0.7861 - val_loss: 0.9723 - val_accuracy: 0.7226\n",
            "Learning rate:  1e-06\n",
            "Epoch 40/50\n",
            "250/250 [==============================] - 7s 29ms/step - loss: 0.7562 - accuracy: 0.7901 - val_loss: 0.9736 - val_accuracy: 0.7216\n",
            "Learning rate:  1e-06\n",
            "Epoch 41/50\n",
            "250/250 [==============================] - 7s 29ms/step - loss: 0.7554 - accuracy: 0.7916 - val_loss: 0.9702 - val_accuracy: 0.7224\n",
            "Learning rate:  5e-07\n",
            "Epoch 42/50\n",
            "250/250 [==============================] - 7s 29ms/step - loss: 0.7557 - accuracy: 0.7919 - val_loss: 0.9708 - val_accuracy: 0.7214\n",
            "Learning rate:  5e-07\n",
            "Epoch 43/50\n",
            "250/250 [==============================] - 7s 29ms/step - loss: 0.7510 - accuracy: 0.7968 - val_loss: 0.9698 - val_accuracy: 0.7228\n",
            "Learning rate:  5e-07\n",
            "Epoch 44/50\n",
            "250/250 [==============================] - 7s 29ms/step - loss: 0.7630 - accuracy: 0.7855 - val_loss: 0.9699 - val_accuracy: 0.7231\n",
            "Learning rate:  5e-07\n",
            "Epoch 45/50\n",
            "250/250 [==============================] - 7s 29ms/step - loss: 0.7569 - accuracy: 0.7934 - val_loss: 0.9697 - val_accuracy: 0.7231\n",
            "Learning rate:  5e-07\n",
            "Epoch 46/50\n",
            "250/250 [==============================] - 7s 29ms/step - loss: 0.7591 - accuracy: 0.7912 - val_loss: 0.9707 - val_accuracy: 0.7220\n",
            "Learning rate:  5e-07\n",
            "Epoch 47/50\n",
            "250/250 [==============================] - 8s 30ms/step - loss: 0.7566 - accuracy: 0.7921 - val_loss: 0.9714 - val_accuracy: 0.7227\n",
            "Learning rate:  5e-07\n",
            "Epoch 48/50\n",
            "250/250 [==============================] - 7s 29ms/step - loss: 0.7600 - accuracy: 0.7921 - val_loss: 0.9714 - val_accuracy: 0.7229\n",
            "Learning rate:  5e-07\n",
            "Epoch 49/50\n",
            "250/250 [==============================] - 7s 29ms/step - loss: 0.7649 - accuracy: 0.7893 - val_loss: 0.9725 - val_accuracy: 0.7212\n",
            "Learning rate:  5e-07\n",
            "Epoch 50/50\n",
            "250/250 [==============================] - 7s 29ms/step - loss: 0.7525 - accuracy: 0.7886 - val_loss: 0.9710 - val_accuracy: 0.7226\n",
            " -- PATH: supervised\n",
            " -- write into csv file\n",
            "Num of trainings: 8\n",
            "Learning rate:  0.001\n",
            "ResNet20\n",
            "Using real-time data augmentation.\n",
            "Learning rate:  0.001\n",
            "Epoch 1/50\n",
            "282/282 [==============================] - 8s 30ms/step - loss: 1.9319 - accuracy: 0.3483 - val_loss: 3.0011 - val_accuracy: 0.2977\n",
            "Learning rate:  0.001\n",
            "Epoch 2/50\n",
            "282/282 [==============================] - 8s 28ms/step - loss: 1.6407 - accuracy: 0.4612 - val_loss: 1.9869 - val_accuracy: 0.3998\n",
            "Learning rate:  0.001\n",
            "Epoch 3/50\n",
            "282/282 [==============================] - 8s 28ms/step - loss: 1.5032 - accuracy: 0.5112 - val_loss: 1.7075 - val_accuracy: 0.4667\n",
            "Learning rate:  0.001\n",
            "Epoch 4/50\n",
            "282/282 [==============================] - 8s 28ms/step - loss: 1.4206 - accuracy: 0.5442 - val_loss: 1.5055 - val_accuracy: 0.5231\n",
            "Learning rate:  0.001\n",
            "Epoch 5/50\n",
            "282/282 [==============================] - 8s 28ms/step - loss: 1.3467 - accuracy: 0.5644 - val_loss: 1.5155 - val_accuracy: 0.5382\n",
            "Learning rate:  0.001\n",
            "Epoch 6/50\n",
            "282/282 [==============================] - 8s 28ms/step - loss: 1.2813 - accuracy: 0.5953 - val_loss: 1.4845 - val_accuracy: 0.5522\n",
            "Learning rate:  0.001\n",
            "Epoch 7/50\n",
            "282/282 [==============================] - 8s 28ms/step - loss: 1.2221 - accuracy: 0.6154 - val_loss: 2.1912 - val_accuracy: 0.4407\n",
            "Learning rate:  0.001\n",
            "Epoch 8/50\n",
            "282/282 [==============================] - 8s 28ms/step - loss: 1.1761 - accuracy: 0.6332 - val_loss: 1.4788 - val_accuracy: 0.5444\n",
            "Learning rate:  0.001\n",
            "Epoch 9/50\n",
            "282/282 [==============================] - 8s 28ms/step - loss: 1.1319 - accuracy: 0.6521 - val_loss: 1.5460 - val_accuracy: 0.5679\n",
            "Learning rate:  0.001\n",
            "Epoch 10/50\n",
            "282/282 [==============================] - 8s 28ms/step - loss: 1.0880 - accuracy: 0.6678 - val_loss: 1.3154 - val_accuracy: 0.6064\n",
            "Learning rate:  0.001\n",
            "Epoch 11/50\n",
            "282/282 [==============================] - 8s 28ms/step - loss: 1.0504 - accuracy: 0.6813 - val_loss: 1.5458 - val_accuracy: 0.5603\n",
            "Learning rate:  0.0001\n",
            "Epoch 12/50\n",
            "282/282 [==============================] - 8s 28ms/step - loss: 0.9258 - accuracy: 0.7331 - val_loss: 1.0082 - val_accuracy: 0.7022\n",
            "Learning rate:  0.0001\n",
            "Epoch 13/50\n",
            "282/282 [==============================] - 8s 28ms/step - loss: 0.8921 - accuracy: 0.7440 - val_loss: 1.0517 - val_accuracy: 0.6865\n",
            "Learning rate:  0.0001\n",
            "Epoch 14/50\n",
            "282/282 [==============================] - 8s 28ms/step - loss: 0.8603 - accuracy: 0.7553 - val_loss: 0.9778 - val_accuracy: 0.7184\n",
            "Learning rate:  0.0001\n",
            "Epoch 15/50\n",
            "282/282 [==============================] - 8s 28ms/step - loss: 0.8469 - accuracy: 0.7598 - val_loss: 0.9861 - val_accuracy: 0.7124\n",
            "Learning rate:  0.0001\n",
            "Epoch 16/50\n",
            "282/282 [==============================] - 8s 28ms/step - loss: 0.8254 - accuracy: 0.7681 - val_loss: 0.9558 - val_accuracy: 0.7242\n",
            "Learning rate:  0.0001\n",
            "Epoch 17/50\n",
            "282/282 [==============================] - 8s 28ms/step - loss: 0.8264 - accuracy: 0.7698 - val_loss: 0.9738 - val_accuracy: 0.7219\n",
            "Learning rate:  0.0001\n",
            "Epoch 18/50\n",
            "282/282 [==============================] - 8s 29ms/step - loss: 0.8114 - accuracy: 0.7774 - val_loss: 0.9747 - val_accuracy: 0.7174\n",
            "Learning rate:  0.0001\n",
            "Epoch 19/50\n",
            "282/282 [==============================] - 8s 28ms/step - loss: 0.7949 - accuracy: 0.7771 - val_loss: 0.9628 - val_accuracy: 0.7253\n",
            "Learning rate:  0.0001\n",
            "Epoch 20/50\n",
            "282/282 [==============================] - 8s 28ms/step - loss: 0.7921 - accuracy: 0.7799 - val_loss: 1.0279 - val_accuracy: 0.7014\n",
            "Learning rate:  0.0001\n",
            "Epoch 21/50\n",
            "282/282 [==============================] - 8s 28ms/step - loss: 0.7846 - accuracy: 0.7830 - val_loss: 0.9586 - val_accuracy: 0.7256\n",
            "Learning rate:  1e-05\n",
            "Epoch 22/50\n",
            "282/282 [==============================] - 8s 28ms/step - loss: 0.7695 - accuracy: 0.7853 - val_loss: 0.9469 - val_accuracy: 0.7285\n",
            "Learning rate:  1e-05\n",
            "Epoch 23/50\n",
            "282/282 [==============================] - 8s 28ms/step - loss: 0.7559 - accuracy: 0.7951 - val_loss: 0.9489 - val_accuracy: 0.7276\n",
            "Learning rate:  1e-05\n",
            "Epoch 24/50\n",
            "282/282 [==============================] - 8s 28ms/step - loss: 0.7664 - accuracy: 0.7872 - val_loss: 0.9447 - val_accuracy: 0.7289\n",
            "Learning rate:  1e-05\n",
            "Epoch 25/50\n",
            "282/282 [==============================] - 8s 28ms/step - loss: 0.7489 - accuracy: 0.7913 - val_loss: 0.9441 - val_accuracy: 0.7293\n",
            "Learning rate:  1e-05\n",
            "Epoch 26/50\n",
            "282/282 [==============================] - 8s 28ms/step - loss: 0.7576 - accuracy: 0.7898 - val_loss: 0.9442 - val_accuracy: 0.7298\n",
            "Learning rate:  1e-05\n",
            "Epoch 27/50\n",
            "282/282 [==============================] - 8s 28ms/step - loss: 0.7499 - accuracy: 0.7928 - val_loss: 0.9415 - val_accuracy: 0.7305\n",
            "Learning rate:  1e-05\n",
            "Epoch 28/50\n",
            "282/282 [==============================] - 8s 28ms/step - loss: 0.7473 - accuracy: 0.7958 - val_loss: 0.9428 - val_accuracy: 0.7300\n",
            "Learning rate:  1e-05\n",
            "Epoch 29/50\n",
            "282/282 [==============================] - 8s 28ms/step - loss: 0.7541 - accuracy: 0.7900 - val_loss: 0.9451 - val_accuracy: 0.7305\n",
            "Learning rate:  1e-05\n",
            "Epoch 30/50\n",
            "282/282 [==============================] - 8s 28ms/step - loss: 0.7367 - accuracy: 0.8017 - val_loss: 0.9377 - val_accuracy: 0.7332\n",
            "Learning rate:  1e-05\n",
            "Epoch 31/50\n",
            "282/282 [==============================] - 8s 28ms/step - loss: 0.7439 - accuracy: 0.7980 - val_loss: 0.9422 - val_accuracy: 0.7300\n",
            "Learning rate:  1e-06\n",
            "Epoch 32/50\n",
            "282/282 [==============================] - 8s 28ms/step - loss: 0.7403 - accuracy: 0.8000 - val_loss: 0.9420 - val_accuracy: 0.7314\n",
            "Learning rate:  1e-06\n",
            "Epoch 33/50\n",
            "282/282 [==============================] - 8s 28ms/step - loss: 0.7403 - accuracy: 0.8012 - val_loss: 0.9412 - val_accuracy: 0.7315\n",
            "Learning rate:  1e-06\n",
            "Epoch 34/50\n",
            "282/282 [==============================] - 8s 28ms/step - loss: 0.7490 - accuracy: 0.7927 - val_loss: 0.9387 - val_accuracy: 0.7309\n",
            "Learning rate:  1e-06\n",
            "Epoch 35/50\n",
            "282/282 [==============================] - 8s 29ms/step - loss: 0.7435 - accuracy: 0.7971 - val_loss: 0.9383 - val_accuracy: 0.7319\n",
            "Learning rate:  1e-06\n",
            "Epoch 36/50\n",
            "282/282 [==============================] - 8s 29ms/step - loss: 0.7460 - accuracy: 0.8022 - val_loss: 0.9374 - val_accuracy: 0.7322\n",
            "Learning rate:  1e-06\n",
            "Epoch 37/50\n",
            "282/282 [==============================] - 8s 28ms/step - loss: 0.7430 - accuracy: 0.7998 - val_loss: 0.9390 - val_accuracy: 0.7321\n",
            "Learning rate:  1e-06\n",
            "Epoch 38/50\n",
            "282/282 [==============================] - 8s 28ms/step - loss: 0.7447 - accuracy: 0.7960 - val_loss: 0.9392 - val_accuracy: 0.7315\n",
            "Learning rate:  1e-06\n",
            "Epoch 39/50\n",
            "282/282 [==============================] - 8s 28ms/step - loss: 0.7422 - accuracy: 0.7973 - val_loss: 0.9392 - val_accuracy: 0.7320\n",
            "Learning rate:  1e-06\n",
            "Epoch 40/50\n",
            "282/282 [==============================] - 8s 28ms/step - loss: 0.7432 - accuracy: 0.7927 - val_loss: 0.9401 - val_accuracy: 0.7315\n",
            "Learning rate:  1e-06\n",
            "Epoch 41/50\n",
            "282/282 [==============================] - 8s 28ms/step - loss: 0.7452 - accuracy: 0.7952 - val_loss: 0.9384 - val_accuracy: 0.7318\n",
            "Learning rate:  5e-07\n",
            "Epoch 42/50\n",
            "282/282 [==============================] - 8s 28ms/step - loss: 0.7462 - accuracy: 0.7948 - val_loss: 0.9366 - val_accuracy: 0.7327\n",
            "Learning rate:  5e-07\n",
            "Epoch 43/50\n",
            "282/282 [==============================] - 8s 28ms/step - loss: 0.7522 - accuracy: 0.7927 - val_loss: 0.9375 - val_accuracy: 0.7320\n",
            "Learning rate:  5e-07\n",
            "Epoch 44/50\n",
            "282/282 [==============================] - 8s 28ms/step - loss: 0.7454 - accuracy: 0.7981 - val_loss: 0.9348 - val_accuracy: 0.7332\n",
            "Learning rate:  5e-07\n",
            "Epoch 45/50\n",
            "282/282 [==============================] - 8s 28ms/step - loss: 0.7551 - accuracy: 0.7878 - val_loss: 0.9378 - val_accuracy: 0.7324\n",
            "Learning rate:  5e-07\n",
            "Epoch 46/50\n",
            "282/282 [==============================] - 8s 28ms/step - loss: 0.7444 - accuracy: 0.7954 - val_loss: 0.9375 - val_accuracy: 0.7324\n",
            "Learning rate:  5e-07\n",
            "Epoch 47/50\n",
            "282/282 [==============================] - 8s 28ms/step - loss: 0.7424 - accuracy: 0.7936 - val_loss: 0.9381 - val_accuracy: 0.7321\n",
            "Learning rate:  5e-07\n",
            "Epoch 48/50\n",
            "282/282 [==============================] - 8s 28ms/step - loss: 0.7443 - accuracy: 0.7976 - val_loss: 0.9368 - val_accuracy: 0.7327\n",
            "Learning rate:  5e-07\n",
            "Epoch 49/50\n",
            "282/282 [==============================] - 8s 28ms/step - loss: 0.7431 - accuracy: 0.7961 - val_loss: 0.9364 - val_accuracy: 0.7328\n",
            "Learning rate:  5e-07\n",
            "Epoch 50/50\n",
            "282/282 [==============================] - 8s 28ms/step - loss: 0.7461 - accuracy: 0.7959 - val_loss: 0.9368 - val_accuracy: 0.7321\n",
            " -- PATH: supervised\n",
            " -- write into csv file\n",
            "Num of trainings: 9\n",
            "Learning rate:  0.001\n",
            "ResNet20\n",
            "Using real-time data augmentation.\n",
            "Learning rate:  0.001\n",
            "Epoch 1/50\n",
            "313/313 [==============================] - 9s 30ms/step - loss: 1.9900 - accuracy: 0.3396 - val_loss: 1.7050 - val_accuracy: 0.4300\n",
            "Learning rate:  0.001\n",
            "Epoch 2/50\n",
            "313/313 [==============================] - 9s 29ms/step - loss: 1.6584 - accuracy: 0.4548 - val_loss: 1.8426 - val_accuracy: 0.4108\n",
            "Learning rate:  0.001\n",
            "Epoch 3/50\n",
            "313/313 [==============================] - 9s 28ms/step - loss: 1.4864 - accuracy: 0.5243 - val_loss: 1.6079 - val_accuracy: 0.5088\n",
            "Learning rate:  0.001\n",
            "Epoch 4/50\n",
            "313/313 [==============================] - 9s 28ms/step - loss: 1.3817 - accuracy: 0.5579 - val_loss: 1.4356 - val_accuracy: 0.5537\n",
            "Learning rate:  0.001\n",
            "Epoch 5/50\n",
            "313/313 [==============================] - 9s 28ms/step - loss: 1.3184 - accuracy: 0.5876 - val_loss: 1.6365 - val_accuracy: 0.5014\n",
            "Learning rate:  0.001\n",
            "Epoch 6/50\n",
            "313/313 [==============================] - 9s 28ms/step - loss: 1.2442 - accuracy: 0.6140 - val_loss: 2.5443 - val_accuracy: 0.3684\n",
            "Learning rate:  0.001\n",
            "Epoch 7/50\n",
            "313/313 [==============================] - 9s 28ms/step - loss: 1.1874 - accuracy: 0.6402 - val_loss: 1.7137 - val_accuracy: 0.4969\n",
            "Learning rate:  0.001\n",
            "Epoch 8/50\n",
            "313/313 [==============================] - 9s 28ms/step - loss: 1.1364 - accuracy: 0.6519 - val_loss: 2.2320 - val_accuracy: 0.4711\n",
            "Learning rate:  0.001\n",
            "Epoch 9/50\n",
            "313/313 [==============================] - 9s 28ms/step - loss: 1.0925 - accuracy: 0.6715 - val_loss: 1.3095 - val_accuracy: 0.5946\n",
            "Learning rate:  0.001\n",
            "Epoch 10/50\n",
            "313/313 [==============================] - 9s 28ms/step - loss: 1.0397 - accuracy: 0.6887 - val_loss: 1.7161 - val_accuracy: 0.5617\n",
            "Learning rate:  0.001\n",
            "Epoch 11/50\n",
            "313/313 [==============================] - 9s 28ms/step - loss: 1.0223 - accuracy: 0.6944 - val_loss: 1.3571 - val_accuracy: 0.6048\n",
            "Learning rate:  0.0001\n",
            "Epoch 12/50\n",
            "313/313 [==============================] - 9s 28ms/step - loss: 0.8747 - accuracy: 0.7570 - val_loss: 0.9786 - val_accuracy: 0.7206\n",
            "Learning rate:  0.0001\n",
            "Epoch 13/50\n",
            "313/313 [==============================] - 9s 28ms/step - loss: 0.8328 - accuracy: 0.7696 - val_loss: 0.9758 - val_accuracy: 0.7225\n",
            "Learning rate:  0.0001\n",
            "Epoch 14/50\n",
            "313/313 [==============================] - 9s 28ms/step - loss: 0.8096 - accuracy: 0.7750 - val_loss: 0.9490 - val_accuracy: 0.7280\n",
            "Learning rate:  0.0001\n",
            "Epoch 15/50\n",
            "313/313 [==============================] - 9s 28ms/step - loss: 0.8118 - accuracy: 0.7723 - val_loss: 0.9295 - val_accuracy: 0.7359\n",
            "Learning rate:  0.0001\n",
            "Epoch 16/50\n",
            "313/313 [==============================] - 9s 28ms/step - loss: 0.7929 - accuracy: 0.7809 - val_loss: 0.9358 - val_accuracy: 0.7371\n",
            "Learning rate:  0.0001\n",
            "Epoch 17/50\n",
            "313/313 [==============================] - 9s 28ms/step - loss: 0.7912 - accuracy: 0.7817 - val_loss: 0.9193 - val_accuracy: 0.7384\n",
            "Learning rate:  0.0001\n",
            "Epoch 18/50\n",
            "313/313 [==============================] - 9s 28ms/step - loss: 0.7609 - accuracy: 0.7942 - val_loss: 0.9003 - val_accuracy: 0.7462\n",
            "Learning rate:  0.0001\n",
            "Epoch 19/50\n",
            "313/313 [==============================] - 9s 28ms/step - loss: 0.7594 - accuracy: 0.7908 - val_loss: 0.9349 - val_accuracy: 0.7381\n",
            "Learning rate:  0.0001\n",
            "Epoch 20/50\n",
            "313/313 [==============================] - 9s 28ms/step - loss: 0.7476 - accuracy: 0.7993 - val_loss: 0.9130 - val_accuracy: 0.7411\n",
            "Learning rate:  0.0001\n",
            "Epoch 21/50\n",
            "313/313 [==============================] - 9s 28ms/step - loss: 0.7320 - accuracy: 0.8018 - val_loss: 0.8942 - val_accuracy: 0.7458\n",
            "Learning rate:  1e-05\n",
            "Epoch 22/50\n",
            "313/313 [==============================] - 9s 29ms/step - loss: 0.7174 - accuracy: 0.8071 - val_loss: 0.8909 - val_accuracy: 0.7493\n",
            "Learning rate:  1e-05\n",
            "Epoch 23/50\n",
            "313/313 [==============================] - 9s 28ms/step - loss: 0.7100 - accuracy: 0.8097 - val_loss: 0.8866 - val_accuracy: 0.7501\n",
            "Learning rate:  1e-05\n",
            "Epoch 24/50\n",
            "313/313 [==============================] - 9s 27ms/step - loss: 0.7092 - accuracy: 0.8064 - val_loss: 0.8832 - val_accuracy: 0.7516\n",
            "Learning rate:  1e-05\n",
            "Epoch 25/50\n",
            "313/313 [==============================] - 9s 28ms/step - loss: 0.7123 - accuracy: 0.8120 - val_loss: 0.8890 - val_accuracy: 0.7492\n",
            "Learning rate:  1e-05\n",
            "Epoch 26/50\n",
            "313/313 [==============================] - 9s 28ms/step - loss: 0.7057 - accuracy: 0.8134 - val_loss: 0.8938 - val_accuracy: 0.7482\n",
            "Learning rate:  1e-05\n",
            "Epoch 27/50\n",
            "313/313 [==============================] - 9s 28ms/step - loss: 0.7033 - accuracy: 0.8108 - val_loss: 0.8867 - val_accuracy: 0.7517\n",
            "Learning rate:  1e-05\n",
            "Epoch 28/50\n",
            "313/313 [==============================] - 9s 28ms/step - loss: 0.7074 - accuracy: 0.8098 - val_loss: 0.8899 - val_accuracy: 0.7495\n",
            "Learning rate:  1e-05\n",
            "Epoch 29/50\n",
            "313/313 [==============================] - 9s 28ms/step - loss: 0.7145 - accuracy: 0.8115 - val_loss: 0.8878 - val_accuracy: 0.7504\n",
            "Learning rate:  1e-05\n",
            "Epoch 30/50\n",
            "313/313 [==============================] - 9s 28ms/step - loss: 0.7013 - accuracy: 0.8115 - val_loss: 0.8914 - val_accuracy: 0.7486\n",
            "Learning rate:  1e-05\n",
            "Epoch 31/50\n",
            "313/313 [==============================] - 9s 28ms/step - loss: 0.7028 - accuracy: 0.8110 - val_loss: 0.8886 - val_accuracy: 0.7496\n",
            "Learning rate:  1e-06\n",
            "Epoch 32/50\n",
            "313/313 [==============================] - 9s 28ms/step - loss: 0.7035 - accuracy: 0.8114 - val_loss: 0.8870 - val_accuracy: 0.7500\n",
            "Learning rate:  1e-06\n",
            "Epoch 33/50\n",
            "313/313 [==============================] - 9s 28ms/step - loss: 0.7109 - accuracy: 0.8062 - val_loss: 0.8885 - val_accuracy: 0.7502\n",
            "Learning rate:  1e-06\n",
            "Epoch 34/50\n",
            "313/313 [==============================] - 9s 28ms/step - loss: 0.7137 - accuracy: 0.8055 - val_loss: 0.8873 - val_accuracy: 0.7502\n",
            "Learning rate:  1e-06\n",
            "Epoch 35/50\n",
            "313/313 [==============================] - 9s 28ms/step - loss: 0.7017 - accuracy: 0.8120 - val_loss: 0.8874 - val_accuracy: 0.7503\n",
            "Learning rate:  1e-06\n",
            "Epoch 36/50\n",
            "313/313 [==============================] - 9s 28ms/step - loss: 0.7011 - accuracy: 0.8122 - val_loss: 0.8851 - val_accuracy: 0.7516\n",
            "Learning rate:  1e-06\n",
            "Epoch 37/50\n",
            "313/313 [==============================] - 9s 28ms/step - loss: 0.7030 - accuracy: 0.8093 - val_loss: 0.8869 - val_accuracy: 0.7492\n",
            "Learning rate:  1e-06\n",
            "Epoch 38/50\n",
            "313/313 [==============================] - 8s 27ms/step - loss: 0.6979 - accuracy: 0.8143 - val_loss: 0.8844 - val_accuracy: 0.7512\n",
            "Learning rate:  1e-06\n",
            "Epoch 39/50\n",
            "313/313 [==============================] - 9s 28ms/step - loss: 0.7140 - accuracy: 0.8059 - val_loss: 0.8859 - val_accuracy: 0.7512\n",
            "Learning rate:  1e-06\n",
            "Epoch 40/50\n",
            "313/313 [==============================] - 9s 27ms/step - loss: 0.6986 - accuracy: 0.8130 - val_loss: 0.8832 - val_accuracy: 0.7511\n",
            "Learning rate:  1e-06\n",
            "Epoch 41/50\n",
            "313/313 [==============================] - 9s 28ms/step - loss: 0.7096 - accuracy: 0.8105 - val_loss: 0.8872 - val_accuracy: 0.7503\n",
            "Learning rate:  5e-07\n",
            "Epoch 42/50\n",
            "313/313 [==============================] - 8s 27ms/step - loss: 0.7054 - accuracy: 0.8099 - val_loss: 0.8862 - val_accuracy: 0.7502\n",
            "Learning rate:  5e-07\n",
            "Epoch 43/50\n",
            "313/313 [==============================] - 9s 28ms/step - loss: 0.7047 - accuracy: 0.8097 - val_loss: 0.8870 - val_accuracy: 0.7498\n",
            "Learning rate:  5e-07\n",
            "Epoch 44/50\n",
            "313/313 [==============================] - 9s 27ms/step - loss: 0.7044 - accuracy: 0.8145 - val_loss: 0.8839 - val_accuracy: 0.7510\n",
            "Learning rate:  5e-07\n",
            "Epoch 45/50\n",
            "313/313 [==============================] - 9s 27ms/step - loss: 0.6955 - accuracy: 0.8145 - val_loss: 0.8853 - val_accuracy: 0.7508\n",
            "Learning rate:  5e-07\n",
            "Epoch 46/50\n",
            "313/313 [==============================] - 9s 28ms/step - loss: 0.7053 - accuracy: 0.8071 - val_loss: 0.8832 - val_accuracy: 0.7513\n",
            "Learning rate:  5e-07\n",
            "Epoch 47/50\n",
            "313/313 [==============================] - 9s 27ms/step - loss: 0.7021 - accuracy: 0.8112 - val_loss: 0.8835 - val_accuracy: 0.7514\n",
            "Learning rate:  5e-07\n",
            "Epoch 48/50\n",
            "313/313 [==============================] - 8s 27ms/step - loss: 0.7085 - accuracy: 0.8111 - val_loss: 0.8867 - val_accuracy: 0.7510\n",
            "Learning rate:  5e-07\n",
            "Epoch 49/50\n",
            "313/313 [==============================] - 9s 27ms/step - loss: 0.7016 - accuracy: 0.8126 - val_loss: 0.8849 - val_accuracy: 0.7513\n",
            "Learning rate:  5e-07\n",
            "Epoch 50/50\n",
            "313/313 [==============================] - 9s 28ms/step - loss: 0.7010 - accuracy: 0.8085 - val_loss: 0.8848 - val_accuracy: 0.7503\n",
            " -- PATH: supervised\n",
            " -- write into csv file\n",
            "Num of trainings: 10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nN3k4Y_F_zfi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0f32001-f3f1-44f3-bbd8-203dccb46385"
      },
      "source": [
        "### Run experiment with WITH self-supervision\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "x_train, y_train, x_test, y_test = preprocess_data2(x_train, y_train, x_test, y_test)\n",
        "train_models_datasplit(x_train, y_train, x_test, y_test, data_fraction_increment=0.02, batch_size=32, num_increments=10, dataset='CIFAR10_large', ssl_path='/content/drive/My Drive/Colab Notebooks/Self-Supervised-Learning/Pre-text_Rotation/Restnetv1_SSL_Rotation.h5')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
            "  FutureWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Num of trainings: 0\n",
            "Learning rate:  0.001\n",
            "ResNet20\n",
            "Using real-time data augmentation.\n",
            "Learning rate:  0.001\n",
            "Epoch 1/50\n",
            "32/32 [==============================] - 3s 79ms/step - loss: 1.9387 - accuracy: 0.3310 - val_loss: 7.6877 - val_accuracy: 0.1881\n",
            "Learning rate:  0.001\n",
            "Epoch 2/50\n",
            "32/32 [==============================] - 2s 61ms/step - loss: 1.4788 - accuracy: 0.5010 - val_loss: 4.8164 - val_accuracy: 0.2377\n",
            "Learning rate:  0.001\n",
            "Epoch 3/50\n",
            "32/32 [==============================] - 2s 60ms/step - loss: 1.3578 - accuracy: 0.5410 - val_loss: 2.6058 - val_accuracy: 0.3803\n",
            "Learning rate:  0.001\n",
            "Epoch 4/50\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 1.2541 - accuracy: 0.5890 - val_loss: 2.8752 - val_accuracy: 0.3415\n",
            "Learning rate:  0.001\n",
            "Epoch 5/50\n",
            "32/32 [==============================] - 2s 60ms/step - loss: 1.1562 - accuracy: 0.6120 - val_loss: 2.2640 - val_accuracy: 0.4312\n",
            "Learning rate:  0.001\n",
            "Epoch 6/50\n",
            "32/32 [==============================] - 2s 60ms/step - loss: 1.0504 - accuracy: 0.6550 - val_loss: 1.6122 - val_accuracy: 0.5065\n",
            "Learning rate:  0.001\n",
            "Epoch 7/50\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 1.0263 - accuracy: 0.6720 - val_loss: 2.3631 - val_accuracy: 0.4626\n",
            "Learning rate:  0.001\n",
            "Epoch 8/50\n",
            "32/32 [==============================] - 2s 61ms/step - loss: 0.9268 - accuracy: 0.7210 - val_loss: 1.7818 - val_accuracy: 0.4955\n",
            "Learning rate:  0.001\n",
            "Epoch 9/50\n",
            "32/32 [==============================] - 2s 59ms/step - loss: 0.8723 - accuracy: 0.7270 - val_loss: 1.8864 - val_accuracy: 0.4765\n",
            "Learning rate:  0.001\n",
            "Epoch 10/50\n",
            "32/32 [==============================] - 2s 61ms/step - loss: 0.8875 - accuracy: 0.7070 - val_loss: 1.6170 - val_accuracy: 0.5198\n",
            "Learning rate:  0.001\n",
            "Epoch 11/50\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 0.8547 - accuracy: 0.7310 - val_loss: 1.5198 - val_accuracy: 0.5417\n",
            "Learning rate:  0.0001\n",
            "Epoch 12/50\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 0.7528 - accuracy: 0.7630 - val_loss: 1.3002 - val_accuracy: 0.5927\n",
            "Learning rate:  0.0001\n",
            "Epoch 13/50\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.6477 - accuracy: 0.8270 - val_loss: 1.2468 - val_accuracy: 0.6073\n",
            "Learning rate:  0.0001\n",
            "Epoch 14/50\n",
            "32/32 [==============================] - 2s 61ms/step - loss: 0.6428 - accuracy: 0.8170 - val_loss: 1.2348 - val_accuracy: 0.6147\n",
            "Learning rate:  0.0001\n",
            "Epoch 15/50\n",
            "32/32 [==============================] - 2s 61ms/step - loss: 0.6067 - accuracy: 0.8360 - val_loss: 1.2233 - val_accuracy: 0.6166\n",
            "Learning rate:  0.0001\n",
            "Epoch 16/50\n",
            "32/32 [==============================] - 2s 60ms/step - loss: 0.6077 - accuracy: 0.8450 - val_loss: 1.2241 - val_accuracy: 0.6144\n",
            "Learning rate:  0.0001\n",
            "Epoch 17/50\n",
            "32/32 [==============================] - 2s 61ms/step - loss: 0.5985 - accuracy: 0.8320 - val_loss: 1.2351 - val_accuracy: 0.6153\n",
            "Learning rate:  0.0001\n",
            "Epoch 18/50\n",
            "32/32 [==============================] - 2s 59ms/step - loss: 0.5850 - accuracy: 0.8380 - val_loss: 1.2280 - val_accuracy: 0.6146\n",
            "Learning rate:  0.0001\n",
            "Epoch 19/50\n",
            "32/32 [==============================] - 2s 60ms/step - loss: 0.5666 - accuracy: 0.8580 - val_loss: 1.2190 - val_accuracy: 0.6173\n",
            "Learning rate:  0.0001\n",
            "Epoch 20/50\n",
            "32/32 [==============================] - 2s 60ms/step - loss: 0.5354 - accuracy: 0.8670 - val_loss: 1.2194 - val_accuracy: 0.6185\n",
            "Learning rate:  0.0001\n",
            "Epoch 21/50\n",
            "32/32 [==============================] - 2s 61ms/step - loss: 0.5530 - accuracy: 0.8640 - val_loss: 1.2532 - val_accuracy: 0.6104\n",
            "Learning rate:  1e-05\n",
            "Epoch 22/50\n",
            "32/32 [==============================] - 2s 60ms/step - loss: 0.5154 - accuracy: 0.8640 - val_loss: 1.2491 - val_accuracy: 0.6136\n",
            "Learning rate:  1e-05\n",
            "Epoch 23/50\n",
            "32/32 [==============================] - 2s 65ms/step - loss: 0.5266 - accuracy: 0.8710 - val_loss: 1.2463 - val_accuracy: 0.6142\n",
            "Learning rate:  1e-05\n",
            "Epoch 24/50\n",
            "32/32 [==============================] - 2s 65ms/step - loss: 0.5418 - accuracy: 0.8590 - val_loss: 1.2485 - val_accuracy: 0.6160\n",
            "Learning rate:  1e-05\n",
            "Epoch 25/50\n",
            "32/32 [==============================] - 2s 65ms/step - loss: 0.4919 - accuracy: 0.8650 - val_loss: 1.2513 - val_accuracy: 0.6145\n",
            "Learning rate:  1e-05\n",
            "Epoch 26/50\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.5135 - accuracy: 0.8670 - val_loss: 1.2539 - val_accuracy: 0.6155\n",
            "Learning rate:  1e-05\n",
            "Epoch 27/50\n",
            "32/32 [==============================] - 2s 65ms/step - loss: 0.5453 - accuracy: 0.8610 - val_loss: 1.2557 - val_accuracy: 0.6155\n",
            "Learning rate:  1e-05\n",
            "Epoch 28/50\n",
            "32/32 [==============================] - 2s 63ms/step - loss: 0.5195 - accuracy: 0.8800 - val_loss: 1.2564 - val_accuracy: 0.6145\n",
            "Learning rate:  1e-05\n",
            "Epoch 29/50\n",
            "32/32 [==============================] - 2s 60ms/step - loss: 0.5272 - accuracy: 0.8580 - val_loss: 1.2595 - val_accuracy: 0.6156\n",
            "Learning rate:  1e-05\n",
            "Epoch 30/50\n",
            "32/32 [==============================] - 2s 61ms/step - loss: 0.5363 - accuracy: 0.8510 - val_loss: 1.2615 - val_accuracy: 0.6145\n",
            "Learning rate:  1e-05\n",
            "Epoch 31/50\n",
            "32/32 [==============================] - 2s 60ms/step - loss: 0.4904 - accuracy: 0.8790 - val_loss: 1.2577 - val_accuracy: 0.6145\n",
            "Learning rate:  1e-06\n",
            "Epoch 32/50\n",
            "32/32 [==============================] - 2s 60ms/step - loss: 0.5166 - accuracy: 0.8730 - val_loss: 1.2579 - val_accuracy: 0.6151\n",
            "Learning rate:  1e-06\n",
            "Epoch 33/50\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 0.5222 - accuracy: 0.8570 - val_loss: 1.2596 - val_accuracy: 0.6146\n",
            "Learning rate:  1e-06\n",
            "Epoch 34/50\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 0.5264 - accuracy: 0.8640 - val_loss: 1.2627 - val_accuracy: 0.6145\n",
            "Learning rate:  1e-06\n",
            "Epoch 35/50\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 0.5177 - accuracy: 0.8720 - val_loss: 1.2623 - val_accuracy: 0.6140\n",
            "Learning rate:  1e-06\n",
            "Epoch 36/50\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 0.5316 - accuracy: 0.8640 - val_loss: 1.2626 - val_accuracy: 0.6144\n",
            "Learning rate:  1e-06\n",
            "Epoch 37/50\n",
            "32/32 [==============================] - 2s 62ms/step - loss: 0.4988 - accuracy: 0.8800 - val_loss: 1.2634 - val_accuracy: 0.6146\n",
            "Learning rate:  1e-06\n",
            "Epoch 38/50\n",
            "32/32 [==============================] - 2s 60ms/step - loss: 0.5187 - accuracy: 0.8560 - val_loss: 1.2641 - val_accuracy: 0.6143\n",
            "Learning rate:  1e-06\n",
            "Epoch 39/50\n",
            "32/32 [==============================] - 2s 61ms/step - loss: 0.5465 - accuracy: 0.8490 - val_loss: 1.2673 - val_accuracy: 0.6142\n",
            "Learning rate:  1e-06\n",
            "Epoch 40/50\n",
            "32/32 [==============================] - 2s 60ms/step - loss: 0.5210 - accuracy: 0.8720 - val_loss: 1.2634 - val_accuracy: 0.6144\n",
            "Learning rate:  1e-06\n",
            "Epoch 41/50\n",
            "32/32 [==============================] - 2s 60ms/step - loss: 0.5069 - accuracy: 0.8690 - val_loss: 1.2631 - val_accuracy: 0.6150\n",
            "Learning rate:  5e-07\n",
            "Epoch 42/50\n",
            "32/32 [==============================] - 2s 61ms/step - loss: 0.5290 - accuracy: 0.8590 - val_loss: 1.2620 - val_accuracy: 0.6155\n",
            "Learning rate:  5e-07\n",
            "Epoch 43/50\n",
            "32/32 [==============================] - 2s 61ms/step - loss: 0.4931 - accuracy: 0.9000 - val_loss: 1.2620 - val_accuracy: 0.6147\n",
            "Learning rate:  5e-07\n",
            "Epoch 44/50\n",
            "32/32 [==============================] - 2s 61ms/step - loss: 0.5095 - accuracy: 0.8760 - val_loss: 1.2625 - val_accuracy: 0.6148\n",
            "Learning rate:  5e-07\n",
            "Epoch 45/50\n",
            "32/32 [==============================] - 2s 61ms/step - loss: 0.5220 - accuracy: 0.8570 - val_loss: 1.2624 - val_accuracy: 0.6148\n",
            "Learning rate:  5e-07\n",
            "Epoch 46/50\n",
            "32/32 [==============================] - 2s 59ms/step - loss: 0.5278 - accuracy: 0.8550 - val_loss: 1.2616 - val_accuracy: 0.6141\n",
            "Learning rate:  5e-07\n",
            "Epoch 47/50\n",
            "32/32 [==============================] - 2s 64ms/step - loss: 0.5392 - accuracy: 0.8650 - val_loss: 1.2606 - val_accuracy: 0.6150\n",
            "Learning rate:  5e-07\n",
            "Epoch 48/50\n",
            "32/32 [==============================] - 2s 65ms/step - loss: 0.5041 - accuracy: 0.8730 - val_loss: 1.2601 - val_accuracy: 0.6149\n",
            "Learning rate:  5e-07\n",
            "Epoch 49/50\n",
            "32/32 [==============================] - 2s 66ms/step - loss: 0.5122 - accuracy: 0.8680 - val_loss: 1.2628 - val_accuracy: 0.6149\n",
            "Learning rate:  5e-07\n",
            "Epoch 50/50\n",
            "32/32 [==============================] - 2s 66ms/step - loss: 0.4903 - accuracy: 0.8820 - val_loss: 1.2630 - val_accuracy: 0.6143\n",
            " -- PATH: self_supervised\n",
            " -- write into csv file\n",
            "Num of trainings: 1\n",
            "Learning rate:  0.001\n",
            "ResNet20\n",
            "Using real-time data augmentation.\n",
            "Learning rate:  0.001\n",
            "Epoch 1/50\n",
            "63/63 [==============================] - 3s 52ms/step - loss: 1.8226 - accuracy: 0.3635 - val_loss: 5.3491 - val_accuracy: 0.1715\n",
            "Learning rate:  0.001\n",
            "Epoch 2/50\n",
            "63/63 [==============================] - 3s 43ms/step - loss: 1.3892 - accuracy: 0.5205 - val_loss: 1.8141 - val_accuracy: 0.4545\n",
            "Learning rate:  0.001\n",
            "Epoch 3/50\n",
            "63/63 [==============================] - 3s 43ms/step - loss: 1.2315 - accuracy: 0.6000 - val_loss: 2.1173 - val_accuracy: 0.4214\n",
            "Learning rate:  0.001\n",
            "Epoch 4/50\n",
            "63/63 [==============================] - 3s 42ms/step - loss: 1.1420 - accuracy: 0.6120 - val_loss: 1.3376 - val_accuracy: 0.5732\n",
            "Learning rate:  0.001\n",
            "Epoch 5/50\n",
            "63/63 [==============================] - 3s 42ms/step - loss: 1.0650 - accuracy: 0.6395 - val_loss: 1.2780 - val_accuracy: 0.5803\n",
            "Learning rate:  0.001\n",
            "Epoch 6/50\n",
            "63/63 [==============================] - 3s 43ms/step - loss: 1.0078 - accuracy: 0.6720 - val_loss: 1.6237 - val_accuracy: 0.5155\n",
            "Learning rate:  0.001\n",
            "Epoch 7/50\n",
            "63/63 [==============================] - 3s 42ms/step - loss: 0.9691 - accuracy: 0.6905 - val_loss: 1.3828 - val_accuracy: 0.5691\n",
            "Learning rate:  0.001\n",
            "Epoch 8/50\n",
            "63/63 [==============================] - 3s 43ms/step - loss: 0.9079 - accuracy: 0.7180 - val_loss: 1.5989 - val_accuracy: 0.5134\n",
            "Learning rate:  0.001\n",
            "Epoch 9/50\n",
            "63/63 [==============================] - 3s 42ms/step - loss: 0.8876 - accuracy: 0.7220 - val_loss: 1.7685 - val_accuracy: 0.5173\n",
            "Learning rate:  0.001\n",
            "Epoch 10/50\n",
            "63/63 [==============================] - 3s 43ms/step - loss: 0.8574 - accuracy: 0.7315 - val_loss: 2.7067 - val_accuracy: 0.4310\n",
            "Learning rate:  0.001\n",
            "Epoch 11/50\n",
            "63/63 [==============================] - 3s 43ms/step - loss: 0.8067 - accuracy: 0.7475 - val_loss: 1.4320 - val_accuracy: 0.5671\n",
            "Learning rate:  0.0001\n",
            "Epoch 12/50\n",
            "63/63 [==============================] - 3s 42ms/step - loss: 0.6895 - accuracy: 0.8085 - val_loss: 1.1872 - val_accuracy: 0.6270\n",
            "Learning rate:  0.0001\n",
            "Epoch 13/50\n",
            "63/63 [==============================] - 3s 42ms/step - loss: 0.6615 - accuracy: 0.8175 - val_loss: 1.0654 - val_accuracy: 0.6596\n",
            "Learning rate:  0.0001\n",
            "Epoch 14/50\n",
            "63/63 [==============================] - 3s 42ms/step - loss: 0.6432 - accuracy: 0.8150 - val_loss: 1.0664 - val_accuracy: 0.6640\n",
            "Learning rate:  0.0001\n",
            "Epoch 15/50\n",
            "63/63 [==============================] - 3s 43ms/step - loss: 0.6190 - accuracy: 0.8300 - val_loss: 1.0684 - val_accuracy: 0.6649\n",
            "Learning rate:  0.0001\n",
            "Epoch 16/50\n",
            "63/63 [==============================] - 3s 43ms/step - loss: 0.5929 - accuracy: 0.8290 - val_loss: 1.0522 - val_accuracy: 0.6694\n",
            "Learning rate:  0.0001\n",
            "Epoch 17/50\n",
            "63/63 [==============================] - 3s 43ms/step - loss: 0.5999 - accuracy: 0.8320 - val_loss: 1.0682 - val_accuracy: 0.6668\n",
            "Learning rate:  0.0001\n",
            "Epoch 18/50\n",
            "63/63 [==============================] - 3s 42ms/step - loss: 0.5849 - accuracy: 0.8355 - val_loss: 1.0870 - val_accuracy: 0.6632\n",
            "Learning rate:  0.0001\n",
            "Epoch 19/50\n",
            "63/63 [==============================] - 3s 43ms/step - loss: 0.5617 - accuracy: 0.8495 - val_loss: 1.0871 - val_accuracy: 0.6670\n",
            "Learning rate:  0.0001\n",
            "Epoch 20/50\n",
            "63/63 [==============================] - 3s 43ms/step - loss: 0.5386 - accuracy: 0.8570 - val_loss: 1.1010 - val_accuracy: 0.6675\n",
            "Learning rate:  0.0001\n",
            "Epoch 21/50\n",
            "63/63 [==============================] - 3s 43ms/step - loss: 0.5402 - accuracy: 0.8480 - val_loss: 1.0920 - val_accuracy: 0.6671\n",
            "Learning rate:  1e-05\n",
            "Epoch 22/50\n",
            "63/63 [==============================] - 3s 42ms/step - loss: 0.5304 - accuracy: 0.8590 - val_loss: 1.0938 - val_accuracy: 0.6688\n",
            "Learning rate:  1e-05\n",
            "Epoch 23/50\n",
            "63/63 [==============================] - 3s 42ms/step - loss: 0.5198 - accuracy: 0.8590 - val_loss: 1.0911 - val_accuracy: 0.6704\n",
            "Learning rate:  1e-05\n",
            "Epoch 24/50\n",
            "63/63 [==============================] - 3s 42ms/step - loss: 0.5334 - accuracy: 0.8565 - val_loss: 1.0938 - val_accuracy: 0.6699\n",
            "Learning rate:  1e-05\n",
            "Epoch 25/50\n",
            "63/63 [==============================] - 3s 42ms/step - loss: 0.5357 - accuracy: 0.8560 - val_loss: 1.0998 - val_accuracy: 0.6674\n",
            "Learning rate:  1e-05\n",
            "Epoch 26/50\n",
            "63/63 [==============================] - 3s 42ms/step - loss: 0.5111 - accuracy: 0.8630 - val_loss: 1.0965 - val_accuracy: 0.6695\n",
            "Learning rate:  1e-05\n",
            "Epoch 27/50\n",
            "63/63 [==============================] - 3s 42ms/step - loss: 0.5258 - accuracy: 0.8570 - val_loss: 1.0989 - val_accuracy: 0.6694\n",
            "Learning rate:  1e-05\n",
            "Epoch 28/50\n",
            "63/63 [==============================] - 3s 41ms/step - loss: 0.5082 - accuracy: 0.8675 - val_loss: 1.0924 - val_accuracy: 0.6697\n",
            "Learning rate:  1e-05\n",
            "Epoch 29/50\n",
            "63/63 [==============================] - 3s 42ms/step - loss: 0.5463 - accuracy: 0.8560 - val_loss: 1.0944 - val_accuracy: 0.6700\n",
            "Learning rate:  1e-05\n",
            "Epoch 30/50\n",
            "63/63 [==============================] - 3s 42ms/step - loss: 0.4983 - accuracy: 0.8700 - val_loss: 1.0936 - val_accuracy: 0.6706\n",
            "Learning rate:  1e-05\n",
            "Epoch 31/50\n",
            "63/63 [==============================] - 3s 42ms/step - loss: 0.5309 - accuracy: 0.8535 - val_loss: 1.0980 - val_accuracy: 0.6697\n",
            "Learning rate:  1e-06\n",
            "Epoch 32/50\n",
            "63/63 [==============================] - 3s 42ms/step - loss: 0.5129 - accuracy: 0.8715 - val_loss: 1.0947 - val_accuracy: 0.6709\n",
            "Learning rate:  1e-06\n",
            "Epoch 33/50\n",
            "63/63 [==============================] - 3s 42ms/step - loss: 0.5090 - accuracy: 0.8620 - val_loss: 1.0948 - val_accuracy: 0.6709\n",
            "Learning rate:  1e-06\n",
            "Epoch 34/50\n",
            "63/63 [==============================] - 3s 42ms/step - loss: 0.5138 - accuracy: 0.8620 - val_loss: 1.0959 - val_accuracy: 0.6700\n",
            "Learning rate:  1e-06\n",
            "Epoch 35/50\n",
            "63/63 [==============================] - 3s 42ms/step - loss: 0.5146 - accuracy: 0.8595 - val_loss: 1.0983 - val_accuracy: 0.6692\n",
            "Learning rate:  1e-06\n",
            "Epoch 36/50\n",
            "63/63 [==============================] - 3s 42ms/step - loss: 0.5092 - accuracy: 0.8640 - val_loss: 1.0989 - val_accuracy: 0.6696\n",
            "Learning rate:  1e-06\n",
            "Epoch 37/50\n",
            "63/63 [==============================] - 3s 42ms/step - loss: 0.5080 - accuracy: 0.8715 - val_loss: 1.0992 - val_accuracy: 0.6697\n",
            "Learning rate:  1e-06\n",
            "Epoch 38/50\n",
            "63/63 [==============================] - 3s 42ms/step - loss: 0.4981 - accuracy: 0.8725 - val_loss: 1.0989 - val_accuracy: 0.6695\n",
            "Learning rate:  1e-06\n",
            "Epoch 39/50\n",
            "63/63 [==============================] - 3s 42ms/step - loss: 0.5175 - accuracy: 0.8615 - val_loss: 1.0991 - val_accuracy: 0.6696\n",
            "Learning rate:  1e-06\n",
            "Epoch 40/50\n",
            "63/63 [==============================] - 3s 42ms/step - loss: 0.5183 - accuracy: 0.8600 - val_loss: 1.0995 - val_accuracy: 0.6692\n",
            "Learning rate:  1e-06\n",
            "Epoch 41/50\n",
            "63/63 [==============================] - 3s 42ms/step - loss: 0.5113 - accuracy: 0.8725 - val_loss: 1.1010 - val_accuracy: 0.6690\n",
            "Learning rate:  5e-07\n",
            "Epoch 42/50\n",
            "63/63 [==============================] - 3s 42ms/step - loss: 0.5201 - accuracy: 0.8605 - val_loss: 1.0997 - val_accuracy: 0.6697\n",
            "Learning rate:  5e-07\n",
            "Epoch 43/50\n",
            "63/63 [==============================] - 3s 42ms/step - loss: 0.4992 - accuracy: 0.8700 - val_loss: 1.0990 - val_accuracy: 0.6695\n",
            "Learning rate:  5e-07\n",
            "Epoch 44/50\n",
            "63/63 [==============================] - 3s 43ms/step - loss: 0.5023 - accuracy: 0.8605 - val_loss: 1.0990 - val_accuracy: 0.6692\n",
            "Learning rate:  5e-07\n",
            "Epoch 45/50\n",
            "63/63 [==============================] - 3s 43ms/step - loss: 0.5009 - accuracy: 0.8665 - val_loss: 1.0990 - val_accuracy: 0.6693\n",
            "Learning rate:  5e-07\n",
            "Epoch 46/50\n",
            "63/63 [==============================] - 3s 43ms/step - loss: 0.5134 - accuracy: 0.8665 - val_loss: 1.0997 - val_accuracy: 0.6694\n",
            "Learning rate:  5e-07\n",
            "Epoch 47/50\n",
            "63/63 [==============================] - 3s 43ms/step - loss: 0.5103 - accuracy: 0.8540 - val_loss: 1.0979 - val_accuracy: 0.6700\n",
            "Learning rate:  5e-07\n",
            "Epoch 48/50\n",
            "63/63 [==============================] - 3s 42ms/step - loss: 0.5222 - accuracy: 0.8560 - val_loss: 1.0987 - val_accuracy: 0.6700\n",
            "Learning rate:  5e-07\n",
            "Epoch 49/50\n",
            "63/63 [==============================] - 3s 42ms/step - loss: 0.5248 - accuracy: 0.8630 - val_loss: 1.1005 - val_accuracy: 0.6694\n",
            "Learning rate:  5e-07\n",
            "Epoch 50/50\n",
            "63/63 [==============================] - 3s 42ms/step - loss: 0.5187 - accuracy: 0.8570 - val_loss: 1.1002 - val_accuracy: 0.6698\n",
            " -- PATH: self_supervised\n",
            " -- write into csv file\n",
            "Num of trainings: 2\n",
            "Learning rate:  0.001\n",
            "ResNet20\n",
            "Using real-time data augmentation.\n",
            "Learning rate:  0.001\n",
            "Epoch 1/50\n",
            "94/94 [==============================] - 4s 42ms/step - loss: 1.6494 - accuracy: 0.4377 - val_loss: 3.5832 - val_accuracy: 0.3427\n",
            "Learning rate:  0.001\n",
            "Epoch 2/50\n",
            "94/94 [==============================] - 3s 36ms/step - loss: 1.2882 - accuracy: 0.5573 - val_loss: 1.7017 - val_accuracy: 0.4863\n",
            "Learning rate:  0.001\n",
            "Epoch 3/50\n",
            "94/94 [==============================] - 3s 36ms/step - loss: 1.1743 - accuracy: 0.6043 - val_loss: 1.7270 - val_accuracy: 0.4998\n",
            "Learning rate:  0.001\n",
            "Epoch 4/50\n",
            "94/94 [==============================] - 3s 36ms/step - loss: 1.0972 - accuracy: 0.6387 - val_loss: 1.4249 - val_accuracy: 0.5549\n",
            "Learning rate:  0.001\n",
            "Epoch 5/50\n",
            "94/94 [==============================] - 3s 36ms/step - loss: 1.0296 - accuracy: 0.6647 - val_loss: 1.2762 - val_accuracy: 0.5731\n",
            "Learning rate:  0.001\n",
            "Epoch 6/50\n",
            "94/94 [==============================] - 3s 35ms/step - loss: 0.9991 - accuracy: 0.6747 - val_loss: 1.5019 - val_accuracy: 0.5541\n",
            "Learning rate:  0.001\n",
            "Epoch 7/50\n",
            "94/94 [==============================] - 3s 35ms/step - loss: 0.9380 - accuracy: 0.7010 - val_loss: 1.5566 - val_accuracy: 0.5561\n",
            "Learning rate:  0.001\n",
            "Epoch 8/50\n",
            "94/94 [==============================] - 3s 36ms/step - loss: 0.8999 - accuracy: 0.7110 - val_loss: 1.4747 - val_accuracy: 0.5715\n",
            "Learning rate:  0.001\n",
            "Epoch 9/50\n",
            "94/94 [==============================] - 3s 36ms/step - loss: 0.8451 - accuracy: 0.7277 - val_loss: 1.2654 - val_accuracy: 0.6253\n",
            "Learning rate:  0.001\n",
            "Epoch 10/50\n",
            "94/94 [==============================] - 3s 36ms/step - loss: 0.8350 - accuracy: 0.7360 - val_loss: 1.3021 - val_accuracy: 0.6108\n",
            "Learning rate:  0.001\n",
            "Epoch 11/50\n",
            "94/94 [==============================] - 3s 36ms/step - loss: 0.7849 - accuracy: 0.7563 - val_loss: 1.2491 - val_accuracy: 0.6127\n",
            "Learning rate:  0.0001\n",
            "Epoch 12/50\n",
            "94/94 [==============================] - 3s 36ms/step - loss: 0.7005 - accuracy: 0.7883 - val_loss: 0.9997 - val_accuracy: 0.6837\n",
            "Learning rate:  0.0001\n",
            "Epoch 13/50\n",
            "94/94 [==============================] - 3s 36ms/step - loss: 0.6501 - accuracy: 0.8033 - val_loss: 0.9866 - val_accuracy: 0.6919\n",
            "Learning rate:  0.0001\n",
            "Epoch 14/50\n",
            "94/94 [==============================] - 3s 36ms/step - loss: 0.6124 - accuracy: 0.8207 - val_loss: 1.0111 - val_accuracy: 0.6853\n",
            "Learning rate:  0.0001\n",
            "Epoch 15/50\n",
            "94/94 [==============================] - 3s 36ms/step - loss: 0.5893 - accuracy: 0.8317 - val_loss: 0.9955 - val_accuracy: 0.6937\n",
            "Learning rate:  0.0001\n",
            "Epoch 16/50\n",
            "94/94 [==============================] - 3s 36ms/step - loss: 0.5853 - accuracy: 0.8370 - val_loss: 0.9857 - val_accuracy: 0.6989\n",
            "Learning rate:  0.0001\n",
            "Epoch 17/50\n",
            "94/94 [==============================] - 3s 36ms/step - loss: 0.5631 - accuracy: 0.8457 - val_loss: 1.0212 - val_accuracy: 0.6923\n",
            "Learning rate:  0.0001\n",
            "Epoch 18/50\n",
            "94/94 [==============================] - 3s 36ms/step - loss: 0.5588 - accuracy: 0.8427 - val_loss: 1.0063 - val_accuracy: 0.6995\n",
            "Learning rate:  0.0001\n",
            "Epoch 19/50\n",
            "94/94 [==============================] - 3s 36ms/step - loss: 0.5467 - accuracy: 0.8527 - val_loss: 1.0085 - val_accuracy: 0.6978\n",
            "Learning rate:  0.0001\n",
            "Epoch 20/50\n",
            "94/94 [==============================] - 3s 36ms/step - loss: 0.5288 - accuracy: 0.8533 - val_loss: 1.0162 - val_accuracy: 0.6950\n",
            "Learning rate:  0.0001\n",
            "Epoch 21/50\n",
            "94/94 [==============================] - 3s 36ms/step - loss: 0.5431 - accuracy: 0.8593 - val_loss: 1.0085 - val_accuracy: 0.6983\n",
            "Learning rate:  1e-05\n",
            "Epoch 22/50\n",
            "94/94 [==============================] - 3s 36ms/step - loss: 0.5192 - accuracy: 0.8547 - val_loss: 1.0081 - val_accuracy: 0.7012\n",
            "Learning rate:  1e-05\n",
            "Epoch 23/50\n",
            "94/94 [==============================] - 3s 37ms/step - loss: 0.5104 - accuracy: 0.8607 - val_loss: 1.0084 - val_accuracy: 0.6999\n",
            "Learning rate:  1e-05\n",
            "Epoch 24/50\n",
            "94/94 [==============================] - 3s 37ms/step - loss: 0.4970 - accuracy: 0.8687 - val_loss: 1.0079 - val_accuracy: 0.6991\n",
            "Learning rate:  1e-05\n",
            "Epoch 25/50\n",
            "94/94 [==============================] - 3s 36ms/step - loss: 0.5206 - accuracy: 0.8570 - val_loss: 1.0063 - val_accuracy: 0.7012\n",
            "Learning rate:  1e-05\n",
            "Epoch 26/50\n",
            "94/94 [==============================] - 3s 35ms/step - loss: 0.5047 - accuracy: 0.8680 - val_loss: 1.0071 - val_accuracy: 0.7011\n",
            "Learning rate:  1e-05\n",
            "Epoch 27/50\n",
            "94/94 [==============================] - 3s 35ms/step - loss: 0.5041 - accuracy: 0.8680 - val_loss: 1.0031 - val_accuracy: 0.7022\n",
            "Learning rate:  1e-05\n",
            "Epoch 28/50\n",
            "94/94 [==============================] - 3s 36ms/step - loss: 0.4990 - accuracy: 0.8737 - val_loss: 0.9994 - val_accuracy: 0.7031\n",
            "Learning rate:  1e-05\n",
            "Epoch 29/50\n",
            "94/94 [==============================] - 3s 36ms/step - loss: 0.4961 - accuracy: 0.8717 - val_loss: 1.0082 - val_accuracy: 0.7008\n",
            "Learning rate:  1e-05\n",
            "Epoch 30/50\n",
            "94/94 [==============================] - 3s 36ms/step - loss: 0.5039 - accuracy: 0.8683 - val_loss: 1.0100 - val_accuracy: 0.7002\n",
            "Learning rate:  1e-05\n",
            "Epoch 31/50\n",
            "94/94 [==============================] - 3s 36ms/step - loss: 0.5046 - accuracy: 0.8670 - val_loss: 1.0048 - val_accuracy: 0.7013\n",
            "Learning rate:  1e-06\n",
            "Epoch 32/50\n",
            "94/94 [==============================] - 4s 37ms/step - loss: 0.4971 - accuracy: 0.8793 - val_loss: 1.0077 - val_accuracy: 0.7013\n",
            "Learning rate:  1e-06\n",
            "Epoch 33/50\n",
            "94/94 [==============================] - 4s 38ms/step - loss: 0.4905 - accuracy: 0.8750 - val_loss: 1.0080 - val_accuracy: 0.7010\n",
            "Learning rate:  1e-06\n",
            "Epoch 34/50\n",
            "94/94 [==============================] - 3s 37ms/step - loss: 0.4855 - accuracy: 0.8750 - val_loss: 1.0096 - val_accuracy: 0.7000\n",
            "Learning rate:  1e-06\n",
            "Epoch 35/50\n",
            "94/94 [==============================] - 3s 36ms/step - loss: 0.5005 - accuracy: 0.8663 - val_loss: 1.0087 - val_accuracy: 0.7007\n",
            "Learning rate:  1e-06\n",
            "Epoch 36/50\n",
            "94/94 [==============================] - 3s 35ms/step - loss: 0.5054 - accuracy: 0.8650 - val_loss: 1.0068 - val_accuracy: 0.7020\n",
            "Learning rate:  1e-06\n",
            "Epoch 37/50\n",
            "94/94 [==============================] - 3s 36ms/step - loss: 0.4906 - accuracy: 0.8717 - val_loss: 1.0067 - val_accuracy: 0.7015\n",
            "Learning rate:  1e-06\n",
            "Epoch 38/50\n",
            "94/94 [==============================] - 3s 36ms/step - loss: 0.4865 - accuracy: 0.8653 - val_loss: 1.0060 - val_accuracy: 0.7010\n",
            "Learning rate:  1e-06\n",
            "Epoch 39/50\n",
            "94/94 [==============================] - 3s 36ms/step - loss: 0.5028 - accuracy: 0.8663 - val_loss: 1.0063 - val_accuracy: 0.7010\n",
            "Learning rate:  1e-06\n",
            "Epoch 40/50\n",
            "94/94 [==============================] - 3s 35ms/step - loss: 0.4820 - accuracy: 0.8797 - val_loss: 1.0062 - val_accuracy: 0.7006\n",
            "Learning rate:  1e-06\n",
            "Epoch 41/50\n",
            "94/94 [==============================] - 3s 36ms/step - loss: 0.4819 - accuracy: 0.8783 - val_loss: 1.0056 - val_accuracy: 0.7006\n",
            "Learning rate:  5e-07\n",
            "Epoch 42/50\n",
            "94/94 [==============================] - 3s 36ms/step - loss: 0.5053 - accuracy: 0.8630 - val_loss: 1.0069 - val_accuracy: 0.7017\n",
            "Learning rate:  5e-07\n",
            "Epoch 43/50\n",
            "94/94 [==============================] - 3s 36ms/step - loss: 0.5049 - accuracy: 0.8657 - val_loss: 1.0072 - val_accuracy: 0.7017\n",
            "Learning rate:  5e-07\n",
            "Epoch 44/50\n",
            "94/94 [==============================] - 3s 35ms/step - loss: 0.4865 - accuracy: 0.8723 - val_loss: 1.0076 - val_accuracy: 0.7011\n",
            "Learning rate:  5e-07\n",
            "Epoch 45/50\n",
            "94/94 [==============================] - 3s 35ms/step - loss: 0.5055 - accuracy: 0.8657 - val_loss: 1.0063 - val_accuracy: 0.7012\n",
            "Learning rate:  5e-07\n",
            "Epoch 46/50\n",
            "94/94 [==============================] - 3s 35ms/step - loss: 0.4917 - accuracy: 0.8660 - val_loss: 1.0056 - val_accuracy: 0.7020\n",
            "Learning rate:  5e-07\n",
            "Epoch 47/50\n",
            "94/94 [==============================] - 3s 35ms/step - loss: 0.4925 - accuracy: 0.8697 - val_loss: 1.0080 - val_accuracy: 0.7006\n",
            "Learning rate:  5e-07\n",
            "Epoch 48/50\n",
            "94/94 [==============================] - 3s 36ms/step - loss: 0.4969 - accuracy: 0.8707 - val_loss: 1.0064 - val_accuracy: 0.7012\n",
            "Learning rate:  5e-07\n",
            "Epoch 49/50\n",
            "94/94 [==============================] - 3s 35ms/step - loss: 0.5049 - accuracy: 0.8640 - val_loss: 1.0068 - val_accuracy: 0.7014\n",
            "Learning rate:  5e-07\n",
            "Epoch 50/50\n",
            "94/94 [==============================] - 3s 35ms/step - loss: 0.4882 - accuracy: 0.8690 - val_loss: 1.0053 - val_accuracy: 0.7017\n",
            " -- PATH: self_supervised\n",
            " -- write into csv file\n",
            "Num of trainings: 3\n",
            "Learning rate:  0.001\n",
            "ResNet20\n",
            "Using real-time data augmentation.\n",
            "Learning rate:  0.001\n",
            "Epoch 1/50\n",
            "125/125 [==============================] - 5s 37ms/step - loss: 1.5938 - accuracy: 0.4450 - val_loss: 2.0916 - val_accuracy: 0.4346\n",
            "Learning rate:  0.001\n",
            "Epoch 2/50\n",
            "125/125 [==============================] - 4s 32ms/step - loss: 1.2721 - accuracy: 0.5705 - val_loss: 1.7487 - val_accuracy: 0.4648\n",
            "Learning rate:  0.001\n",
            "Epoch 3/50\n",
            "125/125 [==============================] - 4s 32ms/step - loss: 1.1654 - accuracy: 0.6175 - val_loss: 1.2073 - val_accuracy: 0.5967\n",
            "Learning rate:  0.001\n",
            "Epoch 4/50\n",
            "125/125 [==============================] - 4s 32ms/step - loss: 1.0953 - accuracy: 0.6373 - val_loss: 1.5381 - val_accuracy: 0.5393\n",
            "Learning rate:  0.001\n",
            "Epoch 5/50\n",
            "125/125 [==============================] - 4s 33ms/step - loss: 1.0165 - accuracy: 0.6687 - val_loss: 1.4007 - val_accuracy: 0.5762\n",
            "Learning rate:  0.001\n",
            "Epoch 6/50\n",
            "125/125 [==============================] - 4s 32ms/step - loss: 0.9810 - accuracy: 0.6780 - val_loss: 1.4668 - val_accuracy: 0.5658\n",
            "Learning rate:  0.001\n",
            "Epoch 7/50\n",
            "125/125 [==============================] - 4s 32ms/step - loss: 0.9153 - accuracy: 0.7057 - val_loss: 1.8873 - val_accuracy: 0.5051\n",
            "Learning rate:  0.001\n",
            "Epoch 8/50\n",
            "125/125 [==============================] - 4s 32ms/step - loss: 0.9019 - accuracy: 0.7160 - val_loss: 1.5077 - val_accuracy: 0.5542\n",
            "Learning rate:  0.001\n",
            "Epoch 9/50\n",
            "125/125 [==============================] - 4s 32ms/step - loss: 0.8778 - accuracy: 0.7240 - val_loss: 1.3106 - val_accuracy: 0.6087\n",
            "Learning rate:  0.001\n",
            "Epoch 10/50\n",
            "125/125 [==============================] - 4s 32ms/step - loss: 0.8297 - accuracy: 0.7405 - val_loss: 1.1628 - val_accuracy: 0.6461\n",
            "Learning rate:  0.001\n",
            "Epoch 11/50\n",
            "125/125 [==============================] - 4s 32ms/step - loss: 0.8198 - accuracy: 0.7485 - val_loss: 1.1803 - val_accuracy: 0.6510\n",
            "Learning rate:  0.0001\n",
            "Epoch 12/50\n",
            "125/125 [==============================] - 4s 33ms/step - loss: 0.6890 - accuracy: 0.8027 - val_loss: 0.9803 - val_accuracy: 0.6986\n",
            "Learning rate:  0.0001\n",
            "Epoch 13/50\n",
            "125/125 [==============================] - 4s 33ms/step - loss: 0.6216 - accuracy: 0.8280 - val_loss: 0.9407 - val_accuracy: 0.7128\n",
            "Learning rate:  0.0001\n",
            "Epoch 14/50\n",
            "125/125 [==============================] - 4s 32ms/step - loss: 0.6026 - accuracy: 0.8332 - val_loss: 0.9252 - val_accuracy: 0.7173\n",
            "Learning rate:  0.0001\n",
            "Epoch 15/50\n",
            "125/125 [==============================] - 4s 32ms/step - loss: 0.5909 - accuracy: 0.8380 - val_loss: 0.9379 - val_accuracy: 0.7188\n",
            "Learning rate:  0.0001\n",
            "Epoch 16/50\n",
            "125/125 [==============================] - 4s 32ms/step - loss: 0.5758 - accuracy: 0.8388 - val_loss: 0.9634 - val_accuracy: 0.7110\n",
            "Learning rate:  0.0001\n",
            "Epoch 17/50\n",
            "125/125 [==============================] - 4s 32ms/step - loss: 0.5520 - accuracy: 0.8482 - val_loss: 0.9524 - val_accuracy: 0.7180\n",
            "Learning rate:  0.0001\n",
            "Epoch 18/50\n",
            "125/125 [==============================] - 4s 32ms/step - loss: 0.5470 - accuracy: 0.8490 - val_loss: 0.9435 - val_accuracy: 0.7203\n",
            "Learning rate:  0.0001\n",
            "Epoch 19/50\n",
            "125/125 [==============================] - 4s 32ms/step - loss: 0.5439 - accuracy: 0.8572 - val_loss: 0.9600 - val_accuracy: 0.7168\n",
            "Learning rate:  0.0001\n",
            "Epoch 20/50\n",
            "125/125 [==============================] - 4s 32ms/step - loss: 0.5522 - accuracy: 0.8525 - val_loss: 0.9630 - val_accuracy: 0.7150\n",
            "Learning rate:  0.0001\n",
            "Epoch 21/50\n",
            "125/125 [==============================] - 4s 32ms/step - loss: 0.5455 - accuracy: 0.8443 - val_loss: 0.9591 - val_accuracy: 0.7195\n",
            "Learning rate:  1e-05\n",
            "Epoch 22/50\n",
            "125/125 [==============================] - 4s 32ms/step - loss: 0.5001 - accuracy: 0.8660 - val_loss: 0.9491 - val_accuracy: 0.7230\n",
            "Learning rate:  1e-05\n",
            "Epoch 23/50\n",
            "125/125 [==============================] - 4s 32ms/step - loss: 0.5131 - accuracy: 0.8620 - val_loss: 0.9421 - val_accuracy: 0.7250\n",
            "Learning rate:  1e-05\n",
            "Epoch 24/50\n",
            "125/125 [==============================] - 4s 31ms/step - loss: 0.5046 - accuracy: 0.8685 - val_loss: 0.9466 - val_accuracy: 0.7244\n",
            "Learning rate:  1e-05\n",
            "Epoch 25/50\n",
            "125/125 [==============================] - 4s 32ms/step - loss: 0.5072 - accuracy: 0.8670 - val_loss: 0.9493 - val_accuracy: 0.7243\n",
            "Learning rate:  1e-05\n",
            "Epoch 26/50\n",
            "125/125 [==============================] - 4s 32ms/step - loss: 0.5065 - accuracy: 0.8590 - val_loss: 0.9463 - val_accuracy: 0.7235\n",
            "Learning rate:  1e-05\n",
            "Epoch 27/50\n",
            "125/125 [==============================] - 4s 32ms/step - loss: 0.5145 - accuracy: 0.8602 - val_loss: 0.9453 - val_accuracy: 0.7248\n",
            "Learning rate:  1e-05\n",
            "Epoch 28/50\n",
            "125/125 [==============================] - 4s 33ms/step - loss: 0.5017 - accuracy: 0.8680 - val_loss: 0.9487 - val_accuracy: 0.7249\n",
            "Learning rate:  1e-05\n",
            "Epoch 29/50\n",
            "125/125 [==============================] - 4s 32ms/step - loss: 0.5079 - accuracy: 0.8658 - val_loss: 0.9456 - val_accuracy: 0.7280\n",
            "Learning rate:  1e-05\n",
            "Epoch 30/50\n",
            "125/125 [==============================] - 4s 32ms/step - loss: 0.5110 - accuracy: 0.8655 - val_loss: 0.9525 - val_accuracy: 0.7250\n",
            "Learning rate:  1e-05\n",
            "Epoch 31/50\n",
            "125/125 [==============================] - 4s 32ms/step - loss: 0.5085 - accuracy: 0.8660 - val_loss: 0.9471 - val_accuracy: 0.7265\n",
            "Learning rate:  1e-06\n",
            "Epoch 32/50\n",
            "125/125 [==============================] - 4s 33ms/step - loss: 0.4898 - accuracy: 0.8720 - val_loss: 0.9471 - val_accuracy: 0.7260\n",
            "Learning rate:  1e-06\n",
            "Epoch 33/50\n",
            "125/125 [==============================] - 4s 32ms/step - loss: 0.4825 - accuracy: 0.8790 - val_loss: 0.9486 - val_accuracy: 0.7263\n",
            "Learning rate:  1e-06\n",
            "Epoch 34/50\n",
            "125/125 [==============================] - 4s 32ms/step - loss: 0.5052 - accuracy: 0.8665 - val_loss: 0.9460 - val_accuracy: 0.7266\n",
            "Learning rate:  1e-06\n",
            "Epoch 35/50\n",
            "125/125 [==============================] - 4s 32ms/step - loss: 0.4858 - accuracy: 0.8737 - val_loss: 0.9486 - val_accuracy: 0.7257\n",
            "Learning rate:  1e-06\n",
            "Epoch 36/50\n",
            "125/125 [==============================] - 4s 32ms/step - loss: 0.5026 - accuracy: 0.8677 - val_loss: 0.9481 - val_accuracy: 0.7262\n",
            "Learning rate:  1e-06\n",
            "Epoch 37/50\n",
            "125/125 [==============================] - 4s 33ms/step - loss: 0.5061 - accuracy: 0.8668 - val_loss: 0.9476 - val_accuracy: 0.7265\n",
            "Learning rate:  1e-06\n",
            "Epoch 38/50\n",
            "125/125 [==============================] - 4s 32ms/step - loss: 0.5053 - accuracy: 0.8692 - val_loss: 0.9467 - val_accuracy: 0.7268\n",
            "Learning rate:  1e-06\n",
            "Epoch 39/50\n",
            "125/125 [==============================] - 4s 32ms/step - loss: 0.5008 - accuracy: 0.8695 - val_loss: 0.9501 - val_accuracy: 0.7244\n",
            "Learning rate:  1e-06\n",
            "Epoch 40/50\n",
            "125/125 [==============================] - 4s 32ms/step - loss: 0.4899 - accuracy: 0.8737 - val_loss: 0.9490 - val_accuracy: 0.7261\n",
            "Learning rate:  1e-06\n",
            "Epoch 41/50\n",
            "125/125 [==============================] - 4s 32ms/step - loss: 0.4976 - accuracy: 0.8710 - val_loss: 0.9481 - val_accuracy: 0.7259\n",
            "Learning rate:  5e-07\n",
            "Epoch 42/50\n",
            "125/125 [==============================] - 4s 33ms/step - loss: 0.5001 - accuracy: 0.8612 - val_loss: 0.9467 - val_accuracy: 0.7267\n",
            "Learning rate:  5e-07\n",
            "Epoch 43/50\n",
            "125/125 [==============================] - 4s 32ms/step - loss: 0.4990 - accuracy: 0.8752 - val_loss: 0.9495 - val_accuracy: 0.7252\n",
            "Learning rate:  5e-07\n",
            "Epoch 44/50\n",
            "125/125 [==============================] - 4s 33ms/step - loss: 0.5026 - accuracy: 0.8745 - val_loss: 0.9493 - val_accuracy: 0.7262\n",
            "Learning rate:  5e-07\n",
            "Epoch 45/50\n",
            "125/125 [==============================] - 4s 33ms/step - loss: 0.5133 - accuracy: 0.8635 - val_loss: 0.9482 - val_accuracy: 0.7263\n",
            "Learning rate:  5e-07\n",
            "Epoch 46/50\n",
            "125/125 [==============================] - 4s 33ms/step - loss: 0.5021 - accuracy: 0.8685 - val_loss: 0.9491 - val_accuracy: 0.7252\n",
            "Learning rate:  5e-07\n",
            "Epoch 47/50\n",
            "125/125 [==============================] - 4s 33ms/step - loss: 0.4937 - accuracy: 0.8668 - val_loss: 0.9482 - val_accuracy: 0.7256\n",
            "Learning rate:  5e-07\n",
            "Epoch 48/50\n",
            "125/125 [==============================] - 4s 33ms/step - loss: 0.4950 - accuracy: 0.8630 - val_loss: 0.9517 - val_accuracy: 0.7249\n",
            "Learning rate:  5e-07\n",
            "Epoch 49/50\n",
            "125/125 [==============================] - 4s 33ms/step - loss: 0.4899 - accuracy: 0.8712 - val_loss: 0.9484 - val_accuracy: 0.7263\n",
            "Learning rate:  5e-07\n",
            "Epoch 50/50\n",
            "125/125 [==============================] - 4s 33ms/step - loss: 0.4921 - accuracy: 0.8700 - val_loss: 0.9486 - val_accuracy: 0.7255\n",
            " -- PATH: self_supervised\n",
            " -- write into csv file\n",
            "Num of trainings: 4\n",
            "Learning rate:  0.001\n",
            "ResNet20\n",
            "Using real-time data augmentation.\n",
            "Learning rate:  0.001\n",
            "Epoch 1/50\n",
            "157/157 [==============================] - 5s 35ms/step - loss: 1.5771 - accuracy: 0.4624 - val_loss: 1.7765 - val_accuracy: 0.4648\n",
            "Learning rate:  0.001\n",
            "Epoch 2/50\n",
            "157/157 [==============================] - 5s 31ms/step - loss: 1.2377 - accuracy: 0.5914 - val_loss: 1.4357 - val_accuracy: 0.5385\n",
            "Learning rate:  0.001\n",
            "Epoch 3/50\n",
            "157/157 [==============================] - 5s 31ms/step - loss: 1.1232 - accuracy: 0.6372 - val_loss: 1.5406 - val_accuracy: 0.5373\n",
            "Learning rate:  0.001\n",
            "Epoch 4/50\n",
            "157/157 [==============================] - 5s 31ms/step - loss: 1.0455 - accuracy: 0.6542 - val_loss: 1.5109 - val_accuracy: 0.5548\n",
            "Learning rate:  0.001\n",
            "Epoch 5/50\n",
            "157/157 [==============================] - 5s 31ms/step - loss: 0.9743 - accuracy: 0.6936 - val_loss: 1.4613 - val_accuracy: 0.5611\n",
            "Learning rate:  0.001\n",
            "Epoch 6/50\n",
            "157/157 [==============================] - 5s 30ms/step - loss: 0.9513 - accuracy: 0.6918 - val_loss: 1.1729 - val_accuracy: 0.6377\n",
            "Learning rate:  0.001\n",
            "Epoch 7/50\n",
            "157/157 [==============================] - 5s 32ms/step - loss: 0.8996 - accuracy: 0.7218 - val_loss: 1.1458 - val_accuracy: 0.6452\n",
            "Learning rate:  0.001\n",
            "Epoch 8/50\n",
            "157/157 [==============================] - 5s 33ms/step - loss: 0.8487 - accuracy: 0.7318 - val_loss: 2.0775 - val_accuracy: 0.4894\n",
            "Learning rate:  0.001\n",
            "Epoch 9/50\n",
            "157/157 [==============================] - 5s 31ms/step - loss: 0.8278 - accuracy: 0.7454 - val_loss: 1.5968 - val_accuracy: 0.5644\n",
            "Learning rate:  0.001\n",
            "Epoch 10/50\n",
            "157/157 [==============================] - 5s 31ms/step - loss: 0.8185 - accuracy: 0.7488 - val_loss: 1.4592 - val_accuracy: 0.5813\n",
            "Learning rate:  0.001\n",
            "Epoch 11/50\n",
            "157/157 [==============================] - 5s 31ms/step - loss: 0.7779 - accuracy: 0.7632 - val_loss: 1.4668 - val_accuracy: 0.6062\n",
            "Learning rate:  0.0001\n",
            "Epoch 12/50\n",
            "157/157 [==============================] - 5s 31ms/step - loss: 0.6678 - accuracy: 0.8058 - val_loss: 0.9009 - val_accuracy: 0.7267\n",
            "Learning rate:  0.0001\n",
            "Epoch 13/50\n",
            "157/157 [==============================] - 5s 32ms/step - loss: 0.6185 - accuracy: 0.8266 - val_loss: 0.9087 - val_accuracy: 0.7316\n",
            "Learning rate:  0.0001\n",
            "Epoch 14/50\n",
            "157/157 [==============================] - 5s 31ms/step - loss: 0.5942 - accuracy: 0.8312 - val_loss: 0.8600 - val_accuracy: 0.7439\n",
            "Learning rate:  0.0001\n",
            "Epoch 15/50\n",
            "157/157 [==============================] - 5s 31ms/step - loss: 0.5900 - accuracy: 0.8344 - val_loss: 0.8956 - val_accuracy: 0.7333\n",
            "Learning rate:  0.0001\n",
            "Epoch 16/50\n",
            "157/157 [==============================] - 5s 31ms/step - loss: 0.5616 - accuracy: 0.8438 - val_loss: 0.8781 - val_accuracy: 0.7407\n",
            "Learning rate:  0.0001\n",
            "Epoch 17/50\n",
            "157/157 [==============================] - 5s 31ms/step - loss: 0.5728 - accuracy: 0.8382 - val_loss: 0.8891 - val_accuracy: 0.7393\n",
            "Learning rate:  0.0001\n",
            "Epoch 18/50\n",
            "157/157 [==============================] - 5s 31ms/step - loss: 0.5416 - accuracy: 0.8540 - val_loss: 0.8732 - val_accuracy: 0.7439\n",
            "Learning rate:  0.0001\n",
            "Epoch 19/50\n",
            "157/157 [==============================] - 5s 31ms/step - loss: 0.5322 - accuracy: 0.8522 - val_loss: 0.8825 - val_accuracy: 0.7451\n",
            "Learning rate:  0.0001\n",
            "Epoch 20/50\n",
            "157/157 [==============================] - 5s 31ms/step - loss: 0.5362 - accuracy: 0.8546 - val_loss: 0.8895 - val_accuracy: 0.7399\n",
            "Learning rate:  0.0001\n",
            "Epoch 21/50\n",
            "157/157 [==============================] - 5s 31ms/step - loss: 0.5365 - accuracy: 0.8550 - val_loss: 0.8760 - val_accuracy: 0.7472\n",
            "Learning rate:  1e-05\n",
            "Epoch 22/50\n",
            "157/157 [==============================] - 5s 31ms/step - loss: 0.4954 - accuracy: 0.8678 - val_loss: 0.8810 - val_accuracy: 0.7472\n",
            "Learning rate:  1e-05\n",
            "Epoch 23/50\n",
            "157/157 [==============================] - 5s 31ms/step - loss: 0.5049 - accuracy: 0.8636 - val_loss: 0.8798 - val_accuracy: 0.7466\n",
            "Learning rate:  1e-05\n",
            "Epoch 24/50\n",
            "157/157 [==============================] - 5s 31ms/step - loss: 0.5054 - accuracy: 0.8616 - val_loss: 0.8803 - val_accuracy: 0.7465\n",
            "Learning rate:  1e-05\n",
            "Epoch 25/50\n",
            "157/157 [==============================] - 5s 31ms/step - loss: 0.5035 - accuracy: 0.8666 - val_loss: 0.8837 - val_accuracy: 0.7468\n",
            "Learning rate:  1e-05\n",
            "Epoch 26/50\n",
            "157/157 [==============================] - 5s 31ms/step - loss: 0.5057 - accuracy: 0.8692 - val_loss: 0.8822 - val_accuracy: 0.7460\n",
            "Learning rate:  1e-05\n",
            "Epoch 27/50\n",
            "157/157 [==============================] - 5s 30ms/step - loss: 0.5048 - accuracy: 0.8628 - val_loss: 0.8840 - val_accuracy: 0.7463\n",
            "Learning rate:  1e-05\n",
            "Epoch 28/50\n",
            "157/157 [==============================] - 5s 31ms/step - loss: 0.5008 - accuracy: 0.8664 - val_loss: 0.8833 - val_accuracy: 0.7458\n",
            "Learning rate:  1e-05\n",
            "Epoch 29/50\n",
            "157/157 [==============================] - 5s 30ms/step - loss: 0.4953 - accuracy: 0.8714 - val_loss: 0.8841 - val_accuracy: 0.7456\n",
            "Learning rate:  1e-05\n",
            "Epoch 30/50\n",
            "157/157 [==============================] - 5s 31ms/step - loss: 0.4859 - accuracy: 0.8730 - val_loss: 0.8856 - val_accuracy: 0.7446\n",
            "Learning rate:  1e-05\n",
            "Epoch 31/50\n",
            "157/157 [==============================] - 5s 30ms/step - loss: 0.5008 - accuracy: 0.8674 - val_loss: 0.8846 - val_accuracy: 0.7445\n",
            "Learning rate:  1e-06\n",
            "Epoch 32/50\n",
            "157/157 [==============================] - 5s 31ms/step - loss: 0.4757 - accuracy: 0.8752 - val_loss: 0.8836 - val_accuracy: 0.7450\n",
            "Learning rate:  1e-06\n",
            "Epoch 33/50\n",
            "157/157 [==============================] - 5s 31ms/step - loss: 0.4831 - accuracy: 0.8762 - val_loss: 0.8844 - val_accuracy: 0.7444\n",
            "Learning rate:  1e-06\n",
            "Epoch 34/50\n",
            "157/157 [==============================] - 5s 31ms/step - loss: 0.4924 - accuracy: 0.8694 - val_loss: 0.8833 - val_accuracy: 0.7457\n",
            "Learning rate:  1e-06\n",
            "Epoch 35/50\n",
            "157/157 [==============================] - 5s 30ms/step - loss: 0.4886 - accuracy: 0.8740 - val_loss: 0.8822 - val_accuracy: 0.7452\n",
            "Learning rate:  1e-06\n",
            "Epoch 36/50\n",
            "157/157 [==============================] - 5s 31ms/step - loss: 0.4927 - accuracy: 0.8712 - val_loss: 0.8852 - val_accuracy: 0.7453\n",
            "Learning rate:  1e-06\n",
            "Epoch 37/50\n",
            "157/157 [==============================] - 5s 31ms/step - loss: 0.4974 - accuracy: 0.8676 - val_loss: 0.8856 - val_accuracy: 0.7449\n",
            "Learning rate:  1e-06\n",
            "Epoch 38/50\n",
            "157/157 [==============================] - 5s 31ms/step - loss: 0.4943 - accuracy: 0.8704 - val_loss: 0.8858 - val_accuracy: 0.7449\n",
            "Learning rate:  1e-06\n",
            "Epoch 39/50\n",
            "157/157 [==============================] - 5s 31ms/step - loss: 0.4903 - accuracy: 0.8740 - val_loss: 0.8821 - val_accuracy: 0.7456\n",
            "Learning rate:  1e-06\n",
            "Epoch 40/50\n",
            "157/157 [==============================] - 5s 30ms/step - loss: 0.4848 - accuracy: 0.8700 - val_loss: 0.8848 - val_accuracy: 0.7449\n",
            "Learning rate:  1e-06\n",
            "Epoch 41/50\n",
            "157/157 [==============================] - 5s 30ms/step - loss: 0.4905 - accuracy: 0.8746 - val_loss: 0.8816 - val_accuracy: 0.7459\n",
            "Learning rate:  5e-07\n",
            "Epoch 42/50\n",
            "157/157 [==============================] - 5s 30ms/step - loss: 0.4830 - accuracy: 0.8746 - val_loss: 0.8793 - val_accuracy: 0.7464\n",
            "Learning rate:  5e-07\n",
            "Epoch 43/50\n",
            "157/157 [==============================] - 5s 31ms/step - loss: 0.4937 - accuracy: 0.8706 - val_loss: 0.8826 - val_accuracy: 0.7451\n",
            "Learning rate:  5e-07\n",
            "Epoch 44/50\n",
            "157/157 [==============================] - 5s 31ms/step - loss: 0.4986 - accuracy: 0.8640 - val_loss: 0.8822 - val_accuracy: 0.7459\n",
            "Learning rate:  5e-07\n",
            "Epoch 45/50\n",
            "157/157 [==============================] - 5s 31ms/step - loss: 0.4886 - accuracy: 0.8708 - val_loss: 0.8819 - val_accuracy: 0.7456\n",
            "Learning rate:  5e-07\n",
            "Epoch 46/50\n",
            "157/157 [==============================] - 5s 31ms/step - loss: 0.4877 - accuracy: 0.8724 - val_loss: 0.8832 - val_accuracy: 0.7450\n",
            "Learning rate:  5e-07\n",
            "Epoch 47/50\n",
            "157/157 [==============================] - 5s 31ms/step - loss: 0.4902 - accuracy: 0.8730 - val_loss: 0.8856 - val_accuracy: 0.7445\n",
            "Learning rate:  5e-07\n",
            "Epoch 48/50\n",
            "157/157 [==============================] - 5s 30ms/step - loss: 0.4958 - accuracy: 0.8650 - val_loss: 0.8845 - val_accuracy: 0.7459\n",
            "Learning rate:  5e-07\n",
            "Epoch 49/50\n",
            "157/157 [==============================] - 5s 30ms/step - loss: 0.4895 - accuracy: 0.8738 - val_loss: 0.8833 - val_accuracy: 0.7452\n",
            "Learning rate:  5e-07\n",
            "Epoch 50/50\n",
            "157/157 [==============================] - 5s 31ms/step - loss: 0.5019 - accuracy: 0.8618 - val_loss: 0.8833 - val_accuracy: 0.7452\n",
            " -- PATH: self_supervised\n",
            " -- write into csv file\n",
            "Num of trainings: 5\n",
            "Learning rate:  0.001\n",
            "ResNet20\n",
            "Using real-time data augmentation.\n",
            "Learning rate:  0.001\n",
            "Epoch 1/50\n",
            "188/188 [==============================] - 6s 33ms/step - loss: 1.5085 - accuracy: 0.4875 - val_loss: 2.0463 - val_accuracy: 0.3865\n",
            "Learning rate:  0.001\n",
            "Epoch 2/50\n",
            "188/188 [==============================] - 6s 30ms/step - loss: 1.2068 - accuracy: 0.5993 - val_loss: 1.3304 - val_accuracy: 0.5790\n",
            "Learning rate:  0.001\n",
            "Epoch 3/50\n",
            "188/188 [==============================] - 6s 30ms/step - loss: 1.0989 - accuracy: 0.6350 - val_loss: 1.2201 - val_accuracy: 0.6057\n",
            "Learning rate:  0.001\n",
            "Epoch 4/50\n",
            "188/188 [==============================] - 6s 29ms/step - loss: 1.0254 - accuracy: 0.6705 - val_loss: 1.2586 - val_accuracy: 0.6084\n",
            "Learning rate:  0.001\n",
            "Epoch 5/50\n",
            "188/188 [==============================] - 5s 29ms/step - loss: 0.9667 - accuracy: 0.6890 - val_loss: 1.1358 - val_accuracy: 0.6489\n",
            "Learning rate:  0.001\n",
            "Epoch 6/50\n",
            "188/188 [==============================] - 6s 29ms/step - loss: 0.9366 - accuracy: 0.6983 - val_loss: 1.2929 - val_accuracy: 0.6051\n",
            "Learning rate:  0.001\n",
            "Epoch 7/50\n",
            "188/188 [==============================] - 6s 29ms/step - loss: 0.8992 - accuracy: 0.7203 - val_loss: 1.1504 - val_accuracy: 0.6419\n",
            "Learning rate:  0.001\n",
            "Epoch 8/50\n",
            "188/188 [==============================] - 6s 29ms/step - loss: 0.8646 - accuracy: 0.7338 - val_loss: 1.3319 - val_accuracy: 0.6203\n",
            "Learning rate:  0.001\n",
            "Epoch 9/50\n",
            "188/188 [==============================] - 6s 29ms/step - loss: 0.8350 - accuracy: 0.7445 - val_loss: 1.2382 - val_accuracy: 0.6406\n",
            "Learning rate:  0.001\n",
            "Epoch 10/50\n",
            "188/188 [==============================] - 6s 30ms/step - loss: 0.8156 - accuracy: 0.7540 - val_loss: 1.1711 - val_accuracy: 0.6448\n",
            "Learning rate:  0.001\n",
            "Epoch 11/50\n",
            "188/188 [==============================] - 6s 30ms/step - loss: 0.7849 - accuracy: 0.7622 - val_loss: 1.3387 - val_accuracy: 0.6452\n",
            "Learning rate:  0.0001\n",
            "Epoch 12/50\n",
            "188/188 [==============================] - 6s 30ms/step - loss: 0.6670 - accuracy: 0.8093 - val_loss: 0.8580 - val_accuracy: 0.7467\n",
            "Learning rate:  0.0001\n",
            "Epoch 13/50\n",
            "188/188 [==============================] - 6s 29ms/step - loss: 0.6219 - accuracy: 0.8242 - val_loss: 0.8462 - val_accuracy: 0.7489\n",
            "Learning rate:  0.0001\n",
            "Epoch 14/50\n",
            "188/188 [==============================] - 6s 29ms/step - loss: 0.6071 - accuracy: 0.8260 - val_loss: 0.8539 - val_accuracy: 0.7494\n",
            "Learning rate:  0.0001\n",
            "Epoch 15/50\n",
            "188/188 [==============================] - 6s 29ms/step - loss: 0.5923 - accuracy: 0.8330 - val_loss: 0.8655 - val_accuracy: 0.7467\n",
            "Learning rate:  0.0001\n",
            "Epoch 16/50\n",
            "188/188 [==============================] - 6s 30ms/step - loss: 0.5813 - accuracy: 0.8393 - val_loss: 0.8623 - val_accuracy: 0.7472\n",
            "Learning rate:  0.0001\n",
            "Epoch 17/50\n",
            "188/188 [==============================] - 6s 31ms/step - loss: 0.5586 - accuracy: 0.8443 - val_loss: 0.8500 - val_accuracy: 0.7521\n",
            "Learning rate:  0.0001\n",
            "Epoch 18/50\n",
            "188/188 [==============================] - 6s 30ms/step - loss: 0.5621 - accuracy: 0.8447 - val_loss: 0.8479 - val_accuracy: 0.7530\n",
            "Learning rate:  0.0001\n",
            "Epoch 19/50\n",
            "188/188 [==============================] - 6s 30ms/step - loss: 0.5359 - accuracy: 0.8578 - val_loss: 0.8602 - val_accuracy: 0.7542\n",
            "Learning rate:  0.0001\n",
            "Epoch 20/50\n",
            "188/188 [==============================] - 6s 29ms/step - loss: 0.5483 - accuracy: 0.8493 - val_loss: 0.8596 - val_accuracy: 0.7545\n",
            "Learning rate:  0.0001\n",
            "Epoch 21/50\n",
            "188/188 [==============================] - 5s 29ms/step - loss: 0.5325 - accuracy: 0.8550 - val_loss: 0.8561 - val_accuracy: 0.7559\n",
            "Learning rate:  1e-05\n",
            "Epoch 22/50\n",
            "188/188 [==============================] - 6s 29ms/step - loss: 0.5175 - accuracy: 0.8605 - val_loss: 0.8509 - val_accuracy: 0.7605\n",
            "Learning rate:  1e-05\n",
            "Epoch 23/50\n",
            "188/188 [==============================] - 6s 30ms/step - loss: 0.5130 - accuracy: 0.8610 - val_loss: 0.8514 - val_accuracy: 0.7599\n",
            "Learning rate:  1e-05\n",
            "Epoch 24/50\n",
            "188/188 [==============================] - 6s 29ms/step - loss: 0.5029 - accuracy: 0.8627 - val_loss: 0.8494 - val_accuracy: 0.7612\n",
            "Learning rate:  1e-05\n",
            "Epoch 25/50\n",
            "188/188 [==============================] - 6s 29ms/step - loss: 0.5094 - accuracy: 0.8623 - val_loss: 0.8537 - val_accuracy: 0.7603\n",
            "Learning rate:  1e-05\n",
            "Epoch 26/50\n",
            "188/188 [==============================] - 6s 29ms/step - loss: 0.4999 - accuracy: 0.8678 - val_loss: 0.8550 - val_accuracy: 0.7601\n",
            "Learning rate:  1e-05\n",
            "Epoch 27/50\n",
            "188/188 [==============================] - 6s 30ms/step - loss: 0.4978 - accuracy: 0.8660 - val_loss: 0.8511 - val_accuracy: 0.7601\n",
            "Learning rate:  1e-05\n",
            "Epoch 28/50\n",
            "188/188 [==============================] - 6s 30ms/step - loss: 0.5059 - accuracy: 0.8670 - val_loss: 0.8521 - val_accuracy: 0.7610\n",
            "Learning rate:  1e-05\n",
            "Epoch 29/50\n",
            "188/188 [==============================] - 6s 29ms/step - loss: 0.4966 - accuracy: 0.8720 - val_loss: 0.8532 - val_accuracy: 0.7606\n",
            "Learning rate:  1e-05\n",
            "Epoch 30/50\n",
            "188/188 [==============================] - 6s 30ms/step - loss: 0.4967 - accuracy: 0.8688 - val_loss: 0.8522 - val_accuracy: 0.7624\n",
            "Learning rate:  1e-05\n",
            "Epoch 31/50\n",
            "188/188 [==============================] - 6s 29ms/step - loss: 0.4998 - accuracy: 0.8673 - val_loss: 0.8520 - val_accuracy: 0.7619\n",
            "Learning rate:  1e-06\n",
            "Epoch 32/50\n",
            "188/188 [==============================] - 6s 29ms/step - loss: 0.4908 - accuracy: 0.8715 - val_loss: 0.8534 - val_accuracy: 0.7619\n",
            "Learning rate:  1e-06\n",
            "Epoch 33/50\n",
            "188/188 [==============================] - 6s 29ms/step - loss: 0.4976 - accuracy: 0.8703 - val_loss: 0.8512 - val_accuracy: 0.7624\n",
            "Learning rate:  1e-06\n",
            "Epoch 34/50\n",
            "188/188 [==============================] - 6s 30ms/step - loss: 0.4993 - accuracy: 0.8673 - val_loss: 0.8542 - val_accuracy: 0.7624\n",
            "Learning rate:  1e-06\n",
            "Epoch 35/50\n",
            "188/188 [==============================] - 5s 29ms/step - loss: 0.4959 - accuracy: 0.8672 - val_loss: 0.8536 - val_accuracy: 0.7617\n",
            "Learning rate:  1e-06\n",
            "Epoch 36/50\n",
            "188/188 [==============================] - 5s 29ms/step - loss: 0.4945 - accuracy: 0.8713 - val_loss: 0.8519 - val_accuracy: 0.7618\n",
            "Learning rate:  1e-06\n",
            "Epoch 37/50\n",
            "188/188 [==============================] - 6s 30ms/step - loss: 0.5040 - accuracy: 0.8670 - val_loss: 0.8546 - val_accuracy: 0.7618\n",
            "Learning rate:  1e-06\n",
            "Epoch 38/50\n",
            "188/188 [==============================] - 5s 29ms/step - loss: 0.4947 - accuracy: 0.8742 - val_loss: 0.8525 - val_accuracy: 0.7620\n",
            "Learning rate:  1e-06\n",
            "Epoch 39/50\n",
            "188/188 [==============================] - 6s 29ms/step - loss: 0.4905 - accuracy: 0.8720 - val_loss: 0.8541 - val_accuracy: 0.7620\n",
            "Learning rate:  1e-06\n",
            "Epoch 40/50\n",
            "188/188 [==============================] - 5s 29ms/step - loss: 0.4977 - accuracy: 0.8653 - val_loss: 0.8533 - val_accuracy: 0.7612\n",
            "Learning rate:  1e-06\n",
            "Epoch 41/50\n",
            "188/188 [==============================] - 5s 29ms/step - loss: 0.5028 - accuracy: 0.8658 - val_loss: 0.8512 - val_accuracy: 0.7625\n",
            "Learning rate:  5e-07\n",
            "Epoch 42/50\n",
            "188/188 [==============================] - 6s 29ms/step - loss: 0.4953 - accuracy: 0.8727 - val_loss: 0.8528 - val_accuracy: 0.7621\n",
            "Learning rate:  5e-07\n",
            "Epoch 43/50\n",
            "188/188 [==============================] - 5s 29ms/step - loss: 0.4978 - accuracy: 0.8712 - val_loss: 0.8547 - val_accuracy: 0.7615\n",
            "Learning rate:  5e-07\n",
            "Epoch 44/50\n",
            "188/188 [==============================] - 5s 29ms/step - loss: 0.5018 - accuracy: 0.8678 - val_loss: 0.8519 - val_accuracy: 0.7633\n",
            "Learning rate:  5e-07\n",
            "Epoch 45/50\n",
            "188/188 [==============================] - 5s 29ms/step - loss: 0.4945 - accuracy: 0.8685 - val_loss: 0.8562 - val_accuracy: 0.7619\n",
            "Learning rate:  5e-07\n",
            "Epoch 46/50\n",
            "188/188 [==============================] - 5s 29ms/step - loss: 0.4893 - accuracy: 0.8750 - val_loss: 0.8536 - val_accuracy: 0.7622\n",
            "Learning rate:  5e-07\n",
            "Epoch 47/50\n",
            "188/188 [==============================] - 5s 29ms/step - loss: 0.5023 - accuracy: 0.8648 - val_loss: 0.8547 - val_accuracy: 0.7620\n",
            "Learning rate:  5e-07\n",
            "Epoch 48/50\n",
            "188/188 [==============================] - 5s 29ms/step - loss: 0.5040 - accuracy: 0.8697 - val_loss: 0.8525 - val_accuracy: 0.7627\n",
            "Learning rate:  5e-07\n",
            "Epoch 49/50\n",
            "188/188 [==============================] - 5s 29ms/step - loss: 0.4863 - accuracy: 0.8737 - val_loss: 0.8529 - val_accuracy: 0.7623\n",
            "Learning rate:  5e-07\n",
            "Epoch 50/50\n",
            "188/188 [==============================] - 5s 29ms/step - loss: 0.5046 - accuracy: 0.8645 - val_loss: 0.8531 - val_accuracy: 0.7625\n",
            " -- PATH: self_supervised\n",
            " -- write into csv file\n",
            "Num of trainings: 6\n",
            "Learning rate:  0.001\n",
            "ResNet20\n",
            "Using real-time data augmentation.\n",
            "Learning rate:  0.001\n",
            "Epoch 1/50\n",
            "219/219 [==============================] - 7s 31ms/step - loss: 1.4823 - accuracy: 0.5047 - val_loss: 1.6277 - val_accuracy: 0.5053\n",
            "Learning rate:  0.001\n",
            "Epoch 2/50\n",
            "219/219 [==============================] - 6s 28ms/step - loss: 1.1564 - accuracy: 0.6191 - val_loss: 1.6025 - val_accuracy: 0.5213\n",
            "Learning rate:  0.001\n",
            "Epoch 3/50\n",
            "219/219 [==============================] - 6s 28ms/step - loss: 1.0680 - accuracy: 0.6510 - val_loss: 1.5023 - val_accuracy: 0.5490\n",
            "Learning rate:  0.001\n",
            "Epoch 4/50\n",
            "219/219 [==============================] - 6s 28ms/step - loss: 0.9997 - accuracy: 0.6769 - val_loss: 1.0656 - val_accuracy: 0.6583\n",
            "Learning rate:  0.001\n",
            "Epoch 5/50\n",
            "219/219 [==============================] - 6s 28ms/step - loss: 0.9348 - accuracy: 0.7099 - val_loss: 1.2022 - val_accuracy: 0.6276\n",
            "Learning rate:  0.001\n",
            "Epoch 6/50\n",
            "219/219 [==============================] - 6s 28ms/step - loss: 0.8935 - accuracy: 0.7206 - val_loss: 1.8036 - val_accuracy: 0.5185\n",
            "Learning rate:  0.001\n",
            "Epoch 7/50\n",
            "219/219 [==============================] - 6s 28ms/step - loss: 0.8484 - accuracy: 0.7406 - val_loss: 1.1723 - val_accuracy: 0.6538\n",
            "Learning rate:  0.001\n",
            "Epoch 8/50\n",
            "219/219 [==============================] - 6s 28ms/step - loss: 0.8189 - accuracy: 0.7514 - val_loss: 0.9843 - val_accuracy: 0.6956\n",
            "Learning rate:  0.001\n",
            "Epoch 9/50\n",
            "219/219 [==============================] - 6s 28ms/step - loss: 0.7937 - accuracy: 0.7556 - val_loss: 1.2115 - val_accuracy: 0.6422\n",
            "Learning rate:  0.001\n",
            "Epoch 10/50\n",
            "219/219 [==============================] - 6s 28ms/step - loss: 0.7768 - accuracy: 0.7681 - val_loss: 1.1290 - val_accuracy: 0.6697\n",
            "Learning rate:  0.001\n",
            "Epoch 11/50\n",
            "219/219 [==============================] - 6s 28ms/step - loss: 0.7465 - accuracy: 0.7763 - val_loss: 1.1550 - val_accuracy: 0.6761\n",
            "Learning rate:  0.0001\n",
            "Epoch 12/50\n",
            "219/219 [==============================] - 6s 29ms/step - loss: 0.6276 - accuracy: 0.8243 - val_loss: 0.8481 - val_accuracy: 0.7550\n",
            "Learning rate:  0.0001\n",
            "Epoch 13/50\n",
            "219/219 [==============================] - 6s 28ms/step - loss: 0.5738 - accuracy: 0.8407 - val_loss: 0.8142 - val_accuracy: 0.7655\n",
            "Learning rate:  0.0001\n",
            "Epoch 14/50\n",
            "219/219 [==============================] - 6s 28ms/step - loss: 0.5536 - accuracy: 0.8510 - val_loss: 0.8233 - val_accuracy: 0.7636\n",
            "Learning rate:  0.0001\n",
            "Epoch 15/50\n",
            "219/219 [==============================] - 6s 28ms/step - loss: 0.5432 - accuracy: 0.8536 - val_loss: 0.8074 - val_accuracy: 0.7650\n",
            "Learning rate:  0.0001\n",
            "Epoch 16/50\n",
            "219/219 [==============================] - 6s 28ms/step - loss: 0.5414 - accuracy: 0.8524 - val_loss: 0.8214 - val_accuracy: 0.7658\n",
            "Learning rate:  0.0001\n",
            "Epoch 17/50\n",
            "219/219 [==============================] - 6s 28ms/step - loss: 0.5311 - accuracy: 0.8543 - val_loss: 0.8223 - val_accuracy: 0.7661\n",
            "Learning rate:  0.0001\n",
            "Epoch 18/50\n",
            "219/219 [==============================] - 6s 29ms/step - loss: 0.5208 - accuracy: 0.8589 - val_loss: 0.8106 - val_accuracy: 0.7673\n",
            "Learning rate:  0.0001\n",
            "Epoch 19/50\n",
            "219/219 [==============================] - 6s 29ms/step - loss: 0.5049 - accuracy: 0.8661 - val_loss: 0.8280 - val_accuracy: 0.7621\n",
            "Learning rate:  0.0001\n",
            "Epoch 20/50\n",
            "219/219 [==============================] - 6s 29ms/step - loss: 0.5030 - accuracy: 0.8653 - val_loss: 0.8360 - val_accuracy: 0.7655\n",
            "Learning rate:  0.0001\n",
            "Epoch 21/50\n",
            "219/219 [==============================] - 6s 28ms/step - loss: 0.4950 - accuracy: 0.8723 - val_loss: 0.8304 - val_accuracy: 0.7648\n",
            "Learning rate:  1e-05\n",
            "Epoch 22/50\n",
            "219/219 [==============================] - 6s 28ms/step - loss: 0.4845 - accuracy: 0.8729 - val_loss: 0.8220 - val_accuracy: 0.7690\n",
            "Learning rate:  1e-05\n",
            "Epoch 23/50\n",
            "219/219 [==============================] - 6s 28ms/step - loss: 0.4793 - accuracy: 0.8766 - val_loss: 0.8227 - val_accuracy: 0.7696\n",
            "Learning rate:  1e-05\n",
            "Epoch 24/50\n",
            "219/219 [==============================] - 6s 28ms/step - loss: 0.4770 - accuracy: 0.8769 - val_loss: 0.8209 - val_accuracy: 0.7698\n",
            "Learning rate:  1e-05\n",
            "Epoch 25/50\n",
            "219/219 [==============================] - 6s 28ms/step - loss: 0.4626 - accuracy: 0.8819 - val_loss: 0.8193 - val_accuracy: 0.7698\n",
            "Learning rate:  1e-05\n",
            "Epoch 26/50\n",
            "219/219 [==============================] - 6s 28ms/step - loss: 0.4691 - accuracy: 0.8820 - val_loss: 0.8160 - val_accuracy: 0.7704\n",
            "Learning rate:  1e-05\n",
            "Epoch 27/50\n",
            "219/219 [==============================] - 6s 28ms/step - loss: 0.4684 - accuracy: 0.8800 - val_loss: 0.8169 - val_accuracy: 0.7704\n",
            "Learning rate:  1e-05\n",
            "Epoch 28/50\n",
            "219/219 [==============================] - 6s 28ms/step - loss: 0.4730 - accuracy: 0.8780 - val_loss: 0.8142 - val_accuracy: 0.7701\n",
            "Learning rate:  1e-05\n",
            "Epoch 29/50\n",
            "219/219 [==============================] - 6s 28ms/step - loss: 0.4665 - accuracy: 0.8754 - val_loss: 0.8146 - val_accuracy: 0.7712\n",
            "Learning rate:  1e-05\n",
            "Epoch 30/50\n",
            "219/219 [==============================] - 6s 28ms/step - loss: 0.4635 - accuracy: 0.8820 - val_loss: 0.8214 - val_accuracy: 0.7703\n",
            "Learning rate:  1e-05\n",
            "Epoch 31/50\n",
            "219/219 [==============================] - 6s 29ms/step - loss: 0.4632 - accuracy: 0.8811 - val_loss: 0.8212 - val_accuracy: 0.7691\n",
            "Learning rate:  1e-06\n",
            "Epoch 32/50\n",
            "219/219 [==============================] - 6s 28ms/step - loss: 0.4586 - accuracy: 0.8847 - val_loss: 0.8178 - val_accuracy: 0.7708\n",
            "Learning rate:  1e-06\n",
            "Epoch 33/50\n",
            "219/219 [==============================] - 6s 28ms/step - loss: 0.4658 - accuracy: 0.8820 - val_loss: 0.8191 - val_accuracy: 0.7690\n",
            "Learning rate:  1e-06\n",
            "Epoch 34/50\n",
            "219/219 [==============================] - 6s 28ms/step - loss: 0.4741 - accuracy: 0.8739 - val_loss: 0.8190 - val_accuracy: 0.7699\n",
            "Learning rate:  1e-06\n",
            "Epoch 35/50\n",
            "219/219 [==============================] - 6s 28ms/step - loss: 0.4681 - accuracy: 0.8823 - val_loss: 0.8188 - val_accuracy: 0.7703\n",
            "Learning rate:  1e-06\n",
            "Epoch 36/50\n",
            "219/219 [==============================] - 6s 28ms/step - loss: 0.4670 - accuracy: 0.8791 - val_loss: 0.8213 - val_accuracy: 0.7700\n",
            "Learning rate:  1e-06\n",
            "Epoch 37/50\n",
            "219/219 [==============================] - 6s 28ms/step - loss: 0.4663 - accuracy: 0.8779 - val_loss: 0.8200 - val_accuracy: 0.7698\n",
            "Learning rate:  1e-06\n",
            "Epoch 38/50\n",
            "219/219 [==============================] - 6s 28ms/step - loss: 0.4611 - accuracy: 0.8843 - val_loss: 0.8158 - val_accuracy: 0.7710\n",
            "Learning rate:  1e-06\n",
            "Epoch 39/50\n",
            "219/219 [==============================] - 6s 28ms/step - loss: 0.4737 - accuracy: 0.8726 - val_loss: 0.8191 - val_accuracy: 0.7705\n",
            "Learning rate:  1e-06\n",
            "Epoch 40/50\n",
            "219/219 [==============================] - 6s 28ms/step - loss: 0.4603 - accuracy: 0.8809 - val_loss: 0.8183 - val_accuracy: 0.7700\n",
            "Learning rate:  1e-06\n",
            "Epoch 41/50\n",
            "219/219 [==============================] - 6s 28ms/step - loss: 0.4627 - accuracy: 0.8820 - val_loss: 0.8212 - val_accuracy: 0.7694\n",
            "Learning rate:  5e-07\n",
            "Epoch 42/50\n",
            "219/219 [==============================] - 6s 29ms/step - loss: 0.4595 - accuracy: 0.8833 - val_loss: 0.8187 - val_accuracy: 0.7707\n",
            "Learning rate:  5e-07\n",
            "Epoch 43/50\n",
            "219/219 [==============================] - 6s 28ms/step - loss: 0.4589 - accuracy: 0.8871 - val_loss: 0.8177 - val_accuracy: 0.7704\n",
            "Learning rate:  5e-07\n",
            "Epoch 44/50\n",
            "219/219 [==============================] - 6s 29ms/step - loss: 0.4655 - accuracy: 0.8799 - val_loss: 0.8171 - val_accuracy: 0.7708\n",
            "Learning rate:  5e-07\n",
            "Epoch 45/50\n",
            "219/219 [==============================] - 6s 28ms/step - loss: 0.4683 - accuracy: 0.8794 - val_loss: 0.8188 - val_accuracy: 0.7698\n",
            "Learning rate:  5e-07\n",
            "Epoch 46/50\n",
            "219/219 [==============================] - 6s 28ms/step - loss: 0.4588 - accuracy: 0.8844 - val_loss: 0.8211 - val_accuracy: 0.7695\n",
            "Learning rate:  5e-07\n",
            "Epoch 47/50\n",
            "219/219 [==============================] - 6s 28ms/step - loss: 0.4573 - accuracy: 0.8849 - val_loss: 0.8202 - val_accuracy: 0.7693\n",
            "Learning rate:  5e-07\n",
            "Epoch 48/50\n",
            "219/219 [==============================] - 6s 28ms/step - loss: 0.4624 - accuracy: 0.8807 - val_loss: 0.8160 - val_accuracy: 0.7705\n",
            "Learning rate:  5e-07\n",
            "Epoch 49/50\n",
            "219/219 [==============================] - 6s 28ms/step - loss: 0.4568 - accuracy: 0.8861 - val_loss: 0.8166 - val_accuracy: 0.7708\n",
            "Learning rate:  5e-07\n",
            "Epoch 50/50\n",
            "219/219 [==============================] - 6s 28ms/step - loss: 0.4655 - accuracy: 0.8779 - val_loss: 0.8161 - val_accuracy: 0.7705\n",
            " -- PATH: self_supervised\n",
            " -- write into csv file\n",
            "Num of trainings: 7\n",
            "Learning rate:  0.001\n",
            "ResNet20\n",
            "Using real-time data augmentation.\n",
            "Learning rate:  0.001\n",
            "Epoch 1/50\n",
            "250/250 [==============================] - 8s 30ms/step - loss: 1.4837 - accuracy: 0.4916 - val_loss: 1.4869 - val_accuracy: 0.5201\n",
            "Learning rate:  0.001\n",
            "Epoch 2/50\n",
            "250/250 [==============================] - 7s 27ms/step - loss: 1.1748 - accuracy: 0.6143 - val_loss: 2.3787 - val_accuracy: 0.4185\n",
            "Learning rate:  0.001\n",
            "Epoch 3/50\n",
            "250/250 [==============================] - 7s 28ms/step - loss: 1.0715 - accuracy: 0.6496 - val_loss: 1.5556 - val_accuracy: 0.5177\n",
            "Learning rate:  0.001\n",
            "Epoch 4/50\n",
            "250/250 [==============================] - 7s 28ms/step - loss: 1.0291 - accuracy: 0.6679 - val_loss: 1.2379 - val_accuracy: 0.6177\n",
            "Learning rate:  0.001\n",
            "Epoch 5/50\n",
            "250/250 [==============================] - 7s 28ms/step - loss: 0.9523 - accuracy: 0.6967 - val_loss: 1.0242 - val_accuracy: 0.6780\n",
            "Learning rate:  0.001\n",
            "Epoch 6/50\n",
            "250/250 [==============================] - 7s 27ms/step - loss: 0.8962 - accuracy: 0.7205 - val_loss: 1.5132 - val_accuracy: 0.5706\n",
            "Learning rate:  0.001\n",
            "Epoch 7/50\n",
            "250/250 [==============================] - 7s 28ms/step - loss: 0.8713 - accuracy: 0.7262 - val_loss: 1.4682 - val_accuracy: 0.5902\n",
            "Learning rate:  0.001\n",
            "Epoch 8/50\n",
            "250/250 [==============================] - 7s 28ms/step - loss: 0.8423 - accuracy: 0.7379 - val_loss: 1.4395 - val_accuracy: 0.6006\n",
            "Learning rate:  0.001\n",
            "Epoch 9/50\n",
            "250/250 [==============================] - 7s 28ms/step - loss: 0.7986 - accuracy: 0.7571 - val_loss: 1.1140 - val_accuracy: 0.6751\n",
            "Learning rate:  0.001\n",
            "Epoch 10/50\n",
            "250/250 [==============================] - 7s 28ms/step - loss: 0.7781 - accuracy: 0.7654 - val_loss: 1.1218 - val_accuracy: 0.6735\n",
            "Learning rate:  0.001\n",
            "Epoch 11/50\n",
            "250/250 [==============================] - 7s 28ms/step - loss: 0.7661 - accuracy: 0.7719 - val_loss: 1.1637 - val_accuracy: 0.6786\n",
            "Learning rate:  0.0001\n",
            "Epoch 12/50\n",
            "250/250 [==============================] - 7s 28ms/step - loss: 0.6378 - accuracy: 0.8192 - val_loss: 0.8197 - val_accuracy: 0.7598\n",
            "Learning rate:  0.0001\n",
            "Epoch 13/50\n",
            "250/250 [==============================] - 7s 28ms/step - loss: 0.5959 - accuracy: 0.8353 - val_loss: 0.7877 - val_accuracy: 0.7770\n",
            "Learning rate:  0.0001\n",
            "Epoch 14/50\n",
            "250/250 [==============================] - 7s 28ms/step - loss: 0.5840 - accuracy: 0.8391 - val_loss: 0.7865 - val_accuracy: 0.7775\n",
            "Learning rate:  0.0001\n",
            "Epoch 15/50\n",
            "250/250 [==============================] - 7s 28ms/step - loss: 0.5623 - accuracy: 0.8521 - val_loss: 0.7891 - val_accuracy: 0.7757\n",
            "Learning rate:  0.0001\n",
            "Epoch 16/50\n",
            "250/250 [==============================] - 7s 28ms/step - loss: 0.5555 - accuracy: 0.8506 - val_loss: 0.7946 - val_accuracy: 0.7726\n",
            "Learning rate:  0.0001\n",
            "Epoch 17/50\n",
            "250/250 [==============================] - 7s 29ms/step - loss: 0.5466 - accuracy: 0.8539 - val_loss: 0.7976 - val_accuracy: 0.7773\n",
            "Learning rate:  0.0001\n",
            "Epoch 18/50\n",
            "250/250 [==============================] - 7s 28ms/step - loss: 0.5421 - accuracy: 0.8533 - val_loss: 0.7787 - val_accuracy: 0.7849\n",
            "Learning rate:  0.0001\n",
            "Epoch 19/50\n",
            "250/250 [==============================] - 7s 28ms/step - loss: 0.5229 - accuracy: 0.8610 - val_loss: 0.7844 - val_accuracy: 0.7797\n",
            "Learning rate:  0.0001\n",
            "Epoch 20/50\n",
            "250/250 [==============================] - 7s 28ms/step - loss: 0.5285 - accuracy: 0.8569 - val_loss: 0.8090 - val_accuracy: 0.7735\n",
            "Learning rate:  0.0001\n",
            "Epoch 21/50\n",
            "250/250 [==============================] - 7s 27ms/step - loss: 0.5116 - accuracy: 0.8616 - val_loss: 0.7784 - val_accuracy: 0.7838\n",
            "Learning rate:  1e-05\n",
            "Epoch 22/50\n",
            "250/250 [==============================] - 7s 28ms/step - loss: 0.4872 - accuracy: 0.8711 - val_loss: 0.7798 - val_accuracy: 0.7838\n",
            "Learning rate:  1e-05\n",
            "Epoch 23/50\n",
            "250/250 [==============================] - 7s 28ms/step - loss: 0.4954 - accuracy: 0.8710 - val_loss: 0.7826 - val_accuracy: 0.7826\n",
            "Learning rate:  1e-05\n",
            "Epoch 24/50\n",
            "250/250 [==============================] - 7s 27ms/step - loss: 0.4888 - accuracy: 0.8723 - val_loss: 0.7802 - val_accuracy: 0.7840\n",
            "Learning rate:  1e-05\n",
            "Epoch 25/50\n",
            "250/250 [==============================] - 7s 27ms/step - loss: 0.4868 - accuracy: 0.8721 - val_loss: 0.7812 - val_accuracy: 0.7845\n",
            "Learning rate:  1e-05\n",
            "Epoch 26/50\n",
            "250/250 [==============================] - 7s 28ms/step - loss: 0.4924 - accuracy: 0.8745 - val_loss: 0.7773 - val_accuracy: 0.7845\n",
            "Learning rate:  1e-05\n",
            "Epoch 27/50\n",
            "250/250 [==============================] - 7s 27ms/step - loss: 0.4845 - accuracy: 0.8734 - val_loss: 0.7766 - val_accuracy: 0.7844\n",
            "Learning rate:  1e-05\n",
            "Epoch 28/50\n",
            "250/250 [==============================] - 7s 28ms/step - loss: 0.4844 - accuracy: 0.8744 - val_loss: 0.7770 - val_accuracy: 0.7840\n",
            "Learning rate:  1e-05\n",
            "Epoch 29/50\n",
            "250/250 [==============================] - 7s 28ms/step - loss: 0.4781 - accuracy: 0.8764 - val_loss: 0.7787 - val_accuracy: 0.7838\n",
            "Learning rate:  1e-05\n",
            "Epoch 30/50\n",
            "250/250 [==============================] - 7s 27ms/step - loss: 0.4869 - accuracy: 0.8730 - val_loss: 0.7789 - val_accuracy: 0.7840\n",
            "Learning rate:  1e-05\n",
            "Epoch 31/50\n",
            "250/250 [==============================] - 7s 28ms/step - loss: 0.4838 - accuracy: 0.8761 - val_loss: 0.7815 - val_accuracy: 0.7834\n",
            "Learning rate:  1e-06\n",
            "Epoch 32/50\n",
            "250/250 [==============================] - 7s 28ms/step - loss: 0.4748 - accuracy: 0.8798 - val_loss: 0.7798 - val_accuracy: 0.7839\n",
            "Learning rate:  1e-06\n",
            "Epoch 33/50\n",
            "250/250 [==============================] - 7s 27ms/step - loss: 0.4818 - accuracy: 0.8723 - val_loss: 0.7791 - val_accuracy: 0.7845\n",
            "Learning rate:  1e-06\n",
            "Epoch 34/50\n",
            "250/250 [==============================] - 7s 27ms/step - loss: 0.4791 - accuracy: 0.8761 - val_loss: 0.7807 - val_accuracy: 0.7847\n",
            "Learning rate:  1e-06\n",
            "Epoch 35/50\n",
            "250/250 [==============================] - 7s 28ms/step - loss: 0.4876 - accuracy: 0.8706 - val_loss: 0.7799 - val_accuracy: 0.7835\n",
            "Learning rate:  1e-06\n",
            "Epoch 36/50\n",
            "250/250 [==============================] - 7s 28ms/step - loss: 0.4785 - accuracy: 0.8730 - val_loss: 0.7800 - val_accuracy: 0.7844\n",
            "Learning rate:  1e-06\n",
            "Epoch 37/50\n",
            "250/250 [==============================] - 7s 28ms/step - loss: 0.4796 - accuracy: 0.8758 - val_loss: 0.7789 - val_accuracy: 0.7848\n",
            "Learning rate:  1e-06\n",
            "Epoch 38/50\n",
            "250/250 [==============================] - 7s 29ms/step - loss: 0.4847 - accuracy: 0.8752 - val_loss: 0.7787 - val_accuracy: 0.7839\n",
            "Learning rate:  1e-06\n",
            "Epoch 39/50\n",
            "250/250 [==============================] - 7s 29ms/step - loss: 0.4802 - accuracy: 0.8767 - val_loss: 0.7765 - val_accuracy: 0.7844\n",
            "Learning rate:  1e-06\n",
            "Epoch 40/50\n",
            "250/250 [==============================] - 7s 30ms/step - loss: 0.4838 - accuracy: 0.8741 - val_loss: 0.7802 - val_accuracy: 0.7837\n",
            "Learning rate:  1e-06\n",
            "Epoch 41/50\n",
            "250/250 [==============================] - 7s 30ms/step - loss: 0.4793 - accuracy: 0.8736 - val_loss: 0.7806 - val_accuracy: 0.7840\n",
            "Learning rate:  5e-07\n",
            "Epoch 42/50\n",
            "250/250 [==============================] - 7s 30ms/step - loss: 0.4863 - accuracy: 0.8730 - val_loss: 0.7791 - val_accuracy: 0.7844\n",
            "Learning rate:  5e-07\n",
            "Epoch 43/50\n",
            "250/250 [==============================] - 7s 30ms/step - loss: 0.4836 - accuracy: 0.8734 - val_loss: 0.7789 - val_accuracy: 0.7842\n",
            "Learning rate:  5e-07\n",
            "Epoch 44/50\n",
            "250/250 [==============================] - 7s 30ms/step - loss: 0.4787 - accuracy: 0.8734 - val_loss: 0.7785 - val_accuracy: 0.7845\n",
            "Learning rate:  5e-07\n",
            "Epoch 45/50\n",
            "250/250 [==============================] - 7s 29ms/step - loss: 0.4866 - accuracy: 0.8724 - val_loss: 0.7780 - val_accuracy: 0.7844\n",
            "Learning rate:  5e-07\n",
            "Epoch 46/50\n",
            "250/250 [==============================] - 7s 29ms/step - loss: 0.4742 - accuracy: 0.8749 - val_loss: 0.7758 - val_accuracy: 0.7848\n",
            "Learning rate:  5e-07\n",
            "Epoch 47/50\n",
            "250/250 [==============================] - 7s 29ms/step - loss: 0.4847 - accuracy: 0.8729 - val_loss: 0.7803 - val_accuracy: 0.7844\n",
            "Learning rate:  5e-07\n",
            "Epoch 48/50\n",
            "250/250 [==============================] - 7s 29ms/step - loss: 0.4891 - accuracy: 0.8721 - val_loss: 0.7775 - val_accuracy: 0.7846\n",
            "Learning rate:  5e-07\n",
            "Epoch 49/50\n",
            "250/250 [==============================] - 7s 29ms/step - loss: 0.4755 - accuracy: 0.8771 - val_loss: 0.7796 - val_accuracy: 0.7837\n",
            "Learning rate:  5e-07\n",
            "Epoch 50/50\n",
            "250/250 [==============================] - 7s 29ms/step - loss: 0.4834 - accuracy: 0.8770 - val_loss: 0.7776 - val_accuracy: 0.7843\n",
            " -- PATH: self_supervised\n",
            " -- write into csv file\n",
            "Num of trainings: 8\n",
            "Learning rate:  0.001\n",
            "ResNet20\n",
            "Using real-time data augmentation.\n",
            "Learning rate:  0.001\n",
            "Epoch 1/50\n",
            "282/282 [==============================] - 9s 31ms/step - loss: 1.4568 - accuracy: 0.5004 - val_loss: 1.5831 - val_accuracy: 0.5251\n",
            "Learning rate:  0.001\n",
            "Epoch 2/50\n",
            "282/282 [==============================] - 8s 28ms/step - loss: 1.1534 - accuracy: 0.6152 - val_loss: 1.2680 - val_accuracy: 0.5861\n",
            "Learning rate:  0.001\n",
            "Epoch 3/50\n",
            "282/282 [==============================] - 8s 28ms/step - loss: 1.0619 - accuracy: 0.6604 - val_loss: 1.3871 - val_accuracy: 0.5776\n",
            "Learning rate:  0.001\n",
            "Epoch 4/50\n",
            "282/282 [==============================] - 8s 28ms/step - loss: 0.9741 - accuracy: 0.6911 - val_loss: 1.4450 - val_accuracy: 0.5753\n",
            "Learning rate:  0.001\n",
            "Epoch 5/50\n",
            "282/282 [==============================] - 8s 28ms/step - loss: 0.9133 - accuracy: 0.7087 - val_loss: 1.3310 - val_accuracy: 0.6235\n",
            "Learning rate:  0.001\n",
            "Epoch 6/50\n",
            "282/282 [==============================] - 8s 28ms/step - loss: 0.8771 - accuracy: 0.7231 - val_loss: 1.2156 - val_accuracy: 0.6470\n",
            "Learning rate:  0.001\n",
            "Epoch 7/50\n",
            "282/282 [==============================] - 8s 27ms/step - loss: 0.8484 - accuracy: 0.7416 - val_loss: 1.1206 - val_accuracy: 0.6713\n",
            "Learning rate:  0.001\n",
            "Epoch 8/50\n",
            "282/282 [==============================] - 8s 28ms/step - loss: 0.8186 - accuracy: 0.7547 - val_loss: 1.3677 - val_accuracy: 0.6060\n",
            "Learning rate:  0.001\n",
            "Epoch 9/50\n",
            "282/282 [==============================] - 8s 28ms/step - loss: 0.7745 - accuracy: 0.7757 - val_loss: 1.0189 - val_accuracy: 0.7042\n",
            "Learning rate:  0.001\n",
            "Epoch 10/50\n",
            "282/282 [==============================] - 8s 27ms/step - loss: 0.7440 - accuracy: 0.7851 - val_loss: 0.9214 - val_accuracy: 0.7329\n",
            "Learning rate:  0.001\n",
            "Epoch 11/50\n",
            "282/282 [==============================] - 8s 27ms/step - loss: 0.7305 - accuracy: 0.7828 - val_loss: 1.0885 - val_accuracy: 0.6895\n",
            "Learning rate:  0.0001\n",
            "Epoch 12/50\n",
            "282/282 [==============================] - 8s 27ms/step - loss: 0.6204 - accuracy: 0.8299 - val_loss: 0.7891 - val_accuracy: 0.7759\n",
            "Learning rate:  0.0001\n",
            "Epoch 13/50\n",
            "282/282 [==============================] - 8s 27ms/step - loss: 0.5790 - accuracy: 0.8426 - val_loss: 0.7567 - val_accuracy: 0.7891\n",
            "Learning rate:  0.0001\n",
            "Epoch 14/50\n",
            "282/282 [==============================] - 8s 27ms/step - loss: 0.5648 - accuracy: 0.8490 - val_loss: 0.7697 - val_accuracy: 0.7819\n",
            "Learning rate:  0.0001\n",
            "Epoch 15/50\n",
            "282/282 [==============================] - 7s 26ms/step - loss: 0.5484 - accuracy: 0.8538 - val_loss: 0.7714 - val_accuracy: 0.7866\n",
            "Learning rate:  0.0001\n",
            "Epoch 16/50\n",
            "282/282 [==============================] - 8s 27ms/step - loss: 0.5348 - accuracy: 0.8558 - val_loss: 0.7481 - val_accuracy: 0.7935\n",
            "Learning rate:  0.0001\n",
            "Epoch 17/50\n",
            "282/282 [==============================] - 7s 26ms/step - loss: 0.5176 - accuracy: 0.8646 - val_loss: 0.7474 - val_accuracy: 0.7933\n",
            "Learning rate:  0.0001\n",
            "Epoch 18/50\n",
            "282/282 [==============================] - 8s 27ms/step - loss: 0.5225 - accuracy: 0.8604 - val_loss: 0.7796 - val_accuracy: 0.7847\n",
            "Learning rate:  0.0001\n",
            "Epoch 19/50\n",
            "282/282 [==============================] - 8s 27ms/step - loss: 0.5118 - accuracy: 0.8663 - val_loss: 0.7624 - val_accuracy: 0.7924\n",
            "Learning rate:  0.0001\n",
            "Epoch 20/50\n",
            "282/282 [==============================] - 8s 27ms/step - loss: 0.4984 - accuracy: 0.8672 - val_loss: 0.7595 - val_accuracy: 0.7920\n",
            "Learning rate:  0.0001\n",
            "Epoch 21/50\n",
            "282/282 [==============================] - 8s 27ms/step - loss: 0.5125 - accuracy: 0.8659 - val_loss: 0.7534 - val_accuracy: 0.7941\n",
            "Learning rate:  1e-05\n",
            "Epoch 22/50\n",
            "282/282 [==============================] - 8s 27ms/step - loss: 0.4777 - accuracy: 0.8756 - val_loss: 0.7533 - val_accuracy: 0.7941\n",
            "Learning rate:  1e-05\n",
            "Epoch 23/50\n",
            "282/282 [==============================] - 8s 27ms/step - loss: 0.4738 - accuracy: 0.8809 - val_loss: 0.7519 - val_accuracy: 0.7942\n",
            "Learning rate:  1e-05\n",
            "Epoch 24/50\n",
            "282/282 [==============================] - 8s 27ms/step - loss: 0.4792 - accuracy: 0.8800 - val_loss: 0.7531 - val_accuracy: 0.7933\n",
            "Learning rate:  1e-05\n",
            "Epoch 25/50\n",
            "282/282 [==============================] - 8s 27ms/step - loss: 0.4816 - accuracy: 0.8747 - val_loss: 0.7489 - val_accuracy: 0.7946\n",
            "Learning rate:  1e-05\n",
            "Epoch 26/50\n",
            "282/282 [==============================] - 8s 27ms/step - loss: 0.4656 - accuracy: 0.8840 - val_loss: 0.7522 - val_accuracy: 0.7952\n",
            "Learning rate:  1e-05\n",
            "Epoch 27/50\n",
            "282/282 [==============================] - 8s 27ms/step - loss: 0.4798 - accuracy: 0.8801 - val_loss: 0.7516 - val_accuracy: 0.7954\n",
            "Learning rate:  1e-05\n",
            "Epoch 28/50\n",
            "282/282 [==============================] - 8s 27ms/step - loss: 0.4658 - accuracy: 0.8852 - val_loss: 0.7485 - val_accuracy: 0.7964\n",
            "Learning rate:  1e-05\n",
            "Epoch 29/50\n",
            "282/282 [==============================] - 8s 27ms/step - loss: 0.4652 - accuracy: 0.8846 - val_loss: 0.7479 - val_accuracy: 0.7977\n",
            "Learning rate:  1e-05\n",
            "Epoch 30/50\n",
            "282/282 [==============================] - 8s 27ms/step - loss: 0.4643 - accuracy: 0.8816 - val_loss: 0.7523 - val_accuracy: 0.7960\n",
            "Learning rate:  1e-05\n",
            "Epoch 31/50\n",
            "282/282 [==============================] - 8s 27ms/step - loss: 0.4599 - accuracy: 0.8833 - val_loss: 0.7487 - val_accuracy: 0.7960\n",
            "Learning rate:  1e-06\n",
            "Epoch 32/50\n",
            "282/282 [==============================] - 8s 27ms/step - loss: 0.4565 - accuracy: 0.8864 - val_loss: 0.7476 - val_accuracy: 0.7971\n",
            "Learning rate:  1e-06\n",
            "Epoch 33/50\n",
            "282/282 [==============================] - 8s 27ms/step - loss: 0.4709 - accuracy: 0.8779 - val_loss: 0.7479 - val_accuracy: 0.7970\n",
            "Learning rate:  1e-06\n",
            "Epoch 34/50\n",
            "282/282 [==============================] - 8s 27ms/step - loss: 0.4693 - accuracy: 0.8790 - val_loss: 0.7492 - val_accuracy: 0.7969\n",
            "Learning rate:  1e-06\n",
            "Epoch 35/50\n",
            "282/282 [==============================] - 8s 27ms/step - loss: 0.4643 - accuracy: 0.8802 - val_loss: 0.7479 - val_accuracy: 0.7968\n",
            "Learning rate:  1e-06\n",
            "Epoch 36/50\n",
            "282/282 [==============================] - 8s 27ms/step - loss: 0.4557 - accuracy: 0.8880 - val_loss: 0.7492 - val_accuracy: 0.7968\n",
            "Learning rate:  1e-06\n",
            "Epoch 37/50\n",
            "282/282 [==============================] - 8s 27ms/step - loss: 0.4663 - accuracy: 0.8794 - val_loss: 0.7476 - val_accuracy: 0.7966\n",
            "Learning rate:  1e-06\n",
            "Epoch 38/50\n",
            "282/282 [==============================] - 8s 27ms/step - loss: 0.4576 - accuracy: 0.8848 - val_loss: 0.7492 - val_accuracy: 0.7968\n",
            "Learning rate:  1e-06\n",
            "Epoch 39/50\n",
            "282/282 [==============================] - 8s 27ms/step - loss: 0.4687 - accuracy: 0.8808 - val_loss: 0.7488 - val_accuracy: 0.7970\n",
            "Learning rate:  1e-06\n",
            "Epoch 40/50\n",
            "282/282 [==============================] - 8s 27ms/step - loss: 0.4680 - accuracy: 0.8813 - val_loss: 0.7463 - val_accuracy: 0.7972\n",
            "Learning rate:  1e-06\n",
            "Epoch 41/50\n",
            "282/282 [==============================] - 8s 27ms/step - loss: 0.4596 - accuracy: 0.8852 - val_loss: 0.7465 - val_accuracy: 0.7971\n",
            "Learning rate:  5e-07\n",
            "Epoch 42/50\n",
            "282/282 [==============================] - 8s 27ms/step - loss: 0.4677 - accuracy: 0.8764 - val_loss: 0.7486 - val_accuracy: 0.7971\n",
            "Learning rate:  5e-07\n",
            "Epoch 43/50\n",
            "282/282 [==============================] - 8s 27ms/step - loss: 0.4652 - accuracy: 0.8816 - val_loss: 0.7472 - val_accuracy: 0.7977\n",
            "Learning rate:  5e-07\n",
            "Epoch 44/50\n",
            "282/282 [==============================] - 8s 27ms/step - loss: 0.4623 - accuracy: 0.8827 - val_loss: 0.7494 - val_accuracy: 0.7971\n",
            "Learning rate:  5e-07\n",
            "Epoch 45/50\n",
            "282/282 [==============================] - 8s 27ms/step - loss: 0.4565 - accuracy: 0.8844 - val_loss: 0.7480 - val_accuracy: 0.7978\n",
            "Learning rate:  5e-07\n",
            "Epoch 46/50\n",
            "282/282 [==============================] - 8s 27ms/step - loss: 0.4660 - accuracy: 0.8823 - val_loss: 0.7467 - val_accuracy: 0.7976\n",
            "Learning rate:  5e-07\n",
            "Epoch 47/50\n",
            "282/282 [==============================] - 8s 27ms/step - loss: 0.4633 - accuracy: 0.8842 - val_loss: 0.7479 - val_accuracy: 0.7974\n",
            "Learning rate:  5e-07\n",
            "Epoch 48/50\n",
            "282/282 [==============================] - 8s 27ms/step - loss: 0.4592 - accuracy: 0.8829 - val_loss: 0.7483 - val_accuracy: 0.7982\n",
            "Learning rate:  5e-07\n",
            "Epoch 49/50\n",
            "282/282 [==============================] - 8s 28ms/step - loss: 0.4603 - accuracy: 0.8841 - val_loss: 0.7469 - val_accuracy: 0.7983\n",
            "Learning rate:  5e-07\n",
            "Epoch 50/50\n",
            "282/282 [==============================] - 8s 27ms/step - loss: 0.4679 - accuracy: 0.8804 - val_loss: 0.7476 - val_accuracy: 0.7979\n",
            " -- PATH: self_supervised\n",
            " -- write into csv file\n",
            "Num of trainings: 9\n",
            "Learning rate:  0.001\n",
            "ResNet20\n",
            "Using real-time data augmentation.\n",
            "Learning rate:  0.001\n",
            "Epoch 1/50\n",
            "313/313 [==============================] - 9s 29ms/step - loss: 1.4216 - accuracy: 0.5137 - val_loss: 1.3104 - val_accuracy: 0.5695\n",
            "Learning rate:  0.001\n",
            "Epoch 2/50\n",
            "313/313 [==============================] - 8s 27ms/step - loss: 1.1309 - accuracy: 0.6233 - val_loss: 1.4534 - val_accuracy: 0.5412\n",
            "Learning rate:  0.001\n",
            "Epoch 3/50\n",
            "313/313 [==============================] - 8s 27ms/step - loss: 1.0526 - accuracy: 0.6562 - val_loss: 1.2384 - val_accuracy: 0.6121\n",
            "Learning rate:  0.001\n",
            "Epoch 4/50\n",
            "313/313 [==============================] - 8s 27ms/step - loss: 0.9595 - accuracy: 0.6954 - val_loss: 1.4283 - val_accuracy: 0.5915\n",
            "Learning rate:  0.001\n",
            "Epoch 5/50\n",
            "313/313 [==============================] - 8s 27ms/step - loss: 0.9311 - accuracy: 0.7075 - val_loss: 1.4175 - val_accuracy: 0.6226\n",
            "Learning rate:  0.001\n",
            "Epoch 6/50\n",
            "313/313 [==============================] - 8s 27ms/step - loss: 0.8600 - accuracy: 0.7371 - val_loss: 1.1608 - val_accuracy: 0.6517\n",
            "Learning rate:  0.001\n",
            "Epoch 7/50\n",
            "313/313 [==============================] - 8s 27ms/step - loss: 0.8252 - accuracy: 0.7476 - val_loss: 1.2319 - val_accuracy: 0.6211\n",
            "Learning rate:  0.001\n",
            "Epoch 8/50\n",
            "313/313 [==============================] - 8s 26ms/step - loss: 0.8125 - accuracy: 0.7522 - val_loss: 1.0026 - val_accuracy: 0.7016\n",
            "Learning rate:  0.001\n",
            "Epoch 9/50\n",
            "313/313 [==============================] - 8s 27ms/step - loss: 0.7817 - accuracy: 0.7682 - val_loss: 1.0322 - val_accuracy: 0.6965\n",
            "Learning rate:  0.001\n",
            "Epoch 10/50\n",
            "313/313 [==============================] - 8s 27ms/step - loss: 0.7496 - accuracy: 0.7822 - val_loss: 1.0059 - val_accuracy: 0.7036\n",
            "Learning rate:  0.001\n",
            "Epoch 11/50\n",
            "313/313 [==============================] - 8s 27ms/step - loss: 0.7419 - accuracy: 0.7804 - val_loss: 1.0915 - val_accuracy: 0.6972\n",
            "Learning rate:  0.0001\n",
            "Epoch 12/50\n",
            "313/313 [==============================] - 8s 27ms/step - loss: 0.6287 - accuracy: 0.8252 - val_loss: 0.7808 - val_accuracy: 0.7770\n",
            "Learning rate:  0.0001\n",
            "Epoch 13/50\n",
            "313/313 [==============================] - 8s 26ms/step - loss: 0.5857 - accuracy: 0.8386 - val_loss: 0.7596 - val_accuracy: 0.7864\n",
            "Learning rate:  0.0001\n",
            "Epoch 14/50\n",
            "313/313 [==============================] - 8s 26ms/step - loss: 0.5678 - accuracy: 0.8470 - val_loss: 0.7594 - val_accuracy: 0.7867\n",
            "Learning rate:  0.0001\n",
            "Epoch 15/50\n",
            "313/313 [==============================] - 8s 27ms/step - loss: 0.5539 - accuracy: 0.8492 - val_loss: 0.7524 - val_accuracy: 0.7893\n",
            "Learning rate:  0.0001\n",
            "Epoch 16/50\n",
            "313/313 [==============================] - 8s 27ms/step - loss: 0.5433 - accuracy: 0.8546 - val_loss: 0.7672 - val_accuracy: 0.7842\n",
            "Learning rate:  0.0001\n",
            "Epoch 17/50\n",
            "313/313 [==============================] - 8s 26ms/step - loss: 0.5356 - accuracy: 0.8587 - val_loss: 0.7846 - val_accuracy: 0.7823\n",
            "Learning rate:  0.0001\n",
            "Epoch 18/50\n",
            "313/313 [==============================] - 8s 26ms/step - loss: 0.5298 - accuracy: 0.8579 - val_loss: 0.7452 - val_accuracy: 0.7937\n",
            "Learning rate:  0.0001\n",
            "Epoch 19/50\n",
            "313/313 [==============================] - 8s 27ms/step - loss: 0.5115 - accuracy: 0.8628 - val_loss: 0.7486 - val_accuracy: 0.7941\n",
            "Learning rate:  0.0001\n",
            "Epoch 20/50\n",
            "313/313 [==============================] - 8s 27ms/step - loss: 0.5058 - accuracy: 0.8686 - val_loss: 0.7688 - val_accuracy: 0.7901\n",
            "Learning rate:  0.0001\n",
            "Epoch 21/50\n",
            "313/313 [==============================] - 8s 27ms/step - loss: 0.4963 - accuracy: 0.8679 - val_loss: 0.7660 - val_accuracy: 0.7885\n",
            "Learning rate:  1e-05\n",
            "Epoch 22/50\n",
            "313/313 [==============================] - 8s 27ms/step - loss: 0.4843 - accuracy: 0.8715 - val_loss: 0.7436 - val_accuracy: 0.7946\n",
            "Learning rate:  1e-05\n",
            "Epoch 23/50\n",
            "313/313 [==============================] - 8s 27ms/step - loss: 0.4773 - accuracy: 0.8768 - val_loss: 0.7459 - val_accuracy: 0.7938\n",
            "Learning rate:  1e-05\n",
            "Epoch 24/50\n",
            "313/313 [==============================] - 8s 26ms/step - loss: 0.4813 - accuracy: 0.8750 - val_loss: 0.7395 - val_accuracy: 0.7977\n",
            "Learning rate:  1e-05\n",
            "Epoch 25/50\n",
            "313/313 [==============================] - 8s 26ms/step - loss: 0.4838 - accuracy: 0.8736 - val_loss: 0.7406 - val_accuracy: 0.7967\n",
            "Learning rate:  1e-05\n",
            "Epoch 26/50\n",
            "313/313 [==============================] - 8s 26ms/step - loss: 0.4830 - accuracy: 0.8757 - val_loss: 0.7429 - val_accuracy: 0.7949\n",
            "Learning rate:  1e-05\n",
            "Epoch 27/50\n",
            "313/313 [==============================] - 8s 27ms/step - loss: 0.4787 - accuracy: 0.8762 - val_loss: 0.7468 - val_accuracy: 0.7931\n",
            "Learning rate:  1e-05\n",
            "Epoch 28/50\n",
            "313/313 [==============================] - 8s 27ms/step - loss: 0.4752 - accuracy: 0.8817 - val_loss: 0.7416 - val_accuracy: 0.7966\n",
            "Learning rate:  1e-05\n",
            "Epoch 29/50\n",
            "313/313 [==============================] - 8s 27ms/step - loss: 0.4748 - accuracy: 0.8783 - val_loss: 0.7431 - val_accuracy: 0.7952\n",
            "Learning rate:  1e-05\n",
            "Epoch 30/50\n",
            "313/313 [==============================] - 8s 27ms/step - loss: 0.4795 - accuracy: 0.8768 - val_loss: 0.7418 - val_accuracy: 0.7958\n",
            "Learning rate:  1e-05\n",
            "Epoch 31/50\n",
            "313/313 [==============================] - 8s 27ms/step - loss: 0.4738 - accuracy: 0.8789 - val_loss: 0.7453 - val_accuracy: 0.7953\n",
            "Learning rate:  1e-06\n",
            "Epoch 32/50\n",
            "313/313 [==============================] - 8s 26ms/step - loss: 0.4662 - accuracy: 0.8818 - val_loss: 0.7452 - val_accuracy: 0.7947\n",
            "Learning rate:  1e-06\n",
            "Epoch 33/50\n",
            "313/313 [==============================] - 8s 26ms/step - loss: 0.4703 - accuracy: 0.8805 - val_loss: 0.7445 - val_accuracy: 0.7949\n",
            "Learning rate:  1e-06\n",
            "Epoch 34/50\n",
            "313/313 [==============================] - 8s 26ms/step - loss: 0.4668 - accuracy: 0.8786 - val_loss: 0.7465 - val_accuracy: 0.7951\n",
            "Learning rate:  1e-06\n",
            "Epoch 35/50\n",
            "313/313 [==============================] - 9s 28ms/step - loss: 0.4742 - accuracy: 0.8791 - val_loss: 0.7442 - val_accuracy: 0.7954\n",
            "Learning rate:  1e-06\n",
            "Epoch 36/50\n",
            "313/313 [==============================] - 8s 27ms/step - loss: 0.4684 - accuracy: 0.8804 - val_loss: 0.7447 - val_accuracy: 0.7953\n",
            "Learning rate:  1e-06\n",
            "Epoch 37/50\n",
            "313/313 [==============================] - 8s 27ms/step - loss: 0.4654 - accuracy: 0.8833 - val_loss: 0.7455 - val_accuracy: 0.7952\n",
            "Learning rate:  1e-06\n",
            "Epoch 38/50\n",
            "313/313 [==============================] - 8s 27ms/step - loss: 0.4679 - accuracy: 0.8801 - val_loss: 0.7444 - val_accuracy: 0.7950\n",
            "Learning rate:  1e-06\n",
            "Epoch 39/50\n",
            "313/313 [==============================] - 8s 27ms/step - loss: 0.4636 - accuracy: 0.8797 - val_loss: 0.7427 - val_accuracy: 0.7960\n",
            "Learning rate:  1e-06\n",
            "Epoch 40/50\n",
            "313/313 [==============================] - 8s 27ms/step - loss: 0.4716 - accuracy: 0.8778 - val_loss: 0.7463 - val_accuracy: 0.7944\n",
            "Learning rate:  1e-06\n",
            "Epoch 41/50\n",
            "313/313 [==============================] - 8s 26ms/step - loss: 0.4712 - accuracy: 0.8809 - val_loss: 0.7455 - val_accuracy: 0.7947\n",
            "Learning rate:  5e-07\n",
            "Epoch 42/50\n",
            "313/313 [==============================] - 8s 27ms/step - loss: 0.4687 - accuracy: 0.8778 - val_loss: 0.7451 - val_accuracy: 0.7956\n",
            "Learning rate:  5e-07\n",
            "Epoch 43/50\n",
            "313/313 [==============================] - 8s 27ms/step - loss: 0.4755 - accuracy: 0.8757 - val_loss: 0.7451 - val_accuracy: 0.7951\n",
            "Learning rate:  5e-07\n",
            "Epoch 44/50\n",
            "313/313 [==============================] - 8s 27ms/step - loss: 0.4734 - accuracy: 0.8765 - val_loss: 0.7448 - val_accuracy: 0.7949\n",
            "Learning rate:  5e-07\n",
            "Epoch 45/50\n",
            "313/313 [==============================] - 8s 26ms/step - loss: 0.4657 - accuracy: 0.8820 - val_loss: 0.7434 - val_accuracy: 0.7960\n",
            "Learning rate:  5e-07\n",
            "Epoch 46/50\n",
            "313/313 [==============================] - 8s 26ms/step - loss: 0.4719 - accuracy: 0.8771 - val_loss: 0.7435 - val_accuracy: 0.7962\n",
            "Learning rate:  5e-07\n",
            "Epoch 47/50\n",
            "313/313 [==============================] - 8s 27ms/step - loss: 0.4671 - accuracy: 0.8807 - val_loss: 0.7436 - val_accuracy: 0.7956\n",
            "Learning rate:  5e-07\n",
            "Epoch 48/50\n",
            "313/313 [==============================] - 8s 26ms/step - loss: 0.4752 - accuracy: 0.8776 - val_loss: 0.7463 - val_accuracy: 0.7960\n",
            "Learning rate:  5e-07\n",
            "Epoch 49/50\n",
            "313/313 [==============================] - 8s 27ms/step - loss: 0.4721 - accuracy: 0.8788 - val_loss: 0.7434 - val_accuracy: 0.7959\n",
            "Learning rate:  5e-07\n",
            "Epoch 50/50\n",
            "313/313 [==============================] - 8s 27ms/step - loss: 0.4762 - accuracy: 0.8822 - val_loss: 0.7427 - val_accuracy: 0.7966\n",
            " -- PATH: self_supervised\n",
            " -- write into csv file\n",
            "Num of trainings: 10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8kZQ_onj_1tZ"
      },
      "source": [
        "def plot_ssl_vs_sl(df_ssl, df_sl, data_increment=0.1):\n",
        "    #df_sl = pd.read_csv('cifar10_large' +'_supervised.csv')\n",
        "    #df_ssl = pd.read_csv('cifar10_large' +'_ssl.csv')\n",
        "    df_sl['Model_Type']='Only_Supervised'\n",
        "    df = pd.concat((df_sl,df_ssl))\n",
        "    df['Model_Type'][len(df_ssl):]='Self_Supervised'\n",
        "    df['Number_of_Samples'] = (df['Unnamed: 0']+1) *50000*data_increment\n",
        "    df['Test_Accuracy'] = df['Val_Accuracy']\n",
        "    \n",
        "    figure = plt.figure(figsize=(10,5))\n",
        "    g = sns.lineplot(y='Test_Accuracy',x='Number_of_Samples',hue='Model_Type',data=df)\n",
        "    title='Accuracy Self-Supervised vs Only Supervised'\n",
        "    g.set_title(title)\n",
        "    \n",
        "    figure = plt.figure(figsize=(10,5))\n",
        "    f = sns.lineplot(y='Val_Loss',x='Number_of_Samples',hue='Model_Type',data=df)\n",
        "    title='Loss Self-Supervised vs Only Supervised'\n",
        "    f.set_title(title)\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H7YNgou1_6Y8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 790
        },
        "outputId": "eeb4cb85-7101-4e53-e316-454d5f9ff81d"
      },
      "source": [
        "df_sl = pd.read_csv('/content/drive/My Drive/Colab Notebooks/Self-Supervised-Learning/Pre-text_Rotation/_supervised.csv')\n",
        "df_ssl = pd.read_csv('/content/drive/My Drive/Colab Notebooks/Self-Supervised-Learning/Pre-text_Rotation/_self_supervised.csv')\n",
        "\n",
        "plot_ssl_vs_sl(df_ssl,df_sl,data_increment=0.02 )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tA8mHPpb_7n3"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}