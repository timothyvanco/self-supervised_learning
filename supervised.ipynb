{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "supervised.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "syU19oRMMEkB",
        "outputId": "a8f05f96-61b1-474e-e12e-ee43d231ee39"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "exxOiLa7MId6"
      },
      "source": [
        "import os\r\n",
        "from pathlib import Path\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import seaborn as sns\r\n",
        "\r\n",
        "import pandas as pd\r\n",
        "import glob\r\n",
        "import torch\r\n",
        "import yaml\r\n",
        "from torchvision import datasets\r\n",
        "\r\n",
        "from torch.optim import lr_scheduler\r\n",
        "import random\r\n",
        "from tqdm import tqdm\r\n",
        "import copy\r\n",
        "import json\r\n",
        "from torchvision import transforms\r\n",
        "import torch.nn as nn\r\n",
        "from torch import nn\r\n",
        "import numpy as np\r\n",
        "from PIL import Image\r\n",
        "\r\n",
        "from torchvision.transforms import transforms\r\n",
        "\r\n",
        "import torchvision.models as models\r\n",
        "from collections import OrderedDict\r\n",
        "\r\n",
        "import torch.nn.functional as F\r\n",
        "from torchvision import transforms as T\r\n",
        "import torchvision\r\n",
        "from torch.utils.data.dataloader import DataLoader\r\n",
        "from torch.utils.tensorboard import SummaryWriter\r\n",
        "\r\n",
        "from shutil import copyfile\r\n",
        "import time\r\n",
        "# !pip install --ignore-installed PyYAML"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QwuMqUc1WtM1"
      },
      "source": [
        "class ResNet(torch.nn.Module):\r\n",
        "    def __init__(self, network_name):\r\n",
        "        super(ResNet, self).__init__()\r\n",
        "        if network_name == 'resnet18':\r\n",
        "            resnet = models.resnet18(pretrained=False)\r\n",
        "        elif network_name == 'resnet50':\r\n",
        "            resnet = models.resnet50(pretrained=False)\r\n",
        "\r\n",
        "\r\n",
        "        self.encoder = torch.nn.Sequential(*list(resnet.children())[:-1])\r\n",
        "\r\n",
        "        self.projection = MLPHead(IN_channels      = resnet.fc.in_features, \r\n",
        "                                  mlp_HIDDEN_size  = projection_head_mlp_hidden_size,\r\n",
        "                                  OUT_channels     = projection_head_projection_size)\r\n",
        "\r\n",
        "    def forward(self, x):\r\n",
        "        h = self.encoder(x)\r\n",
        "        h = h.view(h.shape[0], h.shape[1])\r\n",
        "        return self.projection(h)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DKbAbpFH-mbF"
      },
      "source": [
        "class MLPHead(nn.Module):\r\n",
        "    def __init__(self, IN_channels, mlp_HIDDEN_size, OUT_channels):\r\n",
        "        super(MLPHead, self).__init__()\r\n",
        "\r\n",
        "        self.net = nn.Sequential(\r\n",
        "                      nn.Linear(IN_channels, mlp_HIDDEN_size),\r\n",
        "                      nn.BatchNorm1d(mlp_HIDDEN_size),\r\n",
        "                      nn.ReLU(inplace=True),\r\n",
        "                      nn.Linear(mlp_HIDDEN_size, OUT_channels))\r\n",
        "\r\n",
        "    def forward(self, x):\r\n",
        "        return self.net(x)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zU0m9Gn3MMQf"
      },
      "source": [
        "# Data augmentation and normalization for training\r\n",
        "# Just normalization for validation\r\n",
        "data_transforms_supervised = {\r\n",
        "    'train': transforms.Compose([\r\n",
        "        transforms.RandomResizedCrop(28),\r\n",
        "        transforms.RandomHorizontalFlip(),\r\n",
        "        transforms.ToTensor(),\r\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\r\n",
        "    ]),\r\n",
        "    'test': transforms.Compose([\r\n",
        "        transforms.Resize(28),\r\n",
        "        transforms.CenterCrop(28),\r\n",
        "        transforms.ToTensor(),\r\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\r\n",
        "    ]),\r\n",
        "}\r\n",
        "\r\n",
        "results_supervised = {'train_loss': [], 'test_loss': [], \r\n",
        "                      'train_acc': [], 'test_acc': []}                   \r\n",
        "\r\n",
        "results_BYOL = {'train_loss': [], 'test_loss': [], \r\n",
        "                'train_acc': [], 'test_acc': []}   \r\n",
        "\r\n",
        "results = {'train_loss': [], 'test_loss': [], \r\n",
        "           'train_acc': [], 'test_acc': []}   "
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AW87uwNZWT7f"
      },
      "source": [
        "def save_plot_model_optim_supervised(train_losses, test_losses, model, type_results):\r\n",
        "    if type_results == \"BYOL\":\r\n",
        "        print(\"[INFO] Plotting - saving after supervised training on BYOL pretrained model into files to: {}\".format(results_path))\r\n",
        "            \r\n",
        "        plot_acc_loss(train_losses, test_losses, \"Epochs\", \"Loss\", 'Train Loss', 'Test Loss', \"Training Losses\", os.path.join(results_path, 'Supervised_BYOL_training_losses.png'))\r\n",
        "            \r\n",
        "        torch.save(model.state_dict(), os.path.join(results_path, \"Supervised_BYOL_model.pth\"))\r\n",
        "        np.savez(os.path.join(results_path, \"Supervised_BYOL_lossesfile\"), np.array(train_losses))\r\n",
        "        np.savetxt(os.path.join(results_path, \"Supervised_BYOL_lossesfile.csv\"), train_losses, delimiter=\",\")\r\n",
        "\r\n",
        "    elif type_results == \"notpretrained\":\r\n",
        "        print(\"[INFO] Plotting - saving after supervised training on NOT-pretrained model into files to: {}\".format(results_path))\r\n",
        "            \r\n",
        "        plot_acc_loss(train_losses, test_losses, \"Epochs\", \"Loss\", 'Train Loss', 'Test Loss', \"Training Losses\", os.path.join(results_path, 'Supervised_NotPret_training_losses.png'))\r\n",
        "            \r\n",
        "        torch.save(model.state_dict(), os.path.join(results_path, \"Supervised_NotPret_model.pth\"))\r\n",
        "        np.savez(os.path.join(results_path, \"Supervised_NotPret_lossesfile\"), np.array(train_losses))\r\n",
        "        np.savetxt(os.path.join(results_path, \"Supervised_NotPret_lossesfile.csv\"), train_losses, delimiter=\",\")\r\n",
        "\r\n",
        "# array of data, name of graph, folder to save\r\n",
        "def plot_acc_loss(arr1, arr2, x_axes, y_axes, legend1, legend2, legend_name, fname):\r\n",
        "    plt.figure(figsize=(10, 10))\r\n",
        "    sns.set_style('darkgrid')\r\n",
        "    plt.title(legend_name)\r\n",
        "    plt.plot(arr1, label=arr1)\r\n",
        "    if arr2:\r\n",
        "        plt.plot(arr2, label=arr2)\r\n",
        "    plt.xlabel(x_axes)\r\n",
        "    plt.ylabel(y_axes)\r\n",
        "    plt.legend([legend1, legend2])\r\n",
        "    plt.savefig(fname)\r\n",
        "    plt.show()\r\n",
        "    plt.close()"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b8BaPJ3pMONu"
      },
      "source": [
        "# MODEL\r\n",
        "def get_model(arch, out_dim):\r\n",
        "    # defining our deep learning architecture\r\n",
        "    if arch == \"resnet18\":\r\n",
        "      resnet = models.resnet18(pretrained=False, num_classes=out_dim)\r\n",
        "    elif arch == \"resnet34\":\r\n",
        "      resnet = models.resnet34(pretrained=False, num_classes=out_dim)\r\n",
        "    elif arch == \"resnet50\":\r\n",
        "      resnet = models.resnet50(pretrained=False, num_classes=out_dim)\r\n",
        "    else:\r\n",
        "      print(\"[ERROR] Define resnet18 or resnet34 or resnet50\")\r\n",
        "\r\n",
        "    print(\"[INFO] Training on architecture: {}\".format(arch))\r\n",
        "\r\n",
        "    resnet.to(device)\r\n",
        "\r\n",
        "    return resnet"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u4iaHTtGMQSi"
      },
      "source": [
        "class Supervised:\r\n",
        "    def __init__(self, model, optimizer, scheduler, dataloaders, loss_function):\r\n",
        "        self.model = model\r\n",
        "        self.optimizer = optimizer\r\n",
        "        self.scheduler = scheduler\r\n",
        "        self.dataloaders = dataloaders\r\n",
        "        self.loss_function = loss_function\r\n",
        "        #logging.basicConfig(filename=os.path.join(results_path, 'training.log'), level=logging.DEBUG)\r\n",
        "\r\n",
        "    def train_test_model(self, epochs, log_interval):\r\n",
        "        since = time.time()\r\n",
        "\r\n",
        "        best_model_wts = copy.deepcopy(self.model.state_dict())\r\n",
        "        best_acc, epoch_of_best_acc = 0.0, 0\r\n",
        "        \r\n",
        "        for epoch in range(1, SUPERVISED_EPOCHS+1):\r\n",
        "            since_epoch = time.time()\r\n",
        "            print('-' * 10)\r\n",
        "            print('Epoch {}/{}'.format(epoch, SUPERVISED_EPOCHS))\r\n",
        "            \r\n",
        "            # Each epoch has a training and validation phase\r\n",
        "            for phase in ['train', 'test']:\r\n",
        "                if phase == 'train':\r\n",
        "                    self.model.train()  # Set model to training mode\r\n",
        "                else:\r\n",
        "                    self.model.eval()   # Set model to evaluate mode\r\n",
        "\r\n",
        "                running_loss = 0.0\r\n",
        "                running_corrects = 0\r\n",
        "\r\n",
        "                # Iterate over data.\r\n",
        "                for inputs, labels in self.dataloaders[phase]:\r\n",
        "                    inputs = inputs.to(device)\r\n",
        "                    labels = labels.to(device)\r\n",
        "\r\n",
        "                    # zero the parameter gradients\r\n",
        "                    self.optimizer.zero_grad()\r\n",
        "\r\n",
        "                    # forward - track history if only in train\r\n",
        "                    with torch.set_grad_enabled(phase == 'train'):\r\n",
        "                        outputs = self.model(inputs)\r\n",
        "                        _, preds = torch.max(outputs, 1)\r\n",
        "                        loss = self.loss_function(outputs, labels)\r\n",
        "\r\n",
        "                        # backward + optimize only if in training phase\r\n",
        "                        if phase == 'train':\r\n",
        "                            loss.backward()\r\n",
        "                            self.optimizer.step()\r\n",
        "\r\n",
        "                    # statistics\r\n",
        "                    running_loss += loss.item() * inputs.size(0)\r\n",
        "                    running_corrects += torch.sum(preds == labels.data)\r\n",
        "                #if phase == 'train':\r\n",
        "                    #scheduler.step()\r\n",
        "\r\n",
        "                epoch_loss = running_loss / dataset_sizes[phase]\r\n",
        "                epoch_acc = running_corrects.double() / dataset_sizes[phase]\r\n",
        "\r\n",
        "                if phase == 'train':\r\n",
        "                    results_supervised['train_loss'].append(epoch_loss)\r\n",
        "                    results_supervised['train_acc'].append(epoch_acc.item())\r\n",
        "                if phase == 'test':\r\n",
        "                    results_supervised['test_loss'].append(epoch_loss)\r\n",
        "                    results_supervised['test_acc'].append(epoch_acc.item())\r\n",
        "\r\n",
        "                time_elapsed_epoch = time.time() - since_epoch\r\n",
        "                print(\"[INFO] {} - Epoch {}/{} - Loss {:.4f} - Acc: {:.4f} - Time of last epoch: {:.0f}m {:.0f}s\".format(phase, epoch, SUPERVISED_EPOCHS, epoch_loss, epoch_acc, time_elapsed_epoch // 60, time_elapsed_epoch % 60))\r\n",
        "                #logging.info('Epoch {} - Loss: {:.4f} - Acc: {:.4f}'.format(epoch, epoch_loss, epoch_acc))\r\n",
        "\r\n",
        "                # deep copy the model\r\n",
        "                if phase == 'test' and epoch_acc > best_acc:\r\n",
        "                    best_acc = epoch_acc\r\n",
        "                    best_model_wts = copy.deepcopy(self.model.state_dict())\r\n",
        "                    epoch_of_best_acc = epoch\r\n",
        "\r\n",
        "                \r\n",
        "        #logging.info('-------------TRAINING FINNISH-------------')\r\n",
        "        time_elapsed = time.time() - since\r\n",
        "        print('[INFO] Training completed in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\r\n",
        "        print('[INFO] Best testing Accuracy: {:2} on epoch: {}'.format(best_acc*100, epoch_of_best_acc))\r\n",
        "\r\n",
        "        plot_acc_loss(results_supervised['train_loss'], results_supervised['test_loss'], \"EPOCHS\", \"LOSSES\", \"Train Loss\", \"Test Loss\", \"Losses\", os.path.join(results_path, \"train_test_losses_supervised.jpg\"))\r\n",
        "        plot_acc_loss(results_supervised['train_acc'], results_supervised['test_acc'], \"EPOCHS\", \"ACCURACY\", \"Train Acc\", \"Test Acc\", \"Accuracy\", os.path.join(results_path, \"train_test_acc_supervised.jpg\"))\r\n",
        "\r\n",
        "        data_frame = pd.DataFrame(data=results_supervised, index=range(1, epoch + 1))\r\n",
        "        data_frame.to_csv(os.path.join(results_path, \"DATA_loss_acc_supervised.csv\"), index_label='epoch')\r\n",
        "\r\n",
        "        # load best model weights\r\n",
        "        self.model.load_state_dict(best_model_wts)\r\n",
        "        return self.model, results"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H6reeLnlNhfO",
        "outputId": "10e748fe-e283-4a7d-9b03-00d27a00a400"
      },
      "source": [
        "arch = \"resnet18\"\r\n",
        "dataset = \"MNIST\"\r\n",
        "\r\n",
        "SUPERVISED_BATCH = 256\r\n",
        "SUPERVISED_EPOCHS = 5\r\n",
        "NUM_OUTPUT_CLASS = 10\r\n",
        "LOG_INTERVAL = 10\r\n",
        "\r\n",
        "print(\"[INFO] Preparing Datasets...\")\r\n",
        "\r\n",
        "data_dir = '/content/drive/MyDrive/Colab Notebooks/Self-Supervised-Learning/datasets/MNIST_folders'\r\n",
        "\r\n",
        "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms_supervised[x]) for x in ['train', 'test']}\r\n",
        "dataloaders =    {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=SUPERVISED_BATCH, shuffle=True, num_workers=4) for x in ['train', 'test']}\r\n",
        "\r\n",
        "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'test']}\r\n",
        "class_names = image_datasets['train'].classes\r\n",
        "print(\"[INFO] Class names: {}\".format(class_names))\r\n",
        "\r\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\r\n",
        "print(\"[INFO] Training on: {}\".format(device))\r\n",
        "\r\n",
        "results_path = \"/content/drive/MyDrive/Colab Notebooks/Supervised-Learning/results/supervised-mlp\"     # Path to the results directory where the saved model and evaluation graphs would be stored.\r\n",
        "specific_folder = 'dataset-{}_arch-{}_epochs-{}_batch-{}/'.format(dataset, arch, SUPERVISED_EPOCHS, SUPERVISED_BATCH)\r\n",
        "results_path = os.path.join(results_path, specific_folder)\r\n",
        "Path(results_path).mkdir(parents=True, exist_ok=True)\r\n",
        "print(\"[INFO] Results path: {}\".format(results_path))"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] Preparing Datasets...\n",
            "[INFO] Class names: ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
            "[INFO] Training on: cuda:0\n",
            "[INFO] Results path: /content/drive/MyDrive/Colab Notebooks/Supervised-Learning/results/supervised-mlp/dataset-MNIST_arch-resnet18_epochs-5_batch-256/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1zJPUOdgO5w7"
      },
      "source": [
        "model_supervised = get_model(arch, NUM_OUTPUT_CLASS)\r\n",
        "\r\n",
        "learning_rate = 0.01\r\n",
        "momentum = 0.9\r\n",
        "\r\n",
        "loss_function = nn.CrossEntropyLoss()\r\n",
        "optimizer_ft = torch.optim.SGD(model_supervised.parameters(), lr=learning_rate, momentum=momentum)              # Observe that all parameters are being optimized\r\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)      # Decay LR by a factor of 0.1 every 7 epochs\r\n",
        "\r\n",
        "supervised_model = Supervised(model_supervised, optimizer_ft, None, dataloaders, loss_function)\r\n",
        "print(\"[INFO] Start training on MNIST dataset for {} epochs, with {} batch_size...\".format(SUPERVISED_EPOCHS, SUPERVISED_BATCH))\r\n",
        "supervised_model_trained, results_supervised = supervised_model.train_test_model(SUPERVISED_EPOCHS, LOG_INTERVAL)\r\n",
        "save_plot_model_optim_supervised(results_supervised['train_loss'], results_supervised['test_loss'], supervised_model_trained, type_results=\"notpretrained\")   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H97nZfrg_euB",
        "outputId": "cd8792d9-d9e7-433d-e39e-580e0bce80b1"
      },
      "source": [
        "model_supervised"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu): ReLU(inplace=True)\n",
              "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (layer1): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jXq_fN29WLa9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8bae3ae8-f617-4b2b-976e-e89b8ab8c906"
      },
      "source": [
        "# configurations for the projection and prediction heads\r\n",
        "projection_head_mlp_hidden_size = 512     # Original implementation uses 4096\r\n",
        "projection_head_projection_size = 128     # Original implementation uses 256\r\n",
        "\r\n",
        "# LOAD PRETRAINED MODEL on BYOL\r\n",
        "BYOL_pretrained = ResNet(arch).to(device)\r\n",
        "\r\n",
        "# predictor network\r\n",
        "predictor = MLPHead(IN_channels = BYOL_pretrained.projection.net[-1].out_features, \r\n",
        "                    mlp_HIDDEN_size = projection_head_mlp_hidden_size, \r\n",
        "                    OUT_channels = projection_head_projection_size).to(device)\r\n",
        "\r\n",
        "results_path_load_BYOL = \"/content/drive/MyDrive/Colab Notebooks/Self-Supervised-Learning/BYOL/sthalles/results/BYOL/dataset-MNIST_arch-resnet18_epochs-50_batch-200/\"\r\n",
        "\r\n",
        "print(\"[INFO] Loading pretrained model...\")\r\n",
        "load_params = torch.load(os.path.join(results_path_load_BYOL, 'BYOL_model.pth'), map_location = torch.device(torch.device(device)))\r\n",
        "if 'Online_Net_state_dict' in load_params:\r\n",
        "    BYOL_pretrained.load_state_dict(load_params['Online_Net_state_dict'])\r\n",
        "    print(\"Parameters successfully loaded.\")\r\n"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] Loading pretrained model...\n",
            "Parameters successfully loaded.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V3ZTGaKu_vgR",
        "outputId": "41c345aa-c47f-4709-8e75-99067b86378e"
      },
      "source": [
        "BYOL_pretrained = torch.nn.Sequential(*list(BYOL_pretrained.children())[:-1],   # remove the projection head\r\n",
        "                                      nn.Linear(512, 10))   \r\n",
        "BYOL_pretrained"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "    (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "    (4): Sequential(\n",
              "      (0): BasicBlock(\n",
              "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (1): BasicBlock(\n",
              "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (5): Sequential(\n",
              "      (0): BasicBlock(\n",
              "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): BasicBlock(\n",
              "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (6): Sequential(\n",
              "      (0): BasicBlock(\n",
              "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): BasicBlock(\n",
              "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (7): Sequential(\n",
              "      (0): BasicBlock(\n",
              "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): BasicBlock(\n",
              "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (8): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  )\n",
              "  (1): Linear(in_features=512, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "DgZ9k-ItDM-f",
        "outputId": "f543f41b-0525-4068-dca0-d1067fd97aa3"
      },
      "source": [
        "BYOL_pretrained.to(device)\r\n",
        "\r\n",
        "learning_rate = 0.01\r\n",
        "momentum = 0.9\r\n",
        "\r\n",
        "loss_function = nn.CrossEntropyLoss()\r\n",
        "optimizer_ft = torch.optim.SGD(BYOL_pretrained.parameters(), lr=learning_rate, momentum=momentum)              # Observe that all parameters are being optimized\r\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)      # Decay LR by a factor of 0.1 every 7 epochs\r\n",
        "\r\n",
        "BYOL_pretrained = Supervised(BYOL_pretrained, optimizer_ft, None, dataloaders, loss_function)\r\n",
        "print(\"[INFO] Start training on MNIST dataset for {} epochs, with {} batch_size...\".format(SUPERVISED_EPOCHS, SUPERVISED_BATCH))\r\n",
        "BYOL_pretrained_trained, results_BYOL = BYOL_pretrained.train_test_model(SUPERVISED_EPOCHS, LOG_INTERVAL)\r\n",
        "save_plot_model_optim_supervised(results_BYOL['train_loss'], results_BYOL['test_loss'], BYOL_pretrained_trained, type_results=\"BYOL\")   "
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] Start training on MNIST dataset for 5 epochs, with 256 batch_size...\n",
            "----------\n",
            "Epoch 1/5\n",
            "tensor([[[[-2.1179, -2.1179, -2.1179,  ..., -1.1760, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -1.4672, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -1.9638, -2.1179, -2.1179],\n",
            "          ...,\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179]],\n",
            "\n",
            "         [[-2.0357, -2.0357, -2.0357,  ..., -1.0728, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -1.3704, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -1.8782, -2.0357, -2.0357],\n",
            "          ...,\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357]],\n",
            "\n",
            "         [[-1.8044, -1.8044, -1.8044,  ..., -0.8458, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.1421, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.6476, -1.8044, -1.8044],\n",
            "          ...,\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044]]],\n",
            "\n",
            "\n",
            "        [[[-2.1179, -2.1179, -2.1179,  ...,  2.2147,  2.2147,  2.2147],\n",
            "          [-2.1179, -2.1179, -2.1179,  ...,  2.2147,  2.2147,  2.2147],\n",
            "          [-2.1179, -2.1179, -2.1179,  ...,  2.2147,  2.2147,  2.2147],\n",
            "          ...,\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179]],\n",
            "\n",
            "         [[-2.0357, -2.0357, -2.0357,  ...,  2.3936,  2.3936,  2.3936],\n",
            "          [-2.0357, -2.0357, -2.0357,  ...,  2.3936,  2.3936,  2.3936],\n",
            "          [-2.0357, -2.0357, -2.0357,  ...,  2.3936,  2.3936,  2.3936],\n",
            "          ...,\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357]],\n",
            "\n",
            "         [[-1.8044, -1.8044, -1.8044,  ...,  2.6051,  2.6051,  2.6051],\n",
            "          [-1.8044, -1.8044, -1.8044,  ...,  2.6051,  2.6051,  2.6051],\n",
            "          [-1.8044, -1.8044, -1.8044,  ...,  2.6051,  2.6051,  2.6051],\n",
            "          ...,\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044]]],\n",
            "\n",
            "\n",
            "        [[[-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          ...,\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179]],\n",
            "\n",
            "         [[-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          ...,\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357]],\n",
            "\n",
            "         [[-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          ...,\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          ...,\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179]],\n",
            "\n",
            "         [[-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          ...,\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357]],\n",
            "\n",
            "         [[-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          ...,\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044]]],\n",
            "\n",
            "\n",
            "        [[[-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          ...,\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -1.9467, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -1.9467, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -1.9467, -2.1179, -2.1179]],\n",
            "\n",
            "         [[-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          ...,\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -1.8606, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -1.8606, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -1.8606, -2.0357, -2.0357]],\n",
            "\n",
            "         [[-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          ...,\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.6302, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.6302, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.6302, -1.8044, -1.8044]]],\n",
            "\n",
            "\n",
            "        [[[-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          ...,\n",
            "          [ 1.5125,  1.7180,  2.1119,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [-0.2171, -0.0287,  0.2624,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179]],\n",
            "\n",
            "         [[-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          ...,\n",
            "          [ 1.6758,  1.8859,  2.2885,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [-0.0924,  0.1001,  0.3978,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357]],\n",
            "\n",
            "         [[-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          ...,\n",
            "          [ 1.8905,  2.0997,  2.5006,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [ 0.1302,  0.3219,  0.6182,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044]]]],\n",
            "       device='cuda:0')\n",
            "256\n",
            "<class 'torch.Tensor'>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-54-caf807e7a1f5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mBYOL_pretrained\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSupervised\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBYOL_pretrained\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_ft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"[INFO] Start training on MNIST dataset for {} epochs, with {} batch_size...\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSUPERVISED_EPOCHS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSUPERVISED_BATCH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mBYOL_pretrained_trained\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresults_BYOL\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBYOL_pretrained\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_test_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSUPERVISED_EPOCHS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLOG_INTERVAL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0msave_plot_model_optim_supervised\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults_BYOL\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresults_BYOL\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBYOL_pretrained_trained\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype_results\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"BYOL\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-49-24f15775345e>\u001b[0m in \u001b[0;36mtrain_test_model\u001b[0;34m(self, epochs, log_interval)\u001b[0m\n\u001b[1;32m     43\u001b[0m                     \u001b[0;31m# forward - track history if only in train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m                     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphase\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m                         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m                         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m                         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1751\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhas_torch_function_variadic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1753\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1754\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1755\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: mat1 dim 1 must match mat2 dim 0"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8D8t6h1eDquf"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}