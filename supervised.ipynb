{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "supervised.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "syU19oRMMEkB",
        "outputId": "a8f05f96-61b1-474e-e12e-ee43d231ee39"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "exxOiLa7MId6"
      },
      "source": [
        "import os\r\n",
        "from pathlib import Path\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import seaborn as sns\r\n",
        "\r\n",
        "import pandas as pd\r\n",
        "import glob\r\n",
        "import torch\r\n",
        "import yaml\r\n",
        "from torchvision import datasets\r\n",
        "\r\n",
        "from torch.optim import lr_scheduler\r\n",
        "import random\r\n",
        "from tqdm import tqdm\r\n",
        "import copy\r\n",
        "import json\r\n",
        "from torchvision import transforms\r\n",
        "import torch.nn as nn\r\n",
        "from torch import nn\r\n",
        "import numpy as np\r\n",
        "from PIL import Image\r\n",
        "\r\n",
        "from torchvision.transforms import transforms\r\n",
        "\r\n",
        "import torchvision.models as models\r\n",
        "from collections import OrderedDict\r\n",
        "\r\n",
        "import torch.nn.functional as F\r\n",
        "from torchvision import transforms as T\r\n",
        "import torchvision\r\n",
        "from torch.utils.data.dataloader import DataLoader\r\n",
        "from torch.utils.tensorboard import SummaryWriter\r\n",
        "\r\n",
        "from shutil import copyfile\r\n",
        "import time\r\n",
        "# !pip install --ignore-installed PyYAML"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QwuMqUc1WtM1"
      },
      "source": [
        "class ResNet(torch.nn.Module):\r\n",
        "    def __init__(self, network_name):\r\n",
        "        super(ResNet, self).__init__()\r\n",
        "        if network_name == 'resnet18':\r\n",
        "            resnet = models.resnet18(pretrained=False)\r\n",
        "        elif network_name == 'resnet50':\r\n",
        "            resnet = models.resnet50(pretrained=False)\r\n",
        "\r\n",
        "\r\n",
        "        self.encoder = torch.nn.Sequential(*list(resnet.children())[:-1])\r\n",
        "\r\n",
        "        self.projection = MLPHead(IN_channels      = resnet.fc.in_features, \r\n",
        "                                  mlp_HIDDEN_size  = projection_head_mlp_hidden_size,\r\n",
        "                                  OUT_channels     = projection_head_projection_size)\r\n",
        "\r\n",
        "    def forward(self, x):\r\n",
        "        h = self.encoder(x)\r\n",
        "        h = h.view(h.shape[0], h.shape[1])\r\n",
        "        return self.projection(h)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DKbAbpFH-mbF"
      },
      "source": [
        "class MLPHead(nn.Module):\r\n",
        "    def __init__(self, IN_channels, mlp_HIDDEN_size, OUT_channels):\r\n",
        "        super(MLPHead, self).__init__()\r\n",
        "\r\n",
        "        self.net = nn.Sequential(\r\n",
        "                      nn.Linear(IN_channels, mlp_HIDDEN_size),\r\n",
        "                      nn.BatchNorm1d(mlp_HIDDEN_size),\r\n",
        "                      nn.ReLU(inplace=True),\r\n",
        "                      nn.Linear(mlp_HIDDEN_size, OUT_channels))\r\n",
        "\r\n",
        "    def forward(self, x):\r\n",
        "        return self.net(x)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zU0m9Gn3MMQf"
      },
      "source": [
        "# Data augmentation and normalization for training\r\n",
        "# Just normalization for validation\r\n",
        "data_transforms_supervised = {\r\n",
        "    'train': transforms.Compose([\r\n",
        "        transforms.RandomResizedCrop(28),\r\n",
        "        transforms.RandomHorizontalFlip(),\r\n",
        "        transforms.ToTensor(),\r\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\r\n",
        "    ]),\r\n",
        "    'test': transforms.Compose([\r\n",
        "        transforms.Resize(28),\r\n",
        "        transforms.CenterCrop(28),\r\n",
        "        transforms.ToTensor(),\r\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\r\n",
        "    ]),\r\n",
        "}\r\n",
        "\r\n",
        "results_supervised = {'train_loss': [], 'test_loss': [], \r\n",
        "                      'train_acc': [], 'test_acc': []}                   \r\n",
        "\r\n",
        "results_BYOL = {'train_loss': [], 'test_loss': [], \r\n",
        "                'train_acc': [], 'test_acc': []}   \r\n",
        "\r\n",
        "results = {'train_loss': [], 'test_loss': [], \r\n",
        "           'train_acc': [], 'test_acc': []}   "
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AW87uwNZWT7f"
      },
      "source": [
        "def save_plot_model_optim_supervised(train_losses, test_losses, model, type_results):\r\n",
        "    if type_results == \"BYOL\":\r\n",
        "        print(\"[INFO] Plotting - saving after supervised training on BYOL pretrained model into files to: {}\".format(results_path))\r\n",
        "            \r\n",
        "        plot_acc_loss(train_losses, test_losses, \"Epochs\", \"Loss\", 'Train Loss', 'Test Loss', \"Training Losses\", os.path.join(results_path, 'Supervised_BYOL_training_losses.png'))\r\n",
        "            \r\n",
        "        torch.save(model.state_dict(), os.path.join(results_path, \"Supervised_BYOL_model.pth\"))\r\n",
        "        np.savez(os.path.join(results_path, \"Supervised_BYOL_lossesfile\"), np.array(train_losses))\r\n",
        "        np.savetxt(os.path.join(results_path, \"Supervised_BYOL_lossesfile.csv\"), train_losses, delimiter=\",\")\r\n",
        "\r\n",
        "    elif type_results == \"notpretrained\":\r\n",
        "        print(\"[INFO] Plotting - saving after supervised training on NOT-pretrained model into files to: {}\".format(results_path))\r\n",
        "            \r\n",
        "        plot_acc_loss(train_losses, test_losses, \"Epochs\", \"Loss\", 'Train Loss', 'Test Loss', \"Training Losses\", os.path.join(results_path, 'Supervised_NotPret_training_losses.png'))\r\n",
        "            \r\n",
        "        torch.save(model.state_dict(), os.path.join(results_path, \"Supervised_NotPret_model.pth\"))\r\n",
        "        np.savez(os.path.join(results_path, \"Supervised_NotPret_lossesfile\"), np.array(train_losses))\r\n",
        "        np.savetxt(os.path.join(results_path, \"Supervised_NotPret_lossesfile.csv\"), train_losses, delimiter=\",\")\r\n",
        "\r\n",
        "# array of data, name of graph, folder to save\r\n",
        "def plot_acc_loss(arr1, arr2, x_axes, y_axes, legend1, legend2, legend_name, fname):\r\n",
        "    plt.figure(figsize=(10, 10))\r\n",
        "    sns.set_style('darkgrid')\r\n",
        "    plt.title(legend_name)\r\n",
        "    plt.plot(arr1, label=arr1)\r\n",
        "    if arr2:\r\n",
        "        plt.plot(arr2, label=arr2)\r\n",
        "    plt.xlabel(x_axes)\r\n",
        "    plt.ylabel(y_axes)\r\n",
        "    plt.legend([legend1, legend2])\r\n",
        "    plt.savefig(fname)\r\n",
        "    plt.show()\r\n",
        "    plt.close()"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b8BaPJ3pMONu"
      },
      "source": [
        "# MODEL\r\n",
        "def get_model(arch, out_dim):\r\n",
        "    # defining our deep learning architecture\r\n",
        "    if arch == \"resnet18\":\r\n",
        "      resnet = models.resnet18(pretrained=False, num_classes=out_dim)\r\n",
        "    elif arch == \"resnet34\":\r\n",
        "      resnet = models.resnet34(pretrained=False, num_classes=out_dim)\r\n",
        "    elif arch == \"resnet50\":\r\n",
        "      resnet = models.resnet50(pretrained=False, num_classes=out_dim)\r\n",
        "    else:\r\n",
        "      print(\"[ERROR] Define resnet18 or resnet34 or resnet50\")\r\n",
        "\r\n",
        "    print(\"[INFO] Training on architecture: {}\".format(arch))\r\n",
        "\r\n",
        "    resnet.to(device)\r\n",
        "\r\n",
        "    return resnet"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u4iaHTtGMQSi"
      },
      "source": [
        "class Supervised:\r\n",
        "    def __init__(self, model, optimizer, scheduler, dataloaders, loss_function):\r\n",
        "        self.model = model\r\n",
        "        self.optimizer = optimizer\r\n",
        "        self.scheduler = scheduler\r\n",
        "        self.dataloaders = dataloaders\r\n",
        "        self.loss_function = loss_function\r\n",
        "        #logging.basicConfig(filename=os.path.join(results_path, 'training.log'), level=logging.DEBUG)\r\n",
        "\r\n",
        "    def train_test_model(self, epochs, log_interval):\r\n",
        "        since = time.time()\r\n",
        "\r\n",
        "        best_model_wts = copy.deepcopy(self.model.state_dict())\r\n",
        "        best_acc, epoch_of_best_acc = 0.0, 0\r\n",
        "        \r\n",
        "        for epoch in range(1, SUPERVISED_EPOCHS+1):\r\n",
        "            since_epoch = time.time()\r\n",
        "            print('-' * 10)\r\n",
        "            print('Epoch {}/{}'.format(epoch, SUPERVISED_EPOCHS))\r\n",
        "            \r\n",
        "            # Each epoch has a training and validation phase\r\n",
        "            for phase in ['train', 'test']:\r\n",
        "                if phase == 'train':\r\n",
        "                    self.model.train()  # Set model to training mode\r\n",
        "                else:\r\n",
        "                    self.model.eval()   # Set model to evaluate mode\r\n",
        "\r\n",
        "                running_loss = 0.0\r\n",
        "                running_corrects = 0\r\n",
        "\r\n",
        "                # Iterate over data.\r\n",
        "                for inputs, labels in self.dataloaders[phase]:\r\n",
        "                    inputs = inputs.to(device)\r\n",
        "                    labels = labels.to(device)\r\n",
        "\r\n",
        "                    # zero the parameter gradients\r\n",
        "                    self.optimizer.zero_grad()\r\n",
        "\r\n",
        "                    # forward - track history if only in train\r\n",
        "                    with torch.set_grad_enabled(phase == 'train'):\r\n",
        "                        outputs = self.model(inputs)\r\n",
        "                        _, preds = torch.max(outputs, 1)\r\n",
        "                        loss = self.loss_function(outputs, labels)\r\n",
        "\r\n",
        "                        # backward + optimize only if in training phase\r\n",
        "                        if phase == 'train':\r\n",
        "                            loss.backward()\r\n",
        "                            self.optimizer.step()\r\n",
        "\r\n",
        "                    # statistics\r\n",
        "                    running_loss += loss.item() * inputs.size(0)\r\n",
        "                    running_corrects += torch.sum(preds == labels.data)\r\n",
        "                #if phase == 'train':\r\n",
        "                    #scheduler.step()\r\n",
        "\r\n",
        "                epoch_loss = running_loss / dataset_sizes[phase]\r\n",
        "                epoch_acc = running_corrects.double() / dataset_sizes[phase]\r\n",
        "\r\n",
        "                if phase == 'train':\r\n",
        "                    results_supervised['train_loss'].append(epoch_loss)\r\n",
        "                    results_supervised['train_acc'].append(epoch_acc.item())\r\n",
        "                if phase == 'test':\r\n",
        "                    results_supervised['test_loss'].append(epoch_loss)\r\n",
        "                    results_supervised['test_acc'].append(epoch_acc.item())\r\n",
        "\r\n",
        "                time_elapsed_epoch = time.time() - since_epoch\r\n",
        "                print(\"[INFO] {} - Epoch {}/{} - Loss {:.4f} - Acc: {:.4f} - Time of last epoch: {:.0f}m {:.0f}s\".format(phase, epoch, SUPERVISED_EPOCHS, epoch_loss, epoch_acc, time_elapsed_epoch // 60, time_elapsed_epoch % 60))\r\n",
        "                #logging.info('Epoch {} - Loss: {:.4f} - Acc: {:.4f}'.format(epoch, epoch_loss, epoch_acc))\r\n",
        "\r\n",
        "                # deep copy the model\r\n",
        "                if phase == 'test' and epoch_acc > best_acc:\r\n",
        "                    best_acc = epoch_acc\r\n",
        "                    best_model_wts = copy.deepcopy(self.model.state_dict())\r\n",
        "                    epoch_of_best_acc = epoch\r\n",
        "\r\n",
        "                \r\n",
        "        #logging.info('-------------TRAINING FINNISH-------------')\r\n",
        "        time_elapsed = time.time() - since\r\n",
        "        print('[INFO] Training completed in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\r\n",
        "        print('[INFO] Best testing Accuracy: {:2} on epoch: {}'.format(best_acc*100, epoch_of_best_acc))\r\n",
        "\r\n",
        "        plot_acc_loss(results_supervised['train_loss'], results_supervised['test_loss'], \"EPOCHS\", \"LOSSES\", \"Train Loss\", \"Test Loss\", \"Losses\", os.path.join(results_path, \"train_test_losses_supervised.jpg\"))\r\n",
        "        plot_acc_loss(results_supervised['train_acc'], results_supervised['test_acc'], \"EPOCHS\", \"ACCURACY\", \"Train Acc\", \"Test Acc\", \"Accuracy\", os.path.join(results_path, \"train_test_acc_supervised.jpg\"))\r\n",
        "\r\n",
        "        data_frame = pd.DataFrame(data=results_supervised, index=range(1, epoch + 1))\r\n",
        "        data_frame.to_csv(os.path.join(results_path, \"DATA_loss_acc_supervised.csv\"), index_label='epoch')\r\n",
        "\r\n",
        "        # load best model weights\r\n",
        "        self.model.load_state_dict(best_model_wts)\r\n",
        "        return self.model, results"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H6reeLnlNhfO",
        "outputId": "10e748fe-e283-4a7d-9b03-00d27a00a400"
      },
      "source": [
        "arch = \"resnet18\"\r\n",
        "dataset = \"MNIST\"\r\n",
        "\r\n",
        "SUPERVISED_BATCH = 256\r\n",
        "SUPERVISED_EPOCHS = 5\r\n",
        "NUM_OUTPUT_CLASS = 10\r\n",
        "LOG_INTERVAL = 10\r\n",
        "\r\n",
        "print(\"[INFO] Preparing Datasets...\")\r\n",
        "\r\n",
        "data_dir = '/content/drive/MyDrive/Colab Notebooks/Self-Supervised-Learning/datasets/MNIST_folders'\r\n",
        "\r\n",
        "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms_supervised[x]) for x in ['train', 'test']}\r\n",
        "dataloaders =    {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=SUPERVISED_BATCH, shuffle=True, num_workers=4) for x in ['train', 'test']}\r\n",
        "\r\n",
        "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'test']}\r\n",
        "class_names = image_datasets['train'].classes\r\n",
        "print(\"[INFO] Class names: {}\".format(class_names))\r\n",
        "\r\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\r\n",
        "print(\"[INFO] Training on: {}\".format(device))\r\n",
        "\r\n",
        "results_path = \"/content/drive/MyDrive/Colab Notebooks/Supervised-Learning/results/supervised-mlp\"     # Path to the results directory where the saved model and evaluation graphs would be stored.\r\n",
        "specific_folder = 'dataset-{}_arch-{}_epochs-{}_batch-{}/'.format(dataset, arch, SUPERVISED_EPOCHS, SUPERVISED_BATCH)\r\n",
        "results_path = os.path.join(results_path, specific_folder)\r\n",
        "Path(results_path).mkdir(parents=True, exist_ok=True)\r\n",
        "print(\"[INFO] Results path: {}\".format(results_path))"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] Preparing Datasets...\n",
            "[INFO] Class names: ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
            "[INFO] Training on: cuda:0\n",
            "[INFO] Results path: /content/drive/MyDrive/Colab Notebooks/Supervised-Learning/results/supervised-mlp/dataset-MNIST_arch-resnet18_epochs-5_batch-256/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "1zJPUOdgO5w7",
        "outputId": "12af15aa-72da-4ec6-ffb5-767e170bbfef"
      },
      "source": [
        "model_supervised = get_model(arch, NUM_OUTPUT_CLASS)\r\n",
        "\r\n",
        "learning_rate = 0.01\r\n",
        "momentum = 0.9\r\n",
        "\r\n",
        "loss_function = nn.CrossEntropyLoss()\r\n",
        "optimizer_ft = torch.optim.SGD(model_supervised.parameters(), lr=learning_rate, momentum=momentum)              # Observe that all parameters are being optimized\r\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)      # Decay LR by a factor of 0.1 every 7 epochs\r\n",
        "\r\n",
        "supervised_model = Supervised(model_supervised, optimizer_ft, None, dataloaders, loss_function)\r\n",
        "print(\"[INFO] Start training on MNIST dataset for {} epochs, with {} batch_size...\".format(SUPERVISED_EPOCHS, SUPERVISED_BATCH))\r\n",
        "supervised_model_trained, results_supervised = supervised_model.train_test_model(SUPERVISED_EPOCHS, LOG_INTERVAL)\r\n",
        "save_plot_model_optim_supervised(results_supervised['train_loss'], results_supervised['test_loss'], supervised_model_trained, type_results=\"notpretrained\")   "
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] Training on architecture: resnet18\n",
            "[INFO] Start training on MNIST dataset for 5 epochs, with 256 batch_size...\n",
            "----------\n",
            "Epoch 1/5\n",
            "tensor([[[[ 0.4851, -0.1828, -1.2274,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [-0.5767, -0.9705, -1.5870,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          ...,\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179]],\n",
            "\n",
            "         [[ 0.6254, -0.0574, -1.1253,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [-0.4601, -0.8627, -1.4930,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          ...,\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357]],\n",
            "\n",
            "         [[ 0.8448,  0.1651, -0.8981,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [-0.2358, -0.6367, -1.2641,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          ...,\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044]]],\n",
            "\n",
            "\n",
            "        [[[-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          ...,\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179]],\n",
            "\n",
            "         [[-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          ...,\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357]],\n",
            "\n",
            "         [[-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          ...,\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044]]],\n",
            "\n",
            "\n",
            "        [[[-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          ...,\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179]],\n",
            "\n",
            "         [[-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          ...,\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357]],\n",
            "\n",
            "         [[-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          ...,\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-2.1179, -2.1179, -2.1179,  ...,  1.6667,  0.6392,  0.0569],\n",
            "          [-2.1179, -2.1179, -2.1179,  ...,  1.7009,  0.4337, -0.2684],\n",
            "          [-2.1179, -2.1179, -2.1179,  ...,  1.7180,  0.1426, -0.7479],\n",
            "          ...,\n",
            "          [-2.0494, -1.1075,  0.5878,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [-0.3369,  0.2967,  1.4269,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [ 0.8618,  1.2728,  1.9920,  ..., -2.1179, -2.1179, -2.1179]],\n",
            "\n",
            "         [[-2.0357, -2.0357, -2.0357,  ...,  1.8333,  0.7829,  0.1877],\n",
            "          [-2.0357, -2.0357, -2.0357,  ...,  1.8683,  0.5728, -0.1450],\n",
            "          [-2.0357, -2.0357, -2.0357,  ...,  1.8859,  0.2752, -0.6352],\n",
            "          ...,\n",
            "          [-1.9657, -1.0028,  0.7304,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [-0.2150,  0.4328,  1.5882,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [ 1.0105,  1.4307,  2.1660,  ..., -2.0357, -2.0357, -2.0357]],\n",
            "\n",
            "         [[-1.8044, -1.8044, -1.8044,  ...,  2.0474,  1.0017,  0.4091],\n",
            "          [-1.8044, -1.8044, -1.8044,  ...,  2.0823,  0.7925,  0.0779],\n",
            "          [-1.8044, -1.8044, -1.8044,  ...,  2.0997,  0.4962, -0.4101],\n",
            "          ...,\n",
            "          [-1.7347, -0.7761,  0.9494,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [ 0.0082,  0.6531,  1.8034,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [ 1.2282,  1.6465,  2.3786,  ..., -1.8044, -1.8044, -1.8044]]],\n",
            "\n",
            "\n",
            "        [[[-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          ...,\n",
            "          [-2.1179, -2.1179, -2.1008,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179]],\n",
            "\n",
            "         [[-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          ...,\n",
            "          [-2.0357, -2.0357, -2.0182,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357]],\n",
            "\n",
            "         [[-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          ...,\n",
            "          [-1.8044, -1.8044, -1.7870,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044]]],\n",
            "\n",
            "\n",
            "        [[[-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          ...,\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179]],\n",
            "\n",
            "         [[-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          ...,\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357]],\n",
            "\n",
            "         [[-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          ...,\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044]]]],\n",
            "       device='cuda:0')\n",
            "256\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[[[-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          ...,\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179]],\n",
            "\n",
            "         [[-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          ...,\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357]],\n",
            "\n",
            "         [[-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          ...,\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044]]],\n",
            "\n",
            "\n",
            "        [[[-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          ...,\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179]],\n",
            "\n",
            "         [[-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          ...,\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357]],\n",
            "\n",
            "         [[-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          ...,\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044]]],\n",
            "\n",
            "\n",
            "        [[[-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          ...,\n",
            "          [ 0.0569, -0.3883, -1.2788,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [-1.3302, -1.5014, -1.8097,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179]],\n",
            "\n",
            "         [[-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          ...,\n",
            "          [ 0.1877, -0.2675, -1.1779,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [-1.2304, -1.4055, -1.7206,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357]],\n",
            "\n",
            "         [[-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          ...,\n",
            "          [ 0.4091, -0.0441, -0.9504,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [-1.0027, -1.1770, -1.4907,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-1.0904,  0.6221,  2.2147,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [-1.4500,  0.0569,  1.6324,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [-2.0494, -0.8335,  0.6906,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          ...,\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179]],\n",
            "\n",
            "         [[-0.9853,  0.7654,  2.3936,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [-1.3529,  0.1877,  1.7983,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [-1.9657, -0.7227,  0.8354,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          ...,\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357]],\n",
            "\n",
            "         [[-0.7587,  0.9842,  2.6051,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [-1.1247,  0.4091,  2.0125,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [-1.7347, -0.4973,  1.0539,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          ...,\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044]]],\n",
            "\n",
            "\n",
            "        [[[-2.1179, -2.1179, -2.1179,  ..., -1.9809, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -1.5699, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -0.4397, -1.5699, -2.1179],\n",
            "          ...,\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179]],\n",
            "\n",
            "         [[-2.0357, -2.0357, -2.0357,  ..., -1.8957, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -1.4755, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -0.3200, -1.4755, -2.0357],\n",
            "          ...,\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357]],\n",
            "\n",
            "         [[-1.8044, -1.8044, -1.8044,  ..., -1.6650, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.2467, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -0.0964, -1.2467, -1.8044],\n",
            "          ...,\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044]]],\n",
            "\n",
            "\n",
            "        [[[-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          ...,\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179]],\n",
            "\n",
            "         [[-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          ...,\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357]],\n",
            "\n",
            "         [[-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          ...,\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044]]]],\n",
            "       device='cuda:0')\n",
            "256\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[[[-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          ...,\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.0665, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.0837, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1008, -2.1179, -2.1179]],\n",
            "\n",
            "         [[-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          ...,\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -1.9832, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0007, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0182, -2.0357, -2.0357]],\n",
            "\n",
            "         [[-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          ...,\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.7522, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.7696, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.7870, -1.8044, -1.8044]]],\n",
            "\n",
            "\n",
            "        [[[-0.7137, -0.9192, -1.5185,  ..., -1.8097, -2.0323, -2.1179],\n",
            "          [-0.7137, -0.9192, -1.5185,  ..., -1.8097, -2.0323, -2.1179],\n",
            "          [-0.0287, -0.3027, -1.1589,  ..., -0.9363, -1.3302, -1.4672],\n",
            "          ...,\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179]],\n",
            "\n",
            "         [[-0.6001, -0.8102, -1.4230,  ..., -1.7206, -1.9482, -2.0357],\n",
            "          [-0.6001, -0.8102, -1.4230,  ..., -1.7206, -1.9482, -2.0357],\n",
            "          [ 0.1001, -0.1800, -1.0553,  ..., -0.8277, -1.2304, -1.3704],\n",
            "          ...,\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357]],\n",
            "\n",
            "         [[-0.3753, -0.5844, -1.1944,  ..., -1.4907, -1.7173, -1.8044],\n",
            "          [-0.3753, -0.5844, -1.1944,  ..., -1.4907, -1.7173, -1.8044],\n",
            "          [ 0.3219,  0.0431, -0.8284,  ..., -0.6018, -1.0027, -1.1421],\n",
            "          ...,\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044]]],\n",
            "\n",
            "\n",
            "        [[[-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -0.9020, -2.1179, -2.1179],\n",
            "          ...,\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179]],\n",
            "\n",
            "         [[-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -0.7927, -2.0357, -2.0357],\n",
            "          ...,\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357]],\n",
            "\n",
            "         [[-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -0.5670, -1.8044, -1.8044],\n",
            "          ...,\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          ...,\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -1.2445,  0.2796,  1.0502],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -1.3815,  0.0398,  0.7419],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -1.4329, -0.0458,  0.6392]],\n",
            "\n",
            "         [[-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          ...,\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -1.1429,  0.4153,  1.2031],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -1.2829,  0.1702,  0.8880],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -1.3354,  0.0826,  0.7829]],\n",
            "\n",
            "         [[-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          ...,\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -0.9156,  0.6356,  1.4200],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.0550,  0.3916,  1.1062],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.1073,  0.3045,  1.0017]]],\n",
            "\n",
            "\n",
            "        [[[-2.1179, -2.0494, -1.7240,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [-2.0665, -1.9809, -1.5699,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [-1.8439, -1.6727, -0.9363,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          ...,\n",
            "          [ 1.9064,  1.9407,  2.0605,  ..., -1.0733, -0.6965, -0.6109],\n",
            "          [ 1.6495,  1.7009,  1.9235,  ..., -0.2856,  0.3823,  0.5364],\n",
            "          [ 1.5982,  1.6495,  1.8893,  ..., -0.0972,  0.6221,  0.7933]],\n",
            "\n",
            "         [[-2.0357, -1.9657, -1.6331,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [-1.9832, -1.8957, -1.4755,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [-1.7556, -1.5805, -0.8277,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          ...,\n",
            "          [ 2.0784,  2.1134,  2.2360,  ..., -0.9678, -0.5826, -0.4951],\n",
            "          [ 1.8158,  1.8683,  2.0959,  ..., -0.1625,  0.5203,  0.6779],\n",
            "          [ 1.7633,  1.8158,  2.0609,  ...,  0.0301,  0.7654,  0.9405]],\n",
            "\n",
            "         [[-1.8044, -1.7347, -1.4036,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [-1.7522, -1.6650, -1.2467,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [-1.5256, -1.3513, -0.6018,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          ...,\n",
            "          [ 2.2914,  2.3263,  2.4483,  ..., -0.7413, -0.3578, -0.2707],\n",
            "          [ 2.0300,  2.0823,  2.3088,  ...,  0.0605,  0.7402,  0.8971],\n",
            "          [ 1.9777,  2.0300,  2.2740,  ...,  0.2522,  0.9842,  1.1585]]],\n",
            "\n",
            "\n",
            "        [[[-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          ...,\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179]],\n",
            "\n",
            "         [[-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          ...,\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357]],\n",
            "\n",
            "         [[-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          ...,\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044]]]],\n",
            "       device='cuda:0')\n",
            "256\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[[[-2.1179, -2.1179, -2.1179,  ...,  1.3927,  1.9578,  2.2318],\n",
            "          [-2.1179, -2.1179, -2.1179,  ...,  1.7352,  2.0777,  2.2318],\n",
            "          [-2.1179, -2.1179, -2.1179,  ...,  2.2318,  2.2318,  2.2318],\n",
            "          ...,\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179]],\n",
            "\n",
            "         [[-2.0357, -2.0357, -2.0357,  ...,  1.5532,  2.1310,  2.4111],\n",
            "          [-2.0357, -2.0357, -2.0357,  ...,  1.9034,  2.2535,  2.4111],\n",
            "          [-2.0357, -2.0357, -2.0357,  ...,  2.4111,  2.4111,  2.4111],\n",
            "          ...,\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357]],\n",
            "\n",
            "         [[-1.8044, -1.8044, -1.8044,  ...,  1.7685,  2.3437,  2.6226],\n",
            "          [-1.8044, -1.8044, -1.8044,  ...,  2.1171,  2.4657,  2.6226],\n",
            "          [-1.8044, -1.8044, -1.8044,  ...,  2.6226,  2.6226,  2.6226],\n",
            "          ...,\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044]]],\n",
            "\n",
            "\n",
            "        [[[-2.1179, -2.1179, -2.1179,  ...,  2.2318,  2.2318,  2.2318],\n",
            "          [-2.1179, -2.1179, -2.1179,  ...,  2.2318,  2.2318,  2.2318],\n",
            "          [-2.1179, -2.1179, -2.1179,  ...,  2.2318,  2.2318,  2.2318],\n",
            "          ...,\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -1.6213, -1.9638, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -1.9295, -2.0494, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179]],\n",
            "\n",
            "         [[-2.0357, -2.0357, -2.0357,  ...,  2.4111,  2.4111,  2.4111],\n",
            "          [-2.0357, -2.0357, -2.0357,  ...,  2.4111,  2.4111,  2.4111],\n",
            "          [-2.0357, -2.0357, -2.0357,  ...,  2.4111,  2.4111,  2.4111],\n",
            "          ...,\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -1.5280, -1.8782, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -1.8431, -1.9657, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357]],\n",
            "\n",
            "         [[-1.8044, -1.8044, -1.8044,  ...,  2.6226,  2.6226,  2.6226],\n",
            "          [-1.8044, -1.8044, -1.8044,  ...,  2.6226,  2.6226,  2.6226],\n",
            "          [-1.8044, -1.8044, -1.8044,  ...,  2.6226,  2.6226,  2.6226],\n",
            "          ...,\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.2990, -1.6476, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.6127, -1.7347, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044]]],\n",
            "\n",
            "\n",
            "        [[[-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          ...,\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179]],\n",
            "\n",
            "         [[-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          ...,\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357]],\n",
            "\n",
            "         [[-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          ...,\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          ...,\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179]],\n",
            "\n",
            "         [[-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          ...,\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357]],\n",
            "\n",
            "         [[-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          ...,\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044]]],\n",
            "\n",
            "\n",
            "        [[[-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          ...,\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179]],\n",
            "\n",
            "         [[-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          ...,\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357]],\n",
            "\n",
            "         [[-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          ...,\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0569, -0.1828, -0.6109,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [ 0.4851,  0.2967, -0.0458,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [ 1.4954,  1.4098,  1.2728,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          ...,\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179]],\n",
            "\n",
            "         [[ 0.1877, -0.0574, -0.4951,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [ 0.6254,  0.4328,  0.0826,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [ 1.6583,  1.5707,  1.4307,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          ...,\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357]],\n",
            "\n",
            "         [[ 0.4091,  0.1651, -0.2707,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [ 0.8448,  0.6531,  0.3045,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [ 1.8731,  1.7860,  1.6465,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          ...,\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044]]]],\n",
            "       device='cuda:0')\n",
            "256\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[[[-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          ...,\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -1.2445, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -0.7308, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -0.6109, -2.1179, -2.1179]],\n",
            "\n",
            "         [[-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          ...,\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -1.1429, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -0.6176, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -0.4951, -2.0357, -2.0357]],\n",
            "\n",
            "         [[-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          ...,\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -0.9156, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -0.3927, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -0.2707, -1.8044, -1.8044]]],\n",
            "\n",
            "\n",
            "        [[[-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          ...,\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179]],\n",
            "\n",
            "         [[-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          ...,\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357]],\n",
            "\n",
            "         [[-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          ...,\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044]]],\n",
            "\n",
            "\n",
            "        [[[-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          ...,\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179]],\n",
            "\n",
            "         [[-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          ...,\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357]],\n",
            "\n",
            "         [[-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          ...,\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          ...,\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179]],\n",
            "\n",
            "         [[-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          ...,\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357]],\n",
            "\n",
            "         [[-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          ...,\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044]]],\n",
            "\n",
            "\n",
            "        [[[-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          ...,\n",
            "          [ 0.1597,  0.1597,  0.1597,  ...,  0.1254,  0.1597,  0.1597],\n",
            "          [-1.0390, -1.0390, -1.0390,  ..., -1.0733, -1.0390, -1.0390],\n",
            "          [-1.1589, -1.1589, -1.1589,  ..., -1.1932, -1.1589, -1.1589]],\n",
            "\n",
            "         [[-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          ...,\n",
            "          [ 0.2927,  0.2927,  0.2927,  ...,  0.2577,  0.2927,  0.2927],\n",
            "          [-0.9328, -0.9328, -0.9328,  ..., -0.9678, -0.9328, -0.9328],\n",
            "          [-1.0553, -1.0553, -1.0553,  ..., -1.0903, -1.0553, -1.0553]],\n",
            "\n",
            "         [[-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          ...,\n",
            "          [ 0.5136,  0.5136,  0.5136,  ...,  0.4788,  0.5136,  0.5136],\n",
            "          [-0.7064, -0.7064, -0.7064,  ..., -0.7413, -0.7064, -0.7064],\n",
            "          [-0.8284, -0.8284, -0.8284,  ..., -0.8633, -0.8284, -0.8284]]],\n",
            "\n",
            "\n",
            "        [[[-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          ...,\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179]],\n",
            "\n",
            "         [[-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          ...,\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357]],\n",
            "\n",
            "         [[-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          ...,\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044]]]],\n",
            "       device='cuda:0')\n",
            "256\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[[[-2.1179, -2.1179, -2.1179,  ...,  1.5125,  0.8276,  0.5364],\n",
            "          [-2.1179, -2.1179, -2.1179,  ...,  1.5810,  0.9474,  0.6906],\n",
            "          [-2.1179, -2.1179, -2.1179,  ...,  1.8550,  1.4954,  1.3413],\n",
            "          ...,\n",
            "          [-2.1179, -1.9295, -1.5014,  ..., -0.7479, -0.7479, -0.7479],\n",
            "          [-2.1179, -1.9809, -1.6898,  ...,  0.2967,  0.2967,  0.2967],\n",
            "          [-2.1179, -1.9980, -1.7412,  ...,  0.5364,  0.5364,  0.5364]],\n",
            "\n",
            "         [[-2.0357, -2.0357, -2.0357,  ...,  1.6758,  0.9755,  0.6779],\n",
            "          [-2.0357, -2.0357, -2.0357,  ...,  1.7458,  1.0980,  0.8354],\n",
            "          [-2.0357, -2.0357, -2.0357,  ...,  2.0259,  1.6583,  1.5007],\n",
            "          ...,\n",
            "          [-2.0357, -1.8431, -1.4055,  ..., -0.6352, -0.6352, -0.6352],\n",
            "          [-2.0357, -1.8957, -1.5980,  ...,  0.4328,  0.4328,  0.4328],\n",
            "          [-2.0357, -1.9132, -1.6506,  ...,  0.6779,  0.6779,  0.6779]],\n",
            "\n",
            "         [[-1.8044, -1.8044, -1.8044,  ...,  1.8905,  1.1934,  0.8971],\n",
            "          [-1.8044, -1.8044, -1.8044,  ...,  1.9603,  1.3154,  1.0539],\n",
            "          [-1.8044, -1.8044, -1.8044,  ...,  2.2391,  1.8731,  1.7163],\n",
            "          ...,\n",
            "          [-1.8044, -1.6127, -1.1770,  ..., -0.4101, -0.4101, -0.4101],\n",
            "          [-1.8044, -1.6650, -1.3687,  ...,  0.6531,  0.6531,  0.6531],\n",
            "          [-1.8044, -1.6824, -1.4210,  ...,  0.8971,  0.8971,  0.8971]]],\n",
            "\n",
            "\n",
            "        [[[-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          ...,\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179]],\n",
            "\n",
            "         [[-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          ...,\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357]],\n",
            "\n",
            "         [[-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          ...,\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044]]],\n",
            "\n",
            "\n",
            "        [[[-2.1179, -0.5767,  1.2899,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [-2.1179, -0.7137,  1.0331,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [-2.1179, -0.9020,  0.6734,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          ...,\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179]],\n",
            "\n",
            "         [[-2.0357, -0.4601,  1.4482,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [-2.0357, -0.6001,  1.1856,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [-2.0357, -0.7927,  0.8179,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          ...,\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357]],\n",
            "\n",
            "         [[-1.8044, -0.2358,  1.6640,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [-1.8044, -0.3753,  1.4025,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [-1.8044, -0.5670,  1.0365,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          ...,\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          ...,\n",
            "          [-2.1179, -1.8953, -1.0733,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [-2.1179, -1.5699, -0.4568,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [-2.1179, -1.4843, -0.2856,  ..., -2.1179, -2.1179, -2.1179]],\n",
            "\n",
            "         [[-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          ...,\n",
            "          [-2.0357, -1.8081, -0.9678,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [-2.0357, -1.4755, -0.3375,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [-2.0357, -1.3880, -0.1625,  ..., -2.0357, -2.0357, -2.0357]],\n",
            "\n",
            "         [[-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          ...,\n",
            "          [-1.8044, -1.5779, -0.7413,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.2467, -0.1138,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.1596,  0.0605,  ..., -1.8044, -1.8044, -1.8044]]],\n",
            "\n",
            "\n",
            "        [[[-2.1179, -2.1179, -2.1179,  ..., -1.6555, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -1.6555, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -1.6555, -2.1179, -2.1179],\n",
            "          ...,\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179]],\n",
            "\n",
            "         [[-2.0357, -2.0357, -2.0357,  ..., -1.5630, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -1.5630, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -1.5630, -2.0357, -2.0357],\n",
            "          ...,\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357]],\n",
            "\n",
            "         [[-1.8044, -1.8044, -1.8044,  ..., -1.3339, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.3339, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.3339, -1.8044, -1.8044],\n",
            "          ...,\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044]]],\n",
            "\n",
            "\n",
            "        [[[-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -1.9295, -2.0323, -2.0837],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -1.6384, -1.8782, -2.0323],\n",
            "          ...,\n",
            "          [ 1.5297,  1.7694,  2.1462,  ...,  2.1975,  2.1290,  2.0777],\n",
            "          [ 1.9578,  2.0434,  2.1804,  ...,  2.1290,  1.5125,  1.1358],\n",
            "          [ 2.2147,  2.2147,  2.1975,  ...,  2.0777,  1.1358,  0.5536]],\n",
            "\n",
            "         [[-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -1.8431, -1.9482, -2.0007],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -1.5455, -1.7906, -1.9482],\n",
            "          ...,\n",
            "          [ 1.6933,  1.9384,  2.3235,  ...,  2.3761,  2.3060,  2.2535],\n",
            "          [ 2.1310,  2.2185,  2.3585,  ...,  2.3060,  1.6758,  1.2906],\n",
            "          [ 2.3936,  2.3936,  2.3761,  ...,  2.2535,  1.2906,  0.6954]],\n",
            "\n",
            "         [[-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.6127, -1.7173, -1.7696],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.3164, -1.5604, -1.7173],\n",
            "          ...,\n",
            "          [ 1.9080,  2.1520,  2.5354,  ...,  2.5877,  2.5180,  2.4657],\n",
            "          [ 2.3437,  2.4308,  2.5703,  ...,  2.5180,  1.8905,  1.5071],\n",
            "          [ 2.6051,  2.6051,  2.5877,  ...,  2.4657,  1.5071,  0.9145]]]],\n",
            "       device='cuda:0')\n",
            "256\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[[[-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          ...,\n",
            "          [-2.1179, -2.1179, -2.1179,  ...,  2.1975,  2.1975,  2.1975],\n",
            "          [-2.1179, -2.1179, -2.1179,  ...,  2.1975,  2.1975,  2.1975],\n",
            "          [-2.1179, -2.1179, -2.1179,  ...,  2.1975,  2.1975,  2.1975]],\n",
            "\n",
            "         [[-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          ...,\n",
            "          [-2.0357, -2.0357, -2.0357,  ...,  2.3761,  2.3761,  2.3761],\n",
            "          [-2.0357, -2.0357, -2.0357,  ...,  2.3761,  2.3761,  2.3761],\n",
            "          [-2.0357, -2.0357, -2.0357,  ...,  2.3761,  2.3761,  2.3761]],\n",
            "\n",
            "         [[-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          ...,\n",
            "          [-1.8044, -1.8044, -1.8044,  ...,  2.5877,  2.5877,  2.5877],\n",
            "          [-1.8044, -1.8044, -1.8044,  ...,  2.5877,  2.5877,  2.5877],\n",
            "          [-1.8044, -1.8044, -1.8044,  ...,  2.5877,  2.5877,  2.5877]]],\n",
            "\n",
            "\n",
            "        [[[-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          ...,\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179]],\n",
            "\n",
            "         [[-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          ...,\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357]],\n",
            "\n",
            "         [[-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          ...,\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044]]],\n",
            "\n",
            "\n",
            "        [[[-0.3198, -0.3198, -0.6965,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [-0.3883, -0.3883, -0.7479,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [-1.0219, -1.0219, -1.2617,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          ...,\n",
            "          [ 1.7009,  1.7009,  1.0502,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [ 1.3927,  1.3927,  0.6563,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [ 1.3584,  1.3584,  0.6221,  ..., -2.1179, -2.1179, -2.1179]],\n",
            "\n",
            "         [[-0.1975, -0.1975, -0.5826,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [-0.2675, -0.2675, -0.6352,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [-0.9153, -0.9153, -1.1604,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          ...,\n",
            "          [ 1.8683,  1.8683,  1.2031,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [ 1.5532,  1.5532,  0.8004,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [ 1.5182,  1.5182,  0.7654,  ..., -2.0357, -2.0357, -2.0357]],\n",
            "\n",
            "         [[ 0.0256,  0.0256, -0.3578,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [-0.0441, -0.0441, -0.4101,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [-0.6890, -0.6890, -0.9330,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          ...,\n",
            "          [ 2.0823,  2.0823,  1.4200,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [ 1.7685,  1.7685,  1.0191,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [ 1.7337,  1.7337,  0.9842,  ..., -1.8044, -1.8044, -1.8044]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          ...,\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179]],\n",
            "\n",
            "         [[-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          ...,\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357]],\n",
            "\n",
            "         [[-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          ...,\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044]]],\n",
            "\n",
            "\n",
            "        [[[-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          ...,\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179]],\n",
            "\n",
            "         [[-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          ...,\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357]],\n",
            "\n",
            "         [[-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          ...,\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044]]],\n",
            "\n",
            "\n",
            "        [[[-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          ...,\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179]],\n",
            "\n",
            "         [[-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          ...,\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357]],\n",
            "\n",
            "         [[-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          ...,\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044]]]],\n",
            "       device='cuda:0')\n",
            "256\n",
            "<class 'torch.Tensor'>\n",
            "tensor([[[[-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [-0.9877, -0.9877, -0.9877,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [ 0.4851,  0.4851,  0.4851,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          ...,\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.0665, -2.1008, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179]],\n",
            "\n",
            "         [[-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [-0.8803, -0.8803, -0.8803,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [ 0.6254,  0.6254,  0.6254,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          ...,\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -1.9832, -2.0182, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357]],\n",
            "\n",
            "         [[-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [-0.6541, -0.6541, -0.6541,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [ 0.8448,  0.8448,  0.8448,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          ...,\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.7522, -1.7870, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044]]],\n",
            "\n",
            "\n",
            "        [[[ 0.5878,  0.9988,  1.8037,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [ 0.8276,  1.1700,  1.8550,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [ 1.5125,  1.7009,  2.0434,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          ...,\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179]],\n",
            "\n",
            "         [[ 0.7304,  1.1506,  1.9734,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [ 0.9755,  1.3256,  2.0259,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [ 1.6758,  1.8683,  2.2185,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          ...,\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357]],\n",
            "\n",
            "         [[ 0.9494,  1.3677,  2.1868,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [ 1.1934,  1.5420,  2.2391,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [ 1.8905,  2.0823,  2.4308,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          ...,\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044]]],\n",
            "\n",
            "\n",
            "        [[[-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          ...,\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179]],\n",
            "\n",
            "         [[-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          ...,\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357]],\n",
            "\n",
            "         [[-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          ...,\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-2.1179, -2.1179, -2.1179,  ..., -1.8610, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -1.9809, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          ...,\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179]],\n",
            "\n",
            "         [[-2.0357, -2.0357, -2.0357,  ..., -1.7731, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -1.8957, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          ...,\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357]],\n",
            "\n",
            "         [[-1.8044, -1.8044, -1.8044,  ..., -1.5430, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.6650, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          ...,\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044]]],\n",
            "\n",
            "\n",
            "        [[[-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          ...,\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179]],\n",
            "\n",
            "         [[-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          ...,\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357]],\n",
            "\n",
            "         [[-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          ...,\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044]]],\n",
            "\n",
            "\n",
            "        [[[-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          ...,\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179]],\n",
            "\n",
            "         [[-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          ...,\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357]],\n",
            "\n",
            "         [[-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          ...,\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044]]]],\n",
            "       device='cuda:0')\n",
            "256\n",
            "<class 'torch.Tensor'>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-51-27b34159b32e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0msupervised_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSupervised\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_supervised\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_ft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"[INFO] Start training on MNIST dataset for {} epochs, with {} batch_size...\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSUPERVISED_EPOCHS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSUPERVISED_BATCH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0msupervised_model_trained\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresults_supervised\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msupervised_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_test_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSUPERVISED_EPOCHS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLOG_INTERVAL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0msave_plot_model_optim_supervised\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults_supervised\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresults_supervised\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msupervised_model_trained\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype_results\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"notpretrained\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-49-24f15775345e>\u001b[0m in \u001b[0;36mtrain_test_model\u001b[0;34m(self, epochs, log_interval)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m                 \u001b[0;31m# Iterate over data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataloaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mphase\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m                     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m                     \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    515\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 517\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    518\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1181\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1182\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1183\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1184\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1146\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1147\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1148\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1149\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1150\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    985\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 986\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    987\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    102\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m                     \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeadline\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 414\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    415\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 921\u001b[0;31m                 \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    922\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileobj\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    413\u001b[0m         \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m             \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    416\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H97nZfrg_euB",
        "outputId": "cd8792d9-d9e7-433d-e39e-580e0bce80b1"
      },
      "source": [
        "model_supervised"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu): ReLU(inplace=True)\n",
              "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (layer1): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jXq_fN29WLa9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8bae3ae8-f617-4b2b-976e-e89b8ab8c906"
      },
      "source": [
        "# configurations for the projection and prediction heads\r\n",
        "projection_head_mlp_hidden_size = 512     # Original implementation uses 4096\r\n",
        "projection_head_projection_size = 128     # Original implementation uses 256\r\n",
        "\r\n",
        "# LOAD PRETRAINED MODEL on BYOL\r\n",
        "BYOL_pretrained = ResNet(arch).to(device)\r\n",
        "\r\n",
        "# predictor network\r\n",
        "predictor = MLPHead(IN_channels = BYOL_pretrained.projection.net[-1].out_features, \r\n",
        "                    mlp_HIDDEN_size = projection_head_mlp_hidden_size, \r\n",
        "                    OUT_channels = projection_head_projection_size).to(device)\r\n",
        "\r\n",
        "results_path_load_BYOL = \"/content/drive/MyDrive/Colab Notebooks/Self-Supervised-Learning/BYOL/sthalles/results/BYOL/dataset-MNIST_arch-resnet18_epochs-50_batch-200/\"\r\n",
        "\r\n",
        "print(\"[INFO] Loading pretrained model...\")\r\n",
        "load_params = torch.load(os.path.join(results_path_load_BYOL, 'BYOL_model.pth'), map_location = torch.device(torch.device(device)))\r\n",
        "if 'Online_Net_state_dict' in load_params:\r\n",
        "    BYOL_pretrained.load_state_dict(load_params['Online_Net_state_dict'])\r\n",
        "    print(\"Parameters successfully loaded.\")\r\n"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] Loading pretrained model...\n",
            "Parameters successfully loaded.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V3ZTGaKu_vgR",
        "outputId": "41c345aa-c47f-4709-8e75-99067b86378e"
      },
      "source": [
        "BYOL_pretrained = torch.nn.Sequential(*list(BYOL_pretrained.children())[:-1],   # remove the projection head\r\n",
        "                                      nn.Linear(512, 10))   \r\n",
        "BYOL_pretrained"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "    (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "    (4): Sequential(\n",
              "      (0): BasicBlock(\n",
              "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (1): BasicBlock(\n",
              "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (5): Sequential(\n",
              "      (0): BasicBlock(\n",
              "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): BasicBlock(\n",
              "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (6): Sequential(\n",
              "      (0): BasicBlock(\n",
              "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): BasicBlock(\n",
              "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (7): Sequential(\n",
              "      (0): BasicBlock(\n",
              "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): BasicBlock(\n",
              "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (8): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  )\n",
              "  (1): Linear(in_features=512, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "DgZ9k-ItDM-f",
        "outputId": "f543f41b-0525-4068-dca0-d1067fd97aa3"
      },
      "source": [
        "BYOL_pretrained.to(device)\r\n",
        "\r\n",
        "learning_rate = 0.01\r\n",
        "momentum = 0.9\r\n",
        "\r\n",
        "loss_function = nn.CrossEntropyLoss()\r\n",
        "optimizer_ft = torch.optim.SGD(BYOL_pretrained.parameters(), lr=learning_rate, momentum=momentum)              # Observe that all parameters are being optimized\r\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)      # Decay LR by a factor of 0.1 every 7 epochs\r\n",
        "\r\n",
        "BYOL_pretrained = Supervised(BYOL_pretrained, optimizer_ft, None, dataloaders, loss_function)\r\n",
        "print(\"[INFO] Start training on MNIST dataset for {} epochs, with {} batch_size...\".format(SUPERVISED_EPOCHS, SUPERVISED_BATCH))\r\n",
        "BYOL_pretrained_trained, results_BYOL = BYOL_pretrained.train_test_model(SUPERVISED_EPOCHS, LOG_INTERVAL)\r\n",
        "save_plot_model_optim_supervised(results_BYOL['train_loss'], results_BYOL['test_loss'], BYOL_pretrained_trained, type_results=\"BYOL\")   "
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] Start training on MNIST dataset for 5 epochs, with 256 batch_size...\n",
            "----------\n",
            "Epoch 1/5\n",
            "tensor([[[[-2.1179, -2.1179, -2.1179,  ..., -1.1760, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -1.4672, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -1.9638, -2.1179, -2.1179],\n",
            "          ...,\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179]],\n",
            "\n",
            "         [[-2.0357, -2.0357, -2.0357,  ..., -1.0728, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -1.3704, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -1.8782, -2.0357, -2.0357],\n",
            "          ...,\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357]],\n",
            "\n",
            "         [[-1.8044, -1.8044, -1.8044,  ..., -0.8458, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.1421, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.6476, -1.8044, -1.8044],\n",
            "          ...,\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044]]],\n",
            "\n",
            "\n",
            "        [[[-2.1179, -2.1179, -2.1179,  ...,  2.2147,  2.2147,  2.2147],\n",
            "          [-2.1179, -2.1179, -2.1179,  ...,  2.2147,  2.2147,  2.2147],\n",
            "          [-2.1179, -2.1179, -2.1179,  ...,  2.2147,  2.2147,  2.2147],\n",
            "          ...,\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179]],\n",
            "\n",
            "         [[-2.0357, -2.0357, -2.0357,  ...,  2.3936,  2.3936,  2.3936],\n",
            "          [-2.0357, -2.0357, -2.0357,  ...,  2.3936,  2.3936,  2.3936],\n",
            "          [-2.0357, -2.0357, -2.0357,  ...,  2.3936,  2.3936,  2.3936],\n",
            "          ...,\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357]],\n",
            "\n",
            "         [[-1.8044, -1.8044, -1.8044,  ...,  2.6051,  2.6051,  2.6051],\n",
            "          [-1.8044, -1.8044, -1.8044,  ...,  2.6051,  2.6051,  2.6051],\n",
            "          [-1.8044, -1.8044, -1.8044,  ...,  2.6051,  2.6051,  2.6051],\n",
            "          ...,\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044]]],\n",
            "\n",
            "\n",
            "        [[[-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          ...,\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179]],\n",
            "\n",
            "         [[-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          ...,\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357]],\n",
            "\n",
            "         [[-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          ...,\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          ...,\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179]],\n",
            "\n",
            "         [[-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          ...,\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357]],\n",
            "\n",
            "         [[-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          ...,\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044]]],\n",
            "\n",
            "\n",
            "        [[[-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          ...,\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -1.9467, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -1.9467, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -1.9467, -2.1179, -2.1179]],\n",
            "\n",
            "         [[-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          ...,\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -1.8606, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -1.8606, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -1.8606, -2.0357, -2.0357]],\n",
            "\n",
            "         [[-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          ...,\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.6302, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.6302, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.6302, -1.8044, -1.8044]]],\n",
            "\n",
            "\n",
            "        [[[-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          ...,\n",
            "          [ 1.5125,  1.7180,  2.1119,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [-0.2171, -0.0287,  0.2624,  ..., -2.1179, -2.1179, -2.1179],\n",
            "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179]],\n",
            "\n",
            "         [[-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          ...,\n",
            "          [ 1.6758,  1.8859,  2.2885,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [-0.0924,  0.1001,  0.3978,  ..., -2.0357, -2.0357, -2.0357],\n",
            "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357]],\n",
            "\n",
            "         [[-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          ...,\n",
            "          [ 1.8905,  2.0997,  2.5006,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [ 0.1302,  0.3219,  0.6182,  ..., -1.8044, -1.8044, -1.8044],\n",
            "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044]]]],\n",
            "       device='cuda:0')\n",
            "256\n",
            "<class 'torch.Tensor'>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-54-caf807e7a1f5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mBYOL_pretrained\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSupervised\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBYOL_pretrained\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_ft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"[INFO] Start training on MNIST dataset for {} epochs, with {} batch_size...\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSUPERVISED_EPOCHS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSUPERVISED_BATCH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mBYOL_pretrained_trained\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresults_BYOL\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBYOL_pretrained\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_test_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSUPERVISED_EPOCHS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLOG_INTERVAL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0msave_plot_model_optim_supervised\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults_BYOL\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresults_BYOL\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBYOL_pretrained_trained\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype_results\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"BYOL\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-49-24f15775345e>\u001b[0m in \u001b[0;36mtrain_test_model\u001b[0;34m(self, epochs, log_interval)\u001b[0m\n\u001b[1;32m     43\u001b[0m                     \u001b[0;31m# forward - track history if only in train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m                     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphase\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m                         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m                         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m                         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1751\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhas_torch_function_variadic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1753\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1754\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1755\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: mat1 dim 1 must match mat2 dim 0"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8D8t6h1eDquf"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}